{"meta":{"title":"zz胖的博客","subtitle":"","description":"","author":"zzp","url":"http://new.zzpblog.cn","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-06-10T07:25:58.705Z","updated":"2020-06-10T07:25:58.705Z","comments":true,"path":"404.html","permalink":"http://new.zzpblog.cn/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2020-06-10T08:14:45.913Z","updated":"2020-06-10T08:14:45.913Z","comments":true,"path":"about/index.html","permalink":"http://new.zzpblog.cn/about/index.html","excerpt":"","text":"一句话 Just do it !"},{"title":"","date":"2020-06-10T07:43:45.605Z","updated":"2020-06-10T07:43:45.605Z","comments":true,"path":"mylist/index.html","permalink":"http://new.zzpblog.cn/mylist/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2020-06-10T07:25:02.683Z","updated":"2020-06-10T07:25:02.683Z","comments":true,"path":"categories/index.html","permalink":"http://new.zzpblog.cn/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-06-10T07:25:22.046Z","updated":"2020-06-10T07:25:22.046Z","comments":true,"path":"tags/index.html","permalink":"http://new.zzpblog.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"【webpack】一步步的看webpack-10","slug":"webpack/一步步的看webpack-10","date":"2020-06-29T06:33:57.000Z","updated":"2020-06-29T09:20:20.610Z","comments":true,"path":"2020/06/29/webpack/一步步的看webpack-10/","link":"","permalink":"http://new.zzpblog.cn/2020/06/29/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-10/","excerpt":"我们在打包或者开发过程中经常要区分开发环境和生产环境，webpack给我们提供了webpack-merge插件，可以通过这种方式去区分环境","text":"我们在打包或者开发过程中经常要区分开发环境和生产环境，webpack给我们提供了webpack-merge插件，可以通过这种方式去区分环境 环境变量webpack.common.js 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111 const path = require('path'); const &#123;CleanWebpackPlugin&#125; = require('clean-webpack-plugin'); const HtmlWebpackPlugin = require('html-webpack-plugin'); const MiniCssExtractPlugin = require('mini-css-extract-plugin'); const webpack = require('webpack');const copyWebpackPlugin = require('copy-webpack-plugin');const TerserJSPlugin = require('terser-webpack-plugin');const OptimizeCSSAssetsPlugin = require('optimize-css-assets-webpack-plugin'); module.exports = &#123; entry: &#123; app: './src/index.js' &#125;, optimization: &#123; minimizer: [new TerserJSPlugin(&#123;&#125;), new OptimizeCSSAssetsPlugin(&#123;&#125;)], &#125;, plugins: [ new CleanWebpackPlugin(), new copyWebpackPlugin(&#123; patterns: [ &#123; from: 'doc', to: './' &#125; ], &#125;), new HtmlWebpackPlugin(&#123; title: 'Production', //压缩html minify:&#123; removeAttributeQuotes:true, //去掉双引号 collapseWhitespace:true //这成一行 &#125;, hash: true &#125;), new MiniCssExtractPlugin(&#123; filename: '[name].css', chunkFilename: '[id].css' &#125;), new webpack.ProvidePlugin(&#123; $: \"jquery\", jQuery: \"jquery\" &#125;), new webpack.BannerPlugin('2020 by zzp') ], output: &#123; filename: '[name].bundle.[hash:8].js', path: path.resolve(__dirname, 'dist') &#125;, module:&#123; rules: [ &#123; test: /\\.css$/, exclude: /node_modules/, use: [ MiniCssExtractPlugin.loader, 'css-loader' ] &#125;, &#123; test:/\\.(png|jpg|gif)/ , use:[&#123; loader:'url-loader', options:&#123; outputPath: 'images', name: '[name].[ext]', limit:500 &#125; &#125;] &#125;, // &#123; // test: /\\.js$/, // exclude: /node_modules/, // use:&#123; // loader: 'eslint-loader', // options:&#123; // emitWarning: true, // enforce: 'pre' //前置，在之前先运行，post是后面的意思 // &#125; // &#125; // &#125;, &#123; test: /\\.js$/, exclude: /(node_modules|bower_components)/, include: path.resolve(__dirname,'src'), use:[ &#123; loader: 'babel-loader', // exclude: /(node_modules|bower_components)/, options:&#123; presets: ['@babel/preset-env'], plugins: ['@babel/plugin-proposal-class-properties','@babel/plugin-transform-runtime'] &#125; &#125; ] &#125; ] &#125;, resolve:&#123; modules: [path.resolve('node_modules')], //查找目录，可以写多个，比如第三方插件，自定义的目录 // alias:&#123; // bootstrap:\"bootstrap/dist/css/bootstrap.min.css\" //别名 // &#125;, extensions: ['.css','.js', '.json','.vue'],//配置了以后引入模块可以省略后缀，默认按照数组顺序查找 mainFields:['style','main'] //先去找bootstrap中的style，然后再去找main，可以看node_modules中的bootsratp package.json文件 &#125;, performance: &#123; hints: \"warning\", // 枚举 maxAssetSize: 30000000, // 整数类型（以字节为单位） maxEntrypointSize: 50000000, // 整数类型（以字节为单位） assetFilter: function(assetFilename) &#123; // 提供资源文件名的断言函数 return assetFilename.endsWith('.css') || assetFilename.endsWith('.js'); &#125; &#125; &#125;; webpack.dev.js 1234567891011121314const merge = require('webpack-merge');const common = require('./webpack.common.js');module.exports = merge(common, &#123; mode: 'development', devtool: 'inline-source-map', devServer: &#123; proxy:&#123; '/api':'http://localhost:3000' //代理，在访问/api开头路径时候都代理到后面的地址进行访问 &#125;, contentBase: './dist', progress: true //启动进度 &#125;&#125;); webpack.prod.js 123456789101112const merge = require('webpack-merge');const UglifyJSPlugin = require('uglifyjs-webpack-plugin');const common = require('./webpack.common.js');module.exports = merge(common, &#123; mode: 'production', plugins: [ new UglifyJSPlugin(&#123; sourceMap: true &#125;) ]&#125;); 打包指定package.json12345\"scripts\": &#123; \"build\": \"node_modules/.bin/webpack --config webpack.prod.js\", \"start\": \"webpack-dev-server --open\", \"dev\": \"webpack-dev-server --open --config webpack.dev.js\" &#125;, 简单方式DefinePluginwebpack.config.js 1234567new webpack.DefinePlugin(&#123; PRODUCTION: JSON.stringify(true), VERSION: JSON.stringify(\"5fa3b9\"), BROWSER_SUPPORTS_HTML5: true, TWO: \"1+1\", \"typeof window\": JSON.stringify(\"object\")&#125;) 注意！！因为这个插件直接执行文本替换，给定的值必须包含字符串本身内的实际引号。通常，有两种方式来达到这个效果，使用 ‘“production”‘, 或者使用 JSON.stringify(‘production’)。","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-8","slug":"webpack/一步步的看webpack-8","date":"2020-06-29T06:33:57.000Z","updated":"2020-06-29T09:20:23.369Z","comments":true,"path":"2020/06/29/webpack/一步步的看webpack-8/","link":"","permalink":"http://new.zzpblog.cn/2020/06/29/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-8/","excerpt":"在开发过程中，我们往往会请求后端接口，这时候就会存在跨域的问题，那webpack如何在开发时解决跨域的问题呢？","text":"在开发过程中，我们往往会请求后端接口，这时候就会存在跨域的问题，那webpack如何在开发时解决跨域的问题呢？ 解决跨域webpack.dev.js 1234567891011module.exports = &#123; //... devServer: &#123; proxy: &#123; '/api': &#123; target: 'http://localhost:3000', //将api开头的代理到该地址访问 pathRewrite: &#123;'^/api' : ''&#125; //在路径中将api开头去掉 &#125; &#125; &#125;&#125;; 更多devServer配置","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-9","slug":"webpack/一步步的看webpack-9","date":"2020-06-29T06:33:57.000Z","updated":"2020-06-29T09:20:22.312Z","comments":true,"path":"2020/06/29/webpack/一步步的看webpack-9/","link":"","permalink":"http://new.zzpblog.cn/2020/06/29/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-9/","excerpt":"很多时候我们引入的时候需要输入一长串的路径，或者引入第三方模块的时候不方便，这时候Resolve配置就可以解决这个事情啦","text":"很多时候我们引入的时候需要输入一长串的路径，或者引入第三方模块的时候不方便，这时候Resolve配置就可以解决这个事情啦 webpack.dev.js 1234567891011module.exports = &#123; //... resolve:&#123; modules: [path.resolve('node_modules')], //查找目录，可以写多个，比如第三方插件，自定义的目录 // alias:&#123; // bootstrap:\"bootstrap/dist/css/bootstrap.min.css\" //别名 // &#125;, extensions: ['.css','.js', '.json','.vue'],//配置了以后引入模块可以省略后缀，默认按照数组顺序查找 mainFields:['style','main'] //先去找bootstrap中的style，然后再去找main，可以看node_modules中的bootsratp package.json文件 &#125;,&#125;; 上面配置好我们就可以随心所欲的在需要的模块import &#39;bootstrap&#39; 引入模块啦，这里和ProvidePlugin不一样哦，这个插件是全局变量，都不需要import的，所以根据实际情况进行去选择","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-10","slug":"webpack/一步步的看webpack结尾","date":"2020-06-29T06:33:57.000Z","updated":"2020-06-29T09:20:17.396Z","comments":true,"path":"2020/06/29/webpack/一步步的看webpack结尾/","link":"","permalink":"http://new.zzpblog.cn/2020/06/29/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack%E7%BB%93%E5%B0%BE/","excerpt":"好啦，webpack4大部分的功能概念都在里面咯，剩下的就自己深入摸索吧，比如自定义插件，性能优化之类更深入的东西","text":"好啦，webpack4大部分的功能概念都在里面咯，剩下的就自己深入摸索吧，比如自定义插件，性能优化之类更深入的东西","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-7","slug":"webpack/一步步的看webpack-7","date":"2020-06-28T06:33:57.000Z","updated":"2020-06-29T09:20:24.286Z","comments":true,"path":"2020/06/28/webpack/一步步的看webpack-7/","link":"","permalink":"http://new.zzpblog.cn/2020/06/28/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-7/","excerpt":"当我们需要使用jquery第三方插件的时候使用到”$”这种全局变量该怎么办呢，webpack给我们准备了全局变量配置的概念，我们来看一下把","text":"当我们需要使用jquery第三方插件的时候使用到”$”这种全局变量该怎么办呢，webpack给我们准备了全局变量配置的概念，我们来看一下把 每个模块都加一个，简单哦1234567const webpack = require('webpack');plugins: [ new webpack.ProvidePlugin(&#123; $: \"jquery\", jQuery: \"jquery\" &#125;) ] 这样我们就可以在每个模块里面直接使用$啦 还有一个笨办法，就是使用expose-loader","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-6","slug":"webpack/一步步的看webpack-6","date":"2020-06-27T06:33:57.000Z","updated":"2020-06-29T09:20:25.447Z","comments":true,"path":"2020/06/27/webpack/一步步的看webpack-6/","link":"","permalink":"http://new.zzpblog.cn/2020/06/27/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-6/","excerpt":"在我们开发过程中每次都需要打包而且js报错的话我们也无法跟踪具体的错误在哪个js，只能定位到打包压缩后的js文件，这样让我们开发很麻烦，下面就主要说一下在开发中如何进行调试，以及如何动态热加载文件","text":"在我们开发过程中每次都需要打包而且js报错的话我们也无法跟踪具体的错误在哪个js，只能定位到打包压缩后的js文件，这样让我们开发很麻烦，下面就主要说一下在开发中如何进行调试，以及如何动态热加载文件 使用source map 当 webpack 打包源代码时，可能会很难追踪到错误和警告在源代码中的原始位置。例如，如果将三个源文件（a.js, b.js 和 c.js）打包到一个 bundle（bundle.js）中，而其中一个源文件包含一个错误，那么堆栈跟踪就会简单地指向到 bundle.js。这并通常没有太多帮助，因为你可能需要准确地知道错误来自于哪个源文件。为了更容易地追踪错误和警告，JavaScript 提供了 source map 功能，将编译后的代码映射回原始源代码。如果一个错误来自于 b.js，source map 就会明确的告诉你。source map 有很多不同的选项可用，请务必仔细阅读它们，以便可以根据需要进行配置。对于本指南，我们使用 inline-source-map 选项，这有助于解释说明我们的目的（仅解释说明，不要用于生产环境）： webpack.config.js 123456789101112131415161718192021const path = require('path'); const HtmlWebpackPlugin = require('html-webpack-plugin'); const &#123;CleanWebpackPlugin&#125; = require('clean-webpack-plugin'); module.exports = &#123; entry: &#123; app: './src/index.js', print: './src/print.js' &#125;, devtool: 'inline-source-map', plugins: [ new CleanWebpackPlugin(), new HtmlWebpackPlugin(&#123; title: 'Development' &#125;) ], output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist') &#125; &#125;; 加入devtool后，我们就可以在浏览器f12查看console中看到具体的代码打包之前源代码具体错误在第几行咯 开发工具每次要编译代码时，手动运行 npm run build 就会变得很麻烦。 webpack 中有几个不同的选项，可以帮助你在代码发生变化后自动编译代码： webpack’s Watch Mode webpack-dev-server webpack-dev-middleware多数场景中，你可能需要使用 webpack-dev-server，但是不妨探讨一下以上的所有选项。 我们挑一个大众使用最多的方式webpack-dev-serverwebpack-dev-server为你提供了一个简单的 web 服务器，并且能够实时重新加载(live reloading)。让我们设置以下： 123npm install --save-dev webpack-dev-server&#x2F;&#x2F;或yarn add -D webpack-dev-server webpack.config.js 123456789101112131415161718192021222324const path = require('path'); const HtmlWebpackPlugin = require('html-webpack-plugin'); const &#123;CleanWebpackPlugin&#125; = require('clean-webpack-plugin'); module.exports = &#123; entry: &#123; app: './src/index.js', print: './src/print.js' &#125;, devtool: 'inline-source-map', devServer: &#123; contentBase: './dist' &#125;, plugins: [ new CleanWebpackPlugin(), new HtmlWebpackPlugin(&#123; title: 'Development' &#125;) ], output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist') &#125; &#125;; 以上配置告知 webpack-dev-server，在 localhost:8080 下建立服务，将 dist 目录下的文件，作为可访问文件。 让我们添加一个 script 脚本，可以直接运行开发服务器(dev server)： 12345678910111213141516171819202122232425&#123; \"name\": \"development\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"webpack.config.js\", \"scripts\": &#123; \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\", \"watch\": \"webpack --watch\", \"start\": \"webpack-dev-server --open\", //添加启动,--open为自动打开默认浏览器 \"build\": \"webpack\" &#125;, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"devDependencies\": &#123; \"clean-webpack-plugin\": \"^0.1.16\", \"css-loader\": \"^0.28.4\", \"csv-loader\": \"^2.1.1\", \"file-loader\": \"^0.11.2\", \"html-webpack-plugin\": \"^2.29.0\", \"style-loader\": \"^0.18.2\", \"webpack\": \"^3.0.0\", \"xml-loader\": \"^1.2.1\" &#125;&#125; 现在，我们可以在命令行中运行 npm start，就会看到浏览器自动加载页面。如果现在修改和保存任意源文件，web 服务器就会自动重新加载编译后的代码。试一下！ 模块热替换 模块热替换(HMR - Hot Module Replacement)功能会在应用程序运行过程中替换、添加或删除模块，而无需重新加载整个页面。主要是通过以下几种方式，来显著加快开发速度： 保留在完全重新加载页面时丢失的应用程序状态。 只更新变更内容，以节省宝贵的开发时间。 调整样式更加快速 - 几乎相当于在浏览器调试器中更改样式。了解实现原理 webpack.config.js 123456789101112131415161718192021222324252627const path = require('path'); const HtmlWebpackPlugin = require('html-webpack-plugin'); const &#123;CleanWebpackPlugin&#125; = require('clean-webpack-plugin'); const webpack = require('webpack'); module.exports = &#123; entry: &#123; app: './src/index.js' &#125;, devtool: 'inline-source-map', devServer: &#123; //这里是最主要的哦 contentBase: './dist', hot: true &#125;, plugins: [ new CleanWebpackPlugin(), new HtmlWebpackPlugin(&#123; title: 'Hot Module Replacement' &#125;), new webpack.NamedModulesPlugin(), //告诉我们哪个模块热更新了 new webpack.HotModuleReplacementPlugin() //热替换插件 ], output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist') &#125; &#125;; 你可以通过命令来修改 webpack-dev-server 的配置：webpack-dev-server –hotOnly。 注意，我们还添加了 NamedModulesPlugin，以便更容易查看要修补(patch)的依赖。在起步阶段，我们将通过在命令行中运行 npm start 来启动并运行 dev server。 现在，我们来修改 index.js 文件，以便当 print.js 内部发生变更时可以告诉 webpack 接受更新的模块。","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-5","slug":"webpack/一步步的看webpack-5","date":"2020-06-27T06:26:57.000Z","updated":"2020-06-29T09:20:27.976Z","comments":true,"path":"2020/06/27/webpack/一步步的看webpack-5/","link":"","permalink":"http://new.zzpblog.cn/2020/06/27/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-5/","excerpt":"在webpack进行打包输出的时候，我们每次都要写一个index.html去引入生成的js文件，这里介绍个插件HtmlWebpackPlugin，可以打包的时候帮助我们生成html文件自动引入","text":"在webpack进行打包输出的时候，我们每次都要写一个index.html去引入生成的js文件，这里介绍个插件HtmlWebpackPlugin，可以打包的时候帮助我们生成html文件自动引入 设定HtmlWebpackPlugin 安装123npm install --save-dev html-webpack-plugin&#x2F;&#x2F;或yarnyarn add -D html-webpack-plugin webpack.config.js 123456789101112131415161718192021222324252627const path = require('path');const HtmlWebpackPlugin = require('html-webpack-plugin'); module.exports = &#123; entry: &#123; app: './src/index.js', print: './src/print.js' &#125;, plugins: [ new HtmlWebpackPlugin(&#123; title: 'Output Management', filename: 'app.html', //不指定默认index //压缩生成的html chunks:['app'] //不指定则会将所有入口文件引入到index.html中 &#125;), new HtmlWebpackPlugin(&#123; title: 'Output Management', filename: 'print.html', //压缩生成的html chunks:['app','print'] &#125;) ], output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist') &#125; &#125;; 在我们构建之前，你应该了解，虽然在 dist/ 文件夹我们已经有 index.html 这个文件，然而 HtmlWebpackPlugin 还是会默认生成 index.html 文件。这就是说，它会用新生成的 index.html 文件，把我们的原来的替换如果你在代码编辑器中将 index.html 打开，你就会看到 HtmlWebpackPlugin 创建了一个全新的文件，所有的 bundle 会自动添加到 html 中。如果你想要了解更多 HtmlWebpackPlugin 插件提供的全部功能和选项，那么你就应该多多熟悉 HtmlWebpackPlugin 仓库。 清理/dist文件夹clean-webpack-plugin 你可能已经注意到，由于过去的指南和代码示例遗留下来，导致我们的 /dist 文件夹相当杂乱。webpack 会生成文件，然后将这些文件放置在 /dist 文件夹中，但是 webpack 无法追踪到哪些文件是实际在项目中用到的。通常，在每次构建前清理 /dist 文件夹，是比较推荐的做法，因此只会生成用到的文件。让我们完成这个需求。clean-webpack-plugin 是一个比较普及的管理插件，让我们安装和配置下。123npm install clean-webpack-plugin --save-dev&#x2F;&#x2F;或yarn add -D clean-webpack-plugin webpack.config.js 1234567891011121314151617181920const path = require('path'); const HtmlWebpackPlugin = require('html-webpack-plugin'); const &#123;CleanWebpackPlugin&#125; = require('clean-webpack-plugin'); module.exports = &#123; entry: &#123; app: './src/index.js', print: './src/print.js' &#125;, plugins: [ new CleanWebpackPlugin(), new HtmlWebpackPlugin(&#123; title: 'Output Management' &#125;) ], output: &#123; filename: '[name].bundle.js', path: path.resolve(__dirname, 'dist') &#125; &#125;; 现在执行 npm run build，再检查 /dist 文件夹。如果一切顺利，你现在应该不会再看到旧的文件，只有构建后生成的文件！ Manifest 你可能会感兴趣，webpack及其插件似乎“知道”应该哪些文件生成。答案是，通过 manifest，webpack 能够对「你的模块映射到输出 bundle 的过程」保持追踪。如果你对通过其他方式来管理 webpack 的输出更感兴趣，那么首先了解 manifest 是个好的开始。通过使用 WebpackManifestPlugin，可以直接将数据提取到一个 json 文件，以供使用。","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-4","slug":"webpack/一步步的看webpack-4","date":"2020-06-27T02:26:57.000Z","updated":"2020-06-29T09:20:29.158Z","comments":true,"path":"2020/06/27/webpack/一步步的看webpack-4/","link":"","permalink":"http://new.zzpblog.cn/2020/06/27/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-4/","excerpt":"前面讲了webpack里面大部分的概念，这篇主要说一下loader","text":"前面讲了webpack里面大部分的概念，这篇主要说一下loader 加载css 为了从 JavaScript 模块中 import 一个 CSS 文件，你需要在 module 配置中 安装并添加 style-loader 和 css-loader：123npm install --save-dev style-loader css-loader&#x2F;&#x2F;或者使用yarnyarn add -D style-loader css-loader webpack.config.js 1234567891011121314151617181920const path = require('path');module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist') &#125;, module: &#123; rules: [ &#123; test: /\\.css$/, use: [ 'style-loader', 'css-loader' ] &#125; ] &#125;&#125;; style-loader：它是把css插入到head的标签中 css-loader：接续@import这种语法 use:按照配置的数组顺序执行 webpack 根据正则表达式，来确定应该查找哪些文件，并将其提供给指定的 loader。在这种情况下，以 .css 结尾的全部文件，都将被提供给 style-loader 和 css-loader。这使你可以在依赖于此样式的文件中 import ‘./style.css’。现在，当该模块运行时，含有 CSS 字符串的 &lt;style&gt; 标签，将被插入到 html 文件的 &lt;head&gt; 中。 我们尝试一下，通过在项目中添加一个新的 style.css 文件，并将其导入到我们的 index.js 中： 12345678910webpack-demo|- package.json|- webpack.config.js|- &#x2F;dist |- bundle.js |- index.html|- &#x2F;src |- style.css |- index.js|- &#x2F;node_modules index.js 1234567891011121314 import _ from 'lodash';import './style.css'; function component() &#123; var element = document.createElement('div'); // lodash 是由当前 script 脚本 import 导入进来的 element.innerHTML = _.join(['Hello', 'webpack'], ' '); element.classList.add('hello'); return element; &#125; document.body.appendChild(component()); 再次在浏览器中打开 index.html，你应该看到 Hello webpack 现在的样式是红色。要查看 webpack 做了什么，请检查页面（不要查看页面源代码，因为它不会显示结果），并查看页面的 head 标签。它应该包含我们在 index.js 中导入的 style 块元素。 请注意，在多数情况下，你也可以进行 CSS 分离-将css在js代码中抽取出来，具体的下面会讲到，以便在生产环境中节省加载时间。最重要的是，现有的 loader 可以支持任何你可以想到的 CSS 处理器风格 - postcss, sass 和 less 等。 加载图片 在学习Webapck过程中你可能遇到的第一个坑就是CSS中的图片处理。很多webpack新手都在图片的坑中无法自拔（有的小伙伴在开发环境中是可以找到图片的，但是一打包后就找不到图片了，有的小伙伴是不知道如何正确引入html或者css中的图片，导致程序出错），我们将用三节课时间搞彻底走出webpack图片的坑。 file-loader、url-loader 安装file-loader和url-loader 123npm install --save-dev file-loader url-loader&#x2F;&#x2F;或者yarnyarn add -D file-loader url-loader 安装好后我们需要对两个loader进行基本的了解，学习尽量做到知其然知其所以然。 file-loader：解决引用路径的问题，拿background样式用url引入背景图来说，我们都知道，webpack最终会将各个模块打包成一个文件，因此我们样式中的url路径是相对入口html页面的，而不是相对于原始css文件所在的路径的。这就会导致图片引入失败。这个问题是用file-loader解决的，file-loader可以解析项目中的url引入（不仅限于css），根据我们的配置，将图片拷贝到相应的路径，再根据我们的配置，修改打包后文件引用路径，使之指向正确的文件。 url-loader：如果图片较多，会发很多http请求，会降低页面性能。这个问题可以通过url-loader解决。url-loader会将引入的图片编码，生成dataURl。相当于把图片数据翻译成一串字符。再把这串字符打包到文件中，最终只需要引入这个文件就能访问图片了。当然，如果图片较大，编码会消耗性能。因此url-loader提供了一个limit参数，小于limit字节的文件会被转为DataURl，大于limit的还会使用file-loader进行copy。 配置url-loader我们安装好后，就可以使用这个loader了，记得在loader使用时不需要用require引入，在plugins才需要使用require引入。 webpack.config.js 123456789101112131415161718//模块：例如解读CSS,图片如何转换，压缩 module:&#123; rules: [ &#123; test: /\\.css$/, use: [ 'style-loader', 'css-loader' ] &#125;,&#123; test:/\\.(png|jpg|gif)/ , use:[&#123; loader:'url-loader', options:&#123; limit:200*1024, //byte,200k大小图片内压缩为dataUrl outputPath: 'img/' //打包图片指定路径 &#125; &#125;] &#125; ] &#125;, 1234567891011webpack-demo|- package.json|- webpack.config.js|- &#x2F;dist |- bundle.js |- index.html|- &#x2F;src |- icon.png |- style.css |- index.js|- &#x2F;node_modules index.js 123456789101112131415161718192021 import _ from 'lodash'; import './style.css';import Icon from './icon.png'; function component() &#123; var element = document.createElement('div'); // Lodash，现在由此脚本导入 element.innerHTML = _.join(['Hello', 'webpack'], ' '); element.classList.add('hello'); // 将图像添加到我们现有的 div。 var myIcon = new Image(); myIcon.src = Icon; element.appendChild(myIcon); return element; &#125; document.body.appendChild(component()); style.css 1234.hello &#123; color: red; background: url('./icon.png');&#125; test:/.(png|jpg|gif)/是匹配图片文件后缀名称。 use：是指定使用的loader和loader的配置参数。是按照配置的顺序执行 limit：是把小于500000B的文件打成Base64的格式，写入JS。写好后就可以使用webpack进行打包了，这回你会发现打包很顺利的完成了。具体的Base64的格式，你可以查看视频中的样子。为什么只使用了url-loader 有的小伙伴会发现我们并没有在webpack.config.js中使用file-loader，但是依然打包成功了。我们需要了解file-loader和url-loader的关系。url-loader和file-loader是什么关系呢？简答地说，url-loader封装了file-loader。url-loader不依赖于file-loader，即使用url-loader时，只需要安装url-loader即可，不需要安装file-loader，因为url-loader内置了file-loader。通过上面的介绍，我们可以看到，url-loader工作分两种情况： 1.文件大小小于limit参数，url-loader将会把文件转为DataURL（Base64格式）； 2.文件大小大于limit，url-loader会调用file-loader进行处理，参数也会直接传给file-loader。 也就是说，其实我们只安装一个url-loader就可以了。但是为了以后的操作方便，我们这里就顺便安装上file-loader。 加载字体那么，像字体这样的其他资源如何处理呢？file-loader 和 url-loader 可以接收并加载任何文件，然后将其输出到构建目录。这就是说，我们可以将它们用于任何类型的文件，包括字体。让我们更新 webpack.config.js 来处理字体文件： webpack.config.js 1234567891011121314151617181920212223242526272829303132const path = require('path'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist') &#125;, module: &#123; rules: [ &#123; test: /\\.css$/, use: [ 'style-loader', 'css-loader' ] &#125;, &#123; test: /\\.(png|svg|jpg|gif)$/, use: [ 'file-loader' ] &#125;, &#123; test: /\\.(woff|woff2|eot|ttf|otf)$/, use: [ 'file-loader' ] &#125; ] &#125; &#125;; 加载数据 此外，可以加载的有用资源还有数据，如 JSON 文件，CSV、TSV 和 XML。类似于 NodeJS，JSON 支持实际上是内置的，也就是说 import Data from ‘./data.json’ 默认将正常运行。要导入 CSV、TSV 和 XML，你可以使用 csv-loader 和 xml-loader。让我们处理这三类文件：123npm install --save-dev csv-loader xml-loader//或yarn add -D csv-loader xml-loader webpack.config.js 1234567891011121314151617181920212223242526272829303132333435363738394041424344const path = require('path'); module.exports = &#123; entry: './src/index.js', output: &#123; filename: 'bundle.js', path: path.resolve(__dirname, 'dist') &#125;, module: &#123; rules: [ &#123; test: /\\.css$/, use: [ 'style-loader', 'css-loader' ] &#125;, &#123; test: /\\.(png|svg|jpg|gif)$/, use: [ 'file-loader' ] &#125;, &#123; test: /\\.(woff|woff2|eot|ttf|otf)$/, use: [ 'file-loader' ] &#125;, &#123; test: /\\.(csv|tsv)$/, use: [ 'csv-loader' ] &#125;, &#123; test: /\\.xml$/, use: [ 'xml-loader' ] &#125; ] &#125; &#125;; css分离与图片路径处理 有些简单的交互页面中，你的JavasScript页面代码会非常少，而大部分代码都在CSS中，这时候项目组长会要求把CSS单独提取出来，方便以后更改。遇到这个需求你不要惊慌，已经有大神为我们准备好了对象的插件（plugin）。 extract-text-webpack-plugin 这个插件就可以完美的解决我们提取CSS的需求，但是webpack官方其实并不建议这样，他们认为CSS就应该打包到JavasScript当中以减少http的请求数。但现实中的需求往往不是我们前端能控制的，有些需求是我们不能控制的，分离CSS就是这样一个既合理由不合理的需求。 mini-css-extract-plugin webpack4有一个新插件,同上面的类似，webpack4不用extract-text-webpack-plugin这个插件了123npm install --save-dev mini-css-extract-plugin&#x2F;&#x2F;或者yarnyarn add -D mini-css-extract-plugin webpack.config.js 12345678910111213141516171819202122const MiniCssExtractPlugin = require('mini-css-extract-plugin');module.exports = &#123; plugins: [ new MiniCssExtractPlugin(&#123; // Options similar to the same options in webpackOptions.output // both options are optional filename: '[name].css', chunkFilename: '[id].css', &#125;), ], module: &#123; rules: [ &#123; test: /\\.css$/, use: [ MiniCssExtractPlugin.loader, 'css-loader', ], &#125;, ], &#125;,&#125;; 更多使用方式 图片路径问题：利用mini-css-extract-plugin插件很轻松的就把CSS文件分离了出来，但是CSS路径并不正确，很多小伙伴就在这里搞个几天还是没有头绪，网上也给出了很多的解决方案，我觉的最好的解决方案是使用publicPath解决，我也一直在用。当然我们如果打包的js文件在cdn上也可以用下面的方法指定域名哦 publicPath：是在webpack.config.js文件的output选项中，主要作用就是处理静态文件路径的。 在处理前，我们在webpack.config.js 上方声明一个对象，叫website。 123var website =&#123; publicPath:\"http://192.168.1.108:1717/\"&#125; 注意，这里的IP和端口，是你本机的ip或者是你devServer配置的IP和端口。 然后在output选项中引用这个对象的publicPath属性 12345678//出口文件的配置项 output:&#123; //输出的路径，用了Node语法 path:path.resolve(__dirname,'dist'), //输出的文件名称 filename:'[name].js', publicPath:website.publicPath &#125;, 当然上面是全局的，那么如果我只想对图片单独配置一个输出的域名路径呢？webpack.config.js 1234567891011121314151617181920//模块：例如解读CSS,图片如何转换，压缩 module:&#123; rules: [ &#123; test: /\\.css$/, use: [ 'style-loader', 'css-loader' ] &#125;,&#123; test:/\\.(png|jpg|gif)/ , use:[&#123; loader:'url-loader', options:&#123; name: '[name].[ext]', //其实url-loader内部调用的就是file-loader，我们看file-loader配置项就可以 limit:200*1024, //byte,200k大小图片内压缩为dataUrl outputPath: 'img/', //打包图片指定路径 publicPath: 'http://oss' //这样就可以咯 &#125; &#125;] &#125; ] &#125;, 配置完成后，你再使用webpack命令进行打包，你会发现原来的相对路径改为了绝对路径，这样来讲速度更快。 html-withimg-loader webpack处理资源无往不利，但有个问题总是很苦恼，html中直接使用img标签src加载图片的话，因为没有被依赖，图片将不会被打包。这个loader解决这个问题，图片会被打包，而且路径也处理妥当。额外提供html的include子页面功能。123npm install html-withimg-loader --save&#x2F;&#x2F;或者使用yarnyarn add -D html-withimg-loader webpack.config.js 1234&#123; test: /\\.(htm|html)$/i, use:[ 'html-withimg-loader'] &#125; 然后在终端中可以进行打包了。你会发现images被很好的打包了。并且路径也完全正确。 Less文件打包和分离 我们讲解一下Less文件如何打包和分离。Less 是一门 CSS 预处理语言，它扩展了 CSS 语言，增加了变量、Mixin、函数等特性，使 CSS 更易维护和扩展。也就是说Less给我们枯燥单一的样式文件加入了编程机制，这让我们这些前端程序员很受用，所以在工作中大部分程序员都使用了Leess开发。123npm install --save-dev less less-loader&#x2F;&#x2F;或yarn add -D less less-loader 123456789101112131415let MiniCssExtractPlugin = require(\"mini-css-extract-plugin\");&#123; test: /\\.(sa|sc|c|le)ss$/, use : [ MiniCssExtractPlugin.loader, \"css-loader\" , \"less-loader\", \"sass-loader\" ]&#125;plugins: [ new MiniCssExtractPlugin(&#123; filename: \"css/common.css\" &#125;),] 配置好后，你会发现less被分离到了index.css文件里。当然sass同理，这里就不阐述了 自动处理css3前缀问题123npm -d install postcss-loader autoprefixer&#x2F;&#x2F;或yarn add -D postcss-loader autoprefixer webpack.config.js 123456789101112131415161718192021&#123; test: /\\.(sa|sc|c)ss$/, use: [ MiniCssExtractPlugin.loader, 'css-loader', 'sass-loader', 'postcss-loader' ]&#125;//或webpack3中这样用&#123; test: /\\.css$/, use: extractTextPlugin.extract(&#123; fallback: 'style-loader', use: [ &#123; loader: 'css-loader', options: &#123; importLoaders: 1 &#125; &#125;, 'postcss-loader' ] &#125;)&#125; postcss.config.jspostCSS推荐在项目根目录（和webpack.config.js同级），建立一个postcss.config.js文件。 12345module.exports = &#123; plugins: [ require('autoprefixer') ]&#125; 压缩分离出来的css 要缩小输出，请使用诸如optimize-css-assets-webpack-plugin之类的插件。设置Optimization.minimizer会覆盖webpack提供的默认值，因此请确保还指定一个JS最小化器： webpack.config.js 1234567891011121314151617181920212223//压缩js最小化器const TerserJSPlugin = require('terser-webpack-plugin');const MiniCssExtractPlugin = require('mini-css-extract-plugin');const OptimizeCSSAssetsPlugin = require('optimize-css-assets-webpack-plugin');module.exports = &#123; optimization: &#123; //优化项 minimizer: [new TerserJSPlugin(&#123;&#125;), new OptimizeCSSAssetsPlugin(&#123;&#125;)] &#125;, plugins: [ new MiniCssExtractPlugin(&#123; filename: '[name].css', chunkFilename: '[id].css', &#125;), ], module: &#123; rules: [ &#123; test: /\\.css$/, use: [MiniCssExtractPlugin.loader, 'css-loader'], //注意这里不能和style-loader一块使用MiniCssExtractPlugin.loader会将css抽离出来使用link引用 &#125;, ], &#125;,&#125;; babel-loader 我们打包完成以后无法将es6相关语法转换成es5的语法，那么就需要babel插件去辅助我们完成这个操作咯123yarn add -D babel-loader @babel&#x2F;core @babel&#x2F;preset-env&#x2F;&#x2F;@babel&#x2F;core babel核心模块&#x2F;&#x2F;@babel&#x2F;preset-env 转换的模块 webpack.config.js 1234567891011121314module:&#123; rules: [ &#123; test: /\\.js$/, use:[&#123; loader: 'babel-loader', // exclude: /(node_modules|bower_components)/, options:&#123; presets: ['@babel/preset-env'] &#125; &#125;] &#125; ] &#125; 当我们使用一下语法时候123class A&#123; a =1&#125; 我们编译webpack会出错，会告诉你需要什么插件我们对应的进行配置就好了1Add @babel&#x2F;plugin-proposal-class-properties (https:&#x2F;&#x2F;git.io&#x2F;vb4SL) to the &#39;plugins&#39; section of your Babel config to enable transformation. webpack.config.js 1234567891011&#123; test: /\\.js$/, use:[&#123; loader: 'babel-loader', // exclude: /(node_modules|bower_components)/, options:&#123; presets: ['@babel/preset-env'], plugins: ['@babel/plugin-proposal-class-properties'] &#125; &#125;] &#125; 当然babel对一些公共的方法使用了非常小的辅助代码比如 _extend。 默认情况下会被添加到每一个需要它的文件中，可以通过引用 babel runtime 作为一个独立模块，来避免重复引入。详细解释注意：咱们使用es6，es7语法的时候经常需要webpack需要配置该插件哦1yarn add -D @babel&#x2F;plugin-transform-runtime @babel&#x2F;runtime webpack.config.js 123456789101112&#123; test: /\\.js$/, exclude: /(node_modules|bower_components)/, //不包含node_modules include: path.resolve(__dirname,'src'), //包含src下的进行es语法转换 use:[&#123; loader: 'babel-loader', options:&#123; presets: ['@babel/preset-env'], plugins: ['@babel/plugin-proposal-class-properties','@babel/plugin-transform-runtime'] &#125; &#125;] &#125; 还有一些es7的语法是webpack4无法自动转译的比如说：aaa.includes(&#39;a&#39;),这时候我们就需要@babel-polyfill @babel/preset-env默认只转译js语法，而不转译新的API，比如Iterator、Generator、Set、Maps、Proxy、Reflect、Symbol、Promise等全局对象，以及一些定义在全局对象上的方法(比如Object.assign)都不会转译。这时就必须使用@babel/polyfill(内部集成了core-js和regenerator)。1yarn add -D @babel&#x2F;polyfill webpack.config.js 1import 'babel-polyfill' 或者webpack.config.js 1234//不建议使用这种方式，可以采用上面那种方式按需加载，不然polyfill打包以后的文件会很大module.exports = &#123; entry: [\"@babel/polyfill\", \"./app/js\"],&#125; 以上关于babel官方还提供使用.babelrc配置文件的方式配置 123456789101112131415&#123; \"presets\": [ [\"@babel/env\", &#123; \"modules\": false, \"targets\": &#123; \"chrome\": \"64\" &#125; &#125;] ], \"plugins\": [[\"@babel/plugin-transform-runtime\", &#123; \"useBuiltIns\": true // \"polyfill\": false &#125;] ]&#125; 消除没有用到的css123npm -d install purifycss-webpack purify&#x2F;&#x2F;或yarn add -D purifycss-webpack purify webpack.config.js 123456789const glob = require('glob');const PurifyCssPlugin = require('purifycss-webpack');plugins:[ new extractTextPlugin(\"css/index.css\"), new PurifyCSSPlugin(&#123; // Give paths to parse for rules. These should be absolute! paths: glob.sync(path.join(__dirname, 'src/*.html')), &#125;)] 这里配置了一个paths，主要是需找html模板，purifycss根据这个配置会遍历你的文件，查找哪些css被使用了。 注意：使用这个插件必须配合extract-text-webpack-plugin这个插件，这个插件在前边的课程已经讲解过了。如果你还不会请自学一下。 配置好上边的代码，我们可以故意在css文件里写一些用不到的属性，然后用webpack打包，你会发现没用的CSS已经自动给你删除掉了。在工作中记得一定要配置这个plugins，因为这决定你代码的质量，非常有用。 js代码检测eslint1yarn add -D eslint eslint-loader webpack.config.js 123456789&#123; test: /\\.js$/, use:&#123; loader: 'eslint-loader', options:&#123; enforce: 'pre' //前置，在之前先运行，post是后面的意思 &#125; &#125; &#125;, eslintrc.json下载Download .eslintrc.json file with this configuration点击这项进行eslint规则下载，注意，这里生成的文件需要加”.”,下载后可以修改为.eslintrc.json，将此文件拷贝到根目录中即可总结 好了，这篇总结的比较多慢慢消化，主要就是利用webpack针对css/less/sass等css样式，以及图片，字体等加载引入，以及打包优化，将没用到的css进行剔除，以及将css在js或者html中进行抽取出来到单独的css文件中进行维护","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-3","slug":"webpack/一步步的看webpack-3","date":"2020-06-24T02:26:57.000Z","updated":"2020-06-29T09:20:30.253Z","comments":true,"path":"2020/06/24/webpack/一步步的看webpack-3/","link":"","permalink":"http://new.zzpblog.cn/2020/06/24/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-3/","excerpt":"好啦，介绍完webpack到底是干什么的以后呢，我们需要进入正题了，这篇主要介绍webpack的几个重要的概念入口,出口，loader,插件plugins,模式","text":"好啦，介绍完webpack到底是干什么的以后呢，我们需要进入正题了，这篇主要介绍webpack的几个重要的概念入口,出口，loader,插件plugins,模式 入口(entry point) 指示 webpack 应该使用哪个模块，来作为构建其内部依赖图的开始。进入入口起点后，webpack 会找出有哪些模块和库是入口起点（直接和间接）依赖的。每个依赖项随即被处理，最后输出到称之为 bundles 的文件中，可以通过在 webpack 配置中配置 entry 属性，来指定一个入口起点（或多个入口起点）。默认值为 ./src。接下来我们看一个 entry 配置的最简单例子：webpack.config.js 123module.exports = &#123; entry: './path/to/my/entry/file.js'&#125;; 单个入口语法 webpack.config.js 12345678const config = &#123; entry: './path/to/my/entry/file.js' //此写法是下面的写法简写 &lt;!-- entry: &#123; main: './path/to/my/entry/file.js' &#125; --&gt;&#125;;module.exports = config; 当你向 entry 传入一个数组时会发生什么？向 entry 属性传入「文件路径(file path)数组」将创建“多个主入口(multi-main entry)”。在你想要多个依赖文件一起注入，并且将它们的依赖导向(graph)到一个“chunk”时，传入数组的方式就很有用。 对象语法 webpack.config.js 123456const config = &#123; entry: &#123; app: './src/app.js', vendors: './src/vendors.js' &#125;&#125;; 对象语法会比较繁琐。然而，这是应用程序中定义入口的最可扩展的方式。 数组语法 webpack.config.js 123const config = &#123; entry: ['./src/app.js','./src/vendors.js']&#125;; 总结：上面关于对象和数组语法主要是面向多页面应用（MPA）的，在多页应用中，（译注：每当页面跳转时）服务器将为你获取一个新的 HTML 文档。页面重新加载新文档，并且资源被重新下载。然而，这给了我们特殊的机会去做很多事：使用 CommonsChunkPlugin（该插件主要作用就是通过将公共模块拆出来-多个入口情况下，最终合成的文件能够在最开始的时候加载一次） 为每个页面间的应用程序共享代码创建 bundle。由于入口起点增多，多页应用能够复用入口起点之间的大量代码/模块，从而可以极大地从这些技术中受益。 出口（output） output 属性告诉 webpack 在哪里输出它所创建的 bundles，以及如何命名这些文件，默认值为 ./dist。基本上，整个应用程序结构，都会被编译到你指定的输出路径的文件夹中。你可以通过在配置中指定一个 output 字段，来配置这些处理过程：webpack.config.js 12345678const path = require('path');module.exports = &#123; entry: './path/to/my/entry/file.js', output: &#123; path: path.resolve(__dirname, 'dist'), //输出的路径,结合node的path模块 filename: 'my-first-webpack.bundle.js' //输出的文件名 &#125;&#125;; output.filename这里单独说一下filename其他用法此选项决定了每个输出 bundle 的名称。这些 bundle 将写入到 output.path 选项指定的目录下。 对于单个入口起点，filename 会是一个静态名称。 1filename: \"bundle.js\" 然而，当通过多个入口起点(entry point)、代码拆分(code splitting)或各种插件(plugin)创建多个 bundle，应该使用以下一种替换方式，来赋予每个 bundle 一个唯一的名称…… 使用入口名称： 1filename: \"[name].bundle.js\" 使用内部 chunk id 1filename: \"[id].bundle.js\" 使用每次构建过程中，唯一的 hash 生成，可以指定hash生成的长度如：[hash:8] 1filename: \"[name].[hash].bundle.js\" 使用基于每个 chunk 内容的 hash： 1filename: &quot;[chunkhash].bundle.js&quot; 因为 hash 是项目构建的哈希值，项目中如果有些变动，hash 一定会变，比如说我改动了 utils.js 的代码，index.js 里的代码虽然没有改变，但是大家都是用的同一份 hash。hash 一变，缓存一定失效了，这样子是没办法实现 CDN 和浏览器缓存的。 其他配置项 总结：上面是webpack的最基础的配置，输入和输出，当然这里引入了一个chunk的概念，chunk表示一个文件，默认情况下webpack的输入是一个入口文件，输出也是一个文件，这个文件就是一个chunk，chunkId就是产出时给每个文件一个唯一标识id，chunkhash就是文件内容的md5值，name就是在entry中指定的key值。 123456789module.exports = &#123; entry: &#123; collection: './src/main.js' // collection为chunk的名字，chunk的入口文件是main.js &#125;, output: &#123; path: './dist/js', filename: '[name].[chunkhash].[hash:8].js' // 输出到dist/js目录下，以collection+chunk内容的md5值作为输出的文件名 &#125;&#125;; 以上输入输出会出现几个概念，下面做一下总结: 1234567entry:&#123; main:['./src/main.js','./src/test.js'], other:['./src.other.js']&#125;,output:&#123; filename:\"[name].bundle.js\"&#125; main.js中引入了gloabl.css； module main.js、test.js、other.js、global.css都是module entry-point main.js、test.js、other.js chunk main other bundle main.bundle.js other.bundle.jsentry的两个key对应两个chunk，最终会输出两个bundle；main.js、test.js、other.js都是entry-point loader loader 让 webpack 能够去处理那些非 JavaScript 文件（webpack 自身只理解 JavaScript）。loader 可以将所有类型的文件转换为 webpack 能够处理的有效模块，然后你就可以利用 webpack 的打包能力，对它们进行处理。本质上，webpack loader 将所有类型的文件，转换为应用程序的依赖图（和最终的 bundle）可以直接引用的模块。 在更高层面，在 webpack 的配置中 loader 有两个目标： test 属性，用于标识出应该被对应的 loader 进行转换的某个或某些文件。 use 属性，表示进行转换时，应该使用哪个 loader。 webpack.config.js 1234567891011121314const path = require('path');const config = &#123; output: &#123; filename: 'my-first-webpack.bundle.js' &#125;, module: &#123; rules: [ &#123; test: /\\.txt$/, use: 'raw-loader' &#125; ] &#125;&#125;;module.exports = config; 以上配置中，对一个单独的 module 对象定义了 rules 属性，里面包含两个必须属性：test 和 use。这告诉 webpack 编译器(compiler) 如下信息： “嘿，webpack 编译器，当你碰到「在 require()/import 语句中被解析为 ‘.txt’ 的路径」时，在你对它打包之前，先使用 raw-loader 转换一下。” 重要的是要记得，在 webpack 配置中定义 loader 时，要定义在 module.rules 中，而不是 rules。然而，在定义错误时 webpack 会给出严重的警告。为了使你受益于此，如果没有按照正确方式去做，webpack 会“给出严重的警告” 插件(plugins) loader 被用于转换某些类型的模块，而插件则可以用于执行范围更广的任务。插件的范围包括，从打包优化和压缩，一直到重新定义环境中的变量。插件接口功能极其强大，可以用来处理各种各样的任务。想要使用一个插件，你只需要 require() 它，然后把它添加到 plugins 数组中。多数插件可以通过选项(option)自定义。你也可以在一个配置文件中因为不同目的而多次使用同一个插件，这时需要通过使用 new 操作符来创建它的一个实例。 webpack.config.js 1234567891011121314const HtmlWebpackPlugin = require('html-webpack-plugin'); // 通过 npm 安装const webpack = require('webpack'); // 用于访问内置插件const config = &#123; module: &#123; rules: [ &#123; test: /\\.txt$/, use: 'raw-loader' &#125; ] &#125;, plugins: [ new HtmlWebpackPlugin(&#123;template: './src/index.html'&#125;) ]&#125;;module.exports = config; webpack 提供许多开箱可用的插件！查阅我们的插件列表获取更多信息。 模式 通过选择 development 或 production 之中的一个，来设置 mode 参数，你可以启用相应模式下的 webpack 内置的优化123module.exports = &#123; mode: 'production'&#125;; 或1webpack --mode=production 选项 描述 development 会将 process.env.NODE_ENV 的值设为 development。启用 NamedChunksPlugin 和 NamedModulesPlugin。 production 会将 process.env.NODE_ENV 的值设为 production。启用 FlagDependencyUsagePlugin, FlagIncludedChunksPlugin, ModuleConcatenationPlugin, NoEmitOnErrorsPlugin, OccurrenceOrderPlugin, SideEffectsFlagPlugin 和 UglifyJsPlugin.","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-2","slug":"webpack/一步步的看webpack-2","date":"2020-06-23T07:04:57.000Z","updated":"2020-06-29T09:20:31.225Z","comments":true,"path":"2020/06/23/webpack/一步步的看webpack-2/","link":"","permalink":"http://new.zzpblog.cn/2020/06/23/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-2/","excerpt":"前面先接触了一下webpack这个东西，那这个webpack到底是干什么的，为什么要用webpack呢？这篇文章主要讲一讲为什么要用webpack","text":"前面先接触了一下webpack这个东西，那这个webpack到底是干什么的，为什么要用webpack呢？这篇文章主要讲一讲为什么要用webpack 官方的概念 本质上，webpack 是一个现代 JavaScript 应用程序的静态模块打包器(module bundler)。当 webpack 处理应用程序时，它会递归地构建一个依赖关系图(dependency graph)，其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle。 这是说的什么意思呢？其中官方的话有主要的两个概念：1. 打包，2.模块 为什么要打包然后让我们从一个html页面说起，下面的代码可以看到，我在html页面中通过script标签引入了3个JavaScript文件a.js，b.js和c.js，每个文件中分别定义了一个函数并导出（export）给外部用。并且它们之间有一定的依赖关系，c.js依赖于b.js，b.js依赖于a.js。 12345|- index.html|- main.css| - a.js| - b.js| - c.js 1234567891011&#x2F;&#x2F; index.html&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt;&lt;link href&#x3D;&quot;main.css&quot; rel&#x3D;&quot;stylesheet&quot;&gt;&lt;&#x2F;head&gt; &lt;body&gt; &lt;div&gt;hello world&lt;&#x2F;div&gt; &lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;a.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;b.js&quot;&gt;&lt;&#x2F;script&gt; &lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;c.js&quot;&gt;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 1234&#x2F;&#x2F; a.jsexport default function () &#123; return a + b;&#125; 12345&#x2F;&#x2F; b.jsimport add from &#39;a&#39;;export default function (c, d) &#123; return c &#x2F; add(c, d);&#125; 123456&#x2F;&#x2F; c.jsimport percentage from &#39;b&#39;;export default function (e, f) &#123; console.log(percentage(e, f));&#125; 因为有3个js文件，所以浏览器需要发送三次http 请求来获取这三个文件，然后依次执行其中的代码，如果其中有一个文件因为网络问题而延误了时间，那么整个页面的显示也会被延误。3个文件还好，而当我们的项目逐渐变大，有几十个到上百个JavaScript文件的时候，那问题会更严重，不但有延迟问题，还会遇到很难维护的问题 — 想想如何维护上百个文件的依赖关系？ 这时候你会想，是不是我把所有JavaScript文件合成一个文件就好了呢？没错，我们确实可以这样做，这样就减少了http请求数量，让我们的页面加载和显示更快。不过这个合并的阶段是在开发完成之后才进行的，也就是说开发阶段我仍然是有a.js，b.js和c.js等等这些文件的，这样才好开发和维护，因为如果开发阶段就合并的话，就相当于我基于一个可能上万行的文件进行开发，这样的代码是没法维护的。 在开发后完成的这个合并的过程就是打包，这样你就明白为什么要打包了吧。webpack在打包过程中，会分析各个文件之间的依赖关系，然后生成一个依赖图并用文件的形式保存下来，未来浏览器运行代码的时候就可以读取这个文件，就知道了各个代码块之间的关联以及如何调用了。上面只是用JavaScript文件来举例子，实际上webpack可以支持多种文件类型的打包，如css，sass，jpg，svg等等。 什么是模块上面的3个文件，每个文件都可以看做是一个模块，在JavaScript中可以把模块看做是一堆代码，这堆代码可以被复用，执行某个具体的操作，从表象上来看就是一个模块就是一个文件，其中包含了export这样的关键字用来将模块的功能导出给外部用。 12345&#x2F;&#x2F; b.jsimport add from &#39;a&#39;;export default function (c, d) &#123; return c &#x2F; add(c, d);&#125; 从b.js这个文件/模块中就可以看出，首先从a模块中导入了一个函数，然后定义了一个新的函数，并通过export 导出。官方讲解模块 总结打包是webpack最核心的功能，webpack其它所有的功能都是为了让打包这个功能更好。我们从一个简单的html页面介绍了通过webpack对模块进行打包，既保留了单个模块的可维护性，又减少了页面的http请求，减少了页面加载时间，从而增加了页面的显示速度，让整个应用的体验更好。","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【webpack】一步步的看webpack-1","slug":"webpack/一步步的看webpack-1","date":"2020-06-22T07:04:57.000Z","updated":"2020-06-29T09:20:32.516Z","comments":true,"path":"2020/06/22/webpack/一步步的看webpack-1/","link":"","permalink":"http://new.zzpblog.cn/2020/06/22/webpack/%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9A%84%E7%9C%8Bwebpack-1/","excerpt":"本文主要从最新的webpack4入手，慢慢的学习webpack的相关知识点，进行汇总","text":"本文主要从最新的webpack4入手，慢慢的学习webpack的相关知识点，进行汇总 第一次轻轻的接触 webpack官网地址 github地址 使用webpack前提条件 环境准备 node,使用官方最新版本即可，由于webpack这里使用的是4，不再支持node v4一下的版本，所以node需要安装V4+的版本，这是因为新的webpack和附属插件使用了es6的语法，v4版本对es6不是很到位，所以，就不伺候了 本地安装最新的webpack版本是：v4.43.0 要安装最新版本或特定版本，请运行以下命令之一： 123//这里需要安装webpack-cli，官方给出webpack4以上版本需要使用到`webpack-cli`cnpm install --save-dev webpack webpack-cli //yarn add -D webpack webpack-clicnpm install --save-dev webpack@&lt;version&gt; 当你在本地安装 webpack 后，你能够从 node_modules/.bin/webpack 访问它的 bin 版本。使用./node_modules/.bin/webpack运行即可 由于还需要访问node_modules,这里我们使用linux命令指定别名进行运行webpack alias webpack=&quot;node_modules/.bin/webpack&quot; windows的话可以暂时放到环境变量中 全局安装以下的 NPM 安装方式，将使 webpack 在全局环境下可用： 1cnpm install --global webpack 不推荐全局安装 webpack。这会将你项目中的 webpack 锁定到指定版本，并且在使用不同的 webpack 版本的项目中，可能会导致构建失败。 跑一个小例子感受一下 src/index.js 123import bar from &#39;.&#x2F;bar&#39;;bar(); src/bar.js 123export default function bar() &#123; &#x2F;&#x2F;&#125; webpack.config.js 123456789const path &#x3D; require(&#39;path&#39;);module.exports &#x3D; &#123; entry: &#39;.&#x2F;src&#x2F;index.js&#39;, output: &#123; path: path.resolve(__dirname, &#39;dist&#39;), filename: &#39;bundle.js&#39; &#125;&#125;; page.html 12345678910&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt; ... &lt;&#x2F;head&gt; &lt;body&gt; ... &lt;script src&#x3D;&quot;dist&#x2F;bundle.js&quot;&gt;&lt;&#x2F;script&gt; &lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 然后在命令行运行 webpack 就会创建 bundle.js。 1234567891011121314151617Version: webpack 4.43.0Time: 82msBuilt at: 2020&#x2F;06&#x2F;22 下午5:20:25 Asset Size Chunks Chunk Namesbundle.js 951 bytes 0 [emitted] mainEntrypoint main &#x3D; bundle.js[0] .&#x2F;src&#x2F;index.js + 1 modules 72 bytes &#123;0&#125; [built] | .&#x2F;src&#x2F;index.js 32 bytes [built] | .&#x2F;src&#x2F;bar.js 40 bytes [built]&#x2F;&#x2F;这里会报WARNING，是webpack4后新增了&#96;development&#96;、&#96;production&#96;和&#96;none&#96;环境变量的指定，既然官方推荐了我们可以加一下&#x2F;&#x2F;.&#x2F;node_modules&#x2F;.bin&#x2F;webpack --mode productionWARNING in configurationThe &#39;mode&#39; option has not been set, webpack will fallback to &#39;production&#39; for this value. Set &#39;mode&#39; option to &#39;development&#39; or &#39;production&#39; to enable defaults for each environment.You can also set it to &#39;none&#39; to disable any default behavior. Learn more: https:&#x2F;&#x2F;webpack.js.org&#x2F;configuration&#x2F;mode&#x2F; 官方教程","categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"}]},{"title":"【随笔】BIC工具","slug":"article/BIC工具","date":"2020-06-18T04:04:57.000Z","updated":"2020-06-18T04:05:27.242Z","comments":true,"path":"2020/06/18/article/BIC工具/","link":"","permalink":"http://new.zzpblog.cn/2020/06/18/article/BIC%E5%B7%A5%E5%85%B7/","excerpt":"生活中批评员工的机会会有很多，那么有没有人因为批评的技巧有问题，导致你想批评员工，借此机会帮助员工，结果对方越来越糟糕了，或者对方跟你对着干，对方情绪越来越坏？我们在批评的时候最大的难点在情绪管理。很多人跟被批评的人说过这样的话：“我这个人是对事不对人。”但是真的能做到对事不对人吗？老板有时候还会补充：“我的确是对事不对人，但是事都是人做的。”","text":"生活中批评员工的机会会有很多，那么有没有人因为批评的技巧有问题，导致你想批评员工，借此机会帮助员工，结果对方越来越糟糕了，或者对方跟你对着干，对方情绪越来越坏？我们在批评的时候最大的难点在情绪管理。很多人跟被批评的人说过这样的话：“我这个人是对事不对人。”但是真的能做到对事不对人吗？老板有时候还会补充：“我的确是对事不对人，但是事都是人做的。” 对事不对人是一个境界，这是东方式的管理，但是管理者没法做到。西方的办法一定是给你一个工具，用这个工具来讲话，你就能够做到对事不对人。这个工具叫做BIC（Behavior has impact which leads to consequence, 你的某一个行为，产生了什么样的影响，从而会导致什么样的后果？），这个工具就叫做BIC。 第一部分：B（事实） 首先B代表当我要求你说出对方一个错误的行为的时候，我们有两种表达方式，一种叫做事实，一种叫做观点。那么当我们要说出对方一个错误的行为的时候，应该说事实还是应该说观点？大家都认为应该说事实，但是经常出问题在哪呢？我们很多管理者分不清事实和观点，我们经常把自己的观点当作是事实，比如：“小张，你最近的工作状态不太好。”这是一个观点，你如果是小张的话，你听了会觉得不高兴，再换一个，说：“我觉得你做工作不够投入。”这也是观点，让人听了很不舒服。再比如：“小张你最近经常迟到。”仍然还是观点。如果你是小张，你被别人说经常迟到很不爽，所以当加入“经常”这个词的时候，把一个事实变成了一个观点，因为这代表着我不喜欢你。 那么什么叫事实？比如：“小张，我看了一下考勤记录，上周你有三个迟到记录。今天早上咱们九点钟上课，你进教室的时候是9点半。”这是一个事实对吗？我有没有说你是一个坏员工？我有没有说你为什么迟到的？没有，我只是看到了这么一个现象而已，所以当简单的讲出一个现象的时候，你发现对方的情绪不容易起伏，而当你说你怎么上课这么喜欢迟到，对方情绪马上就起来了，你是不是不重视我的课呢？推理阶梯就已经出现了。所以我们平常跟人谈话的时候，是什么让我们的谈话变得很艰难？是我们一张口就已经伤了人了，所以一定要能够学会把你想要表达的观点改成事实。 第二部分：I（影响） 接下来I叫做影响，影响就是短期的，局部的就能够看到的负面结果，一定要跟这个人自身的利益挂钩。为什么要跟这个人自身的利益挂钩呢？因为他会重视。更重要的是一个人长期犯错，最终会影响到的一定是他自己，这是原理。我们跟员工谈话的唯一目的是为了帮助他，你得挽回他，帮助他，所以既然你要表达，你想帮他，就得让他感受到你想帮他，怎么才能让他感受到你想帮他呢？你可以说：“这样下去话，我担心咱们的班风会涣散，不利于咱们这次培训的效果，而且也不利于你在咱班的形象。”这是跟他的利益挂钩，这个叫做BIC。 到此为止，我没有说过你迟到的原因，没有给他扣过任何帽子，所以接下来我们就要去问他，为什么会出现这样的情况，允许员工去解释，所以BIC能够有效的去把你的观点以及你对这件事未来的担心讲出来。 2008年我第一次代表IBM去海尔上这个课程，IBM派了一些人在后边听我们讲课，那天我给海尔上的是团队那部分内容，带大家玩团队的游戏，玩完了以后大家很开心，都觉得很棒，给我的反馈很不错，我觉得很好，第一次上课就成功了。 晚上回到酒店， IBM的人打电话给我，他说：“樊老师，请问你有没有时间？关于今天上午上课有些内容，我想给你做一个反馈。”我一听这个我就知道我上课过程中有问题了。他接着说：“樊老师，今天早上你在讲团队那部分的时候，你是这样说的……”他把我的原话记了下来，然后给我念了一遍。这是事实，事实就是一个发生过的事儿。他把我的原话重复了一遍，这时候我不会生气，因为对方说的是我的原话。他把原话给念完了，然后接着说：“我观察到学生在做游戏的时候，并没有体会到您说的这几点。您把这个东西讲给他们听，会影响到他们对于已有的知识点的接收。”这是对这个班的影响，IBM的人认为我讲多了，讲的不是游戏当中体会到的东西，影响到学员对知识点的接收了。 第三部分：C（后果） 接下来到C了，也就是结论。IBM的人接着说：“这样下去的话，我们担心这门课程在中国的传播会变味，而且也不利于您成为一名优秀的facilitator（引导师）。” 不利于课程在中国传播这个结论是跟全局挂钩，不利于我我成为优秀的引导师是跟我挂钩。最后说：“那么樊老师，我想听听您的意见。”这时候我能有什么意见？人家说的很客观，而且也很诚恳。我回应到：“你说的有道理，我确实还是这个习惯，喜欢多讲，没有观察学生的反应，你这个提醒的特别到位，我回头一定会注意，我要更多的提问，观察学生的感受。”他说：“不，樊老师，您的讲课是很有特色的，你讲的真的挺好的，学生的反应也很好，所以如果您有什么独特的设计的话，请您一定告诉我们，如果你想改这门课程，我们可以给美国总部打报告，可以改这门课。”我说：“不用改课程，是我应该改变。”，我们俩客气了半天，最后结束。 通过这次反馈，我知道我讲课效果还不错，也很开心的去注意做facilitation。所以过了很多年以后，我们再一次见面，我还跟他说起这件事，感谢当年他对我的帮助。经过了这么一次负面反馈，我们俩的关系没有变得更糟糕，反倒拉近了，因为你知道人家做这个事是为了我，为了整个的团队，而且人家的水平很高，一般的学生听不出来，人家是高手，一听都听明白了，所以我就对人很尊敬，然后保持良好的关系，这就告诉我们，并不是所有的负面反馈都会伤害人。 良好的负面反馈一样会带来扩大公开象限的效果，会让员工觉得老板说话真有道理。IBM这样老牌的帝国公司，可怕在他们所有的人都是这样说话的，不是只有这总监一个人会这样说话。总监后来被挖到埃森哲就走了，换了一个年轻人上来接着干也是一样。他们入职第一天所受到的训练就是这些东西。表扬人就是二级反馈。批评人就BIC，开会就六顶思考帽，头脑风暴，布置工作说五遍，他永远有一大堆的方法放在那，所以这些人都被规规矩矩地塑造成了职业经理人。谁走了他都能够接着干，所以你们跟这些国外公司打交道，你会发现跟他们的老总说话和他们底下人说话感觉差别不大，因为都是套路。我们中国的企业从小做到大，这个是蛮快的，从无到有，从小到大是蛮快，但是从大做到巨大，是非常困难的。因为我们做到大，还能够勉强靠这些人的这种力量在维持，但是一旦做到超大，做到像可口可乐这样的规模就不行，所以我们的企业做到强大还有很长的距离，标准化是非常重要的一个过程。 不是要把大家的思想禁锢起来标准化，而是我们的沟通模式。沟通模式一旦标准化以后，你发现就跟早上我们开会一样，就会觉得很省劲，所以把BIC一定要学会。 作者：刘思彤班长链接：https://www.jianshu.com/p/0c7ba0c06939来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://new.zzpblog.cn/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://new.zzpblog.cn/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"【随笔】人生随笔","slug":"article/人生随笔","date":"2020-06-12T02:50:57.000Z","updated":"2020-06-12T05:48:54.688Z","comments":true,"path":"2020/06/12/article/人生随笔/","link":"","permalink":"http://new.zzpblog.cn/2020/06/12/article/%E4%BA%BA%E7%94%9F%E9%9A%8F%E7%AC%94/","excerpt":"人的一生或多或少都会经历各样的选择，不同的选择决定着走向不同的道路","text":"人的一生或多或少都会经历各样的选择，不同的选择决定着走向不同的道路 人生这一辈子其实很短暂，现在的我已经快本三了，经历了困惑，做了很多错误的选择，如果有机会让我重新来过，那会不会是不一样的人生呢？在刚出生，到上大学，其实这段时间是无法去主动选择的，大部分的人都是经历了一样的过程，上学，学习，写作业等等，其实也是人生必经阶段，当然出生的环境会影响人的人生轨迹，但是所有人生下来的环境是自己无法去选择的，只能去接受，那么当自己成年，或者以后有了自己的生活，那会面临这无数的选择，据说人的一天会面临4万多次选择，所有的事情在你不经意间你已经做出了选择，那么在点点滴滴就会影响着自己的人生道路，人生本身就是有起有落，人生不能重来，之前的选择都已经作废，接下来的选择才能决定你人生的走向，至于接下来的路怎么走，怎么选择，看你自己！结婚，生子，工作将是接下来的走向，但是这个走向到底是越走越好，还是越走越不开心，在人生的岔路口要谨慎选择，往往在不经意间做了错误的选择，则会走向你不想面对的人生，人生就像选择题，或者是一场赌注，谁也不知道做了选择以后会发生什么，这样的人生才有意思不是么，很简单一个道理，怎么活看自己，怎么选择不一样的人生看自己，所以有些事情是自己可以决定也可以选择的，只是看你愿意不愿意，加油吧，骚年～","categories":[{"name":"随笔","slug":"随笔","permalink":"http://new.zzpblog.cn/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://new.zzpblog.cn/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Kubernetes基础","slug":"kubernetes/kubernetes1","date":"2020-06-11T01:55:57.000Z","updated":"2020-06-11T06:02:44.859Z","comments":true,"path":"2020/06/11/kubernetes/kubernetes1/","link":"","permalink":"http://new.zzpblog.cn/2020/06/11/kubernetes/kubernetes1/","excerpt":"主要说明Kubernetes中每个控制器说明和使用场景","text":"主要说明Kubernetes中每个控制器说明和使用场景 什么是控制器 Kubernetes 中内建了很多 controller(控制器)，这些相当于一个状态机，用来控制 Pod 的具体状态和行为 控制器类型 ReplicationController 和 ReplicaSet Deployment DaemonSet StateFulSet Job/CronJob Horizontal Pod Autoscaling ReplicationController 和 ReplicaSet ReplicationController(RC)用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代;而如果异常多出来的容器也会自动回收;在新版本的 Kubernetes 中建议使用 ReplicaSet 来取代 ReplicationController 。ReplicaSet 跟ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector; Deployment Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义 (declarative) 方法，用来替代以前的 ReplicationController 来方便的管理应用。典型的应用场景包括; 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续 Deployment DaemonSetDaemonSet 确保全部(或者一些)Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod 使用 DaemonSet 的一些典型用法: 运行集群存储 daemon，例如在每个 Node 上运行 glusterd 、 ceph 在每个 Node 上运行日志收集 daemon，例如 fluentd 、 logstash 在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd` 、Datadog 代理、 **New Relic 代理，或 Ganglia gmond Job Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束 CronJob Cron Job 管理基于时间的 Job，即: 在给定时间点只运行一次 周期性地在给定时间点运行 使用前提条件:当前使用的 Kubernetes 集群，版本 &gt;= 1.8(对 CronJob)。对于先前版本的集群，版本 &lt; 1.8，启动 API Server时，通过传递选项 --runtime-config=batch/v2alpha1=true 可以开启 batch/v2alpha1 API** 典型的用法如下所示: 在给定的时间点调度 Job 运行 创建周期性运行的 Job，例如:数据库备份、发送邮件 StatefulSetStatefulSet 作为 Controller 为 Pod 提供唯一的标识。它可以保证部署和 scale 的顺序StatefulSet是为了解决有状态服务的问题(对应Deployments和ReplicaSets是为无状态服务而设计)，其应用 场景包括: 稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service(即没有 Cluster IP的Service)来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行(即从0到 N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态)，基于init containers来实 现 有序收缩，有序删除(即从N-1到0) Horizontal Pod Autoscaling 应用的资源使用率通常都有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，让service中的Pod 个数自动调整呢?这就有赖于Horizontal Pod Autoscaling了，顾名思义，使Pod水平自动缩放","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://new.zzpblog.cn/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://new.zzpblog.cn/tags/Kubernetes/"}]},{"title":"zz胖博客大改版","slug":"hello-world","date":"2020-06-10T05:58:30.901Z","updated":"2020-06-10T08:50:26.209Z","comments":true,"path":"2020/06/10/hello-world/","link":"","permalink":"http://new.zzpblog.cn/2020/06/10/hello-world/","excerpt":"","text":"最近工作不是很忙，对自己的博客来个大升级，更方便维护和阅读","categories":[],"tags":[]},{"title":"[Node] nodejs-mongoose","slug":"node/nodejs-mongoose","date":"2019-05-30T07:50:57.000Z","updated":"2020-06-10T09:15:33.479Z","comments":true,"path":"2019/05/30/node/nodejs-mongoose/","link":"","permalink":"http://new.zzpblog.cn/2019/05/30/node/nodejs-mongoose/","excerpt":"nodejs-mongoose关于mongoose返回对象的处理看这里","text":"nodejs-mongoose关于mongoose返回对象的处理看这里","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] Express-路由 ","slug":"Express/Express-路由","date":"2019-05-29T06:50:57.000Z","updated":"2020-06-10T09:14:52.693Z","comments":true,"path":"2019/05/29/Express/Express-路由/","link":"","permalink":"http://new.zzpblog.cn/2019/05/29/Express/Express-%E8%B7%AF%E7%94%B1/","excerpt":"Express-路由 什么是路由简单磊说,咱们都用过路由器,那就是路由,比如门牌号地址,这也是路由,最简单的,url路径,其实就是路由","text":"Express-路由 什么是路由简单磊说,咱们都用过路由器,那就是路由,比如门牌号地址,这也是路由,最简单的,url路径,其实就是路由","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] Express静态服务 ","slug":"Express/Express静态服务","date":"2019-05-29T06:50:57.000Z","updated":"2020-06-10T09:14:59.515Z","comments":true,"path":"2019/05/29/Express/Express静态服务/","link":"","permalink":"http://new.zzpblog.cn/2019/05/29/Express/Express%E9%9D%99%E6%80%81%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"Express静态服务 很简单看下面代码 123456789101112131415//公开指定目录,下列方式就可以访问项目下public下的文件了/** * 个人推荐咯 * 当以/public/开头请求路径, 就回去./public/目录中查找对应的资源,也就是第一个参数是请求路径,第二个是对应的文件位置相对路径 * 访问路径 http://localhost:3000/public/xxx */app.use('/public/',express.static('./public/'))&lt;!-- more --&gt;//当省略第一个参数的时候,则可以通过省略/public/的方式访问,也就是直接访问/跟路径,没有代表的就是///访问路径 http://localhost:3000/xxxapp.use(express.static('./public/'))//访问路径 http://localhost:3000/a/xxxapp.use('/a/',express.static('./public/')) 剩下的看文档咯,很简单 文档","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] Express简介 ","slug":"Express/Express简介","date":"2019-05-29T06:50:57.000Z","updated":"2020-06-10T09:14:57.365Z","comments":true,"path":"2019/05/29/Express/Express简介/","link":"","permalink":"http://new.zzpblog.cn/2019/05/29/Express/Express%E7%AE%80%E4%BB%8B/","excerpt":"Express简介 原生的node中http在某些方面已经不足以应对我们的开发需求,所以我们就需要使用框架来加快我们开发效率了,框架目的就是开发效率","text":"Express简介 原生的node中http在某些方面已经不足以应对我们的开发需求,所以我们就需要使用框架来加快我们开发效率了,框架目的就是开发效率 所以Express终于来啦,当然现在出了新的框架Koa2,以后我会继续加入这一部分啦,最近先整理一下Express的内容 Express官网 好吧,这个框架的作者https://github.com/tj,这哥们还是很牛逼啊","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] Express-HelloWord ","slug":"Express/Express-HelloWord","date":"2019-05-29T06:50:57.000Z","updated":"2020-06-10T09:21:03.028Z","comments":true,"path":"2019/05/29/Express/Express-HelloWord/","link":"","permalink":"http://new.zzpblog.cn/2019/05/29/Express/Express-HelloWord/","excerpt":"Express-HelloWord来吧,万事开头helloword","text":"Express-HelloWord来吧,万事开头helloword 安装 创建目录12$ mkdir myapp$ cd myapp 初始化1$ npm init 安装Express1$ npm install express --save 创建app.js文件 12345678910111213const express = require('express')//创建server ,node原生是http.createServer()const app = express()//公开指定目录,下列方式就可以访问项目下public下的文件了app.use('/public/',express.static('./public/'))//当服务器收到get请求时,路径为/的时候会调用这个方法app.get('/', function (req, res) &#123; res.send('hello express')&#125;)app.listen(3000,function () &#123; console.log(\"server is running:\"+3000)&#125;) 运行 node app.js 修改完代码自动重启,热加载 简单直接一个工具nodemon 安装cnpm install --global nodemon 查看是否安装成功nodemon --version 使用nodemon app.js 这样修改完js文件它就会自动加载啦,不用每次重启啦","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs-其他成员","slug":"node/nodejs-其他成员","date":"2019-05-29T06:50:57.000Z","updated":"2020-06-10T09:15:22.380Z","comments":true,"path":"2019/05/29/node/nodejs-其他成员/","link":"","permalink":"http://new.zzpblog.cn/2019/05/29/node/nodejs-%E5%85%B6%E4%BB%96%E6%88%90%E5%91%98/","excerpt":"nodejs-其他成员 除了require、exports 等相关api之外，还有两个特殊的成员 __dirname:动态获取可以获取当前文件模块所属目录的绝对路径 __filename:动态获取可以获取当前文件的绝对路径12&#x2F;home&#x2F;zzp&#x2F;express-demo-project &#x2F;&#x2F;__dirname&#x2F;home&#x2F;zzp&#x2F;express-demo-project&#x2F;demo.js &#x2F;&#x2F;__filename","text":"nodejs-其他成员 除了require、exports 等相关api之外，还有两个特殊的成员 __dirname:动态获取可以获取当前文件模块所属目录的绝对路径 __filename:动态获取可以获取当前文件的绝对路径12&#x2F;home&#x2F;zzp&#x2F;express-demo-project &#x2F;&#x2F;__dirname&#x2F;home&#x2F;zzp&#x2F;express-demo-project&#x2F;demo.js &#x2F;&#x2F;__filename 有啥好处呢？ 在文件操作中，使用相对路径是不可靠的，因为在Node中文件操作的路径被设计为相对与执行node命令所处的路径所以为了解决这个问题，很简单，将相对路径变为绝对路径所以例子来咯 123fs.readfile(path.join(__dirname,'./a.txt'),'utf-8',function()&#123;&#125;) 所以强烈要求大家，以后操作相对路径的时候，都要用上面说的动态路径的方式哦当然require中的相对路径是不受影响的哈，模块中的路径标识就是相对于当前文件模块，不受执行node命令所处路径的影响","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs-path","slug":"node/nodejs-path","date":"2019-05-28T06:50:57.000Z","updated":"2020-06-10T09:15:35.926Z","comments":true,"path":"2019/05/28/node/nodejs-path/","link":"","permalink":"http://new.zzpblog.cn/2019/05/28/node/nodejs-path/","excerpt":"nodejs-path做什么用的 专门用来操作路径的 具体的函数看这里吧nodejs-path","text":"nodejs-path做什么用的 专门用来操作路径的 具体的函数看这里吧nodejs-path","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] npm与package.json","slug":"node/npm与package.json","date":"2019-05-24T05:50:57.000Z","updated":"2020-06-10T09:15:48.116Z","comments":true,"path":"2019/05/24/node/npm与package.json/","link":"","permalink":"http://new.zzpblog.cn/2019/05/24/node/npm%E4%B8%8Epackage.json/","excerpt":"npm与package.jsonpackage.json 我们建议每一个项目都要有一个package.json文件 package.json 包描述文件(包的说明书) 可以描述自己的项目依赖了哪些第三方包 --save 放在包名之前和之后都可以,会保存dependencies依赖项 dependencies 依赖的意思 package.json 可以通过命令 npm init方式创建,过程是以向导方式一步步设置,这个就不说啦,傻瓜式的呢,要是真是傻瓜的话,那就回车回车啦! 生成以下文件","text":"npm与package.jsonpackage.json 我们建议每一个项目都要有一个package.json文件 package.json 包描述文件(包的说明书) 可以描述自己的项目依赖了哪些第三方包 --save 放在包名之前和之后都可以,会保存dependencies依赖项 dependencies 依赖的意思 package.json 可以通过命令 npm init方式创建,过程是以向导方式一步步设置,这个就不说啦,傻瓜式的呢,要是真是傻瓜的话,那就回车回车啦! 生成以下文件 1234567891011&#123; \"name\": \"npmtest\", //项目名称 \"version\": \"1.0.0\",//版本号 \"description\": \"\",//描述 \"main\": \"index.js\",//项目主入口 \"scripts\": &#123; //scripts脚本 \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\" &#125;, \"author\": \"\", //作者 \"license\": \"ISC\" //证书&#125; 安装个jquery包试一下运行 npm install jquery --save 1234567891011121314&#123; \"name\": \"npmtest\", //项目名称 \"version\": \"1.0.0\",//版本号 \"description\": \"\",//描述 \"main\": \"index.js\",//项目主入口 \"scripts\": &#123; //scripts脚本 \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\" &#125;, \"author\": \"\", //作者 \"license\": \"ISC\", //证书 \"dependencies\": &#123; //依赖 \"jquery\": \"^3.4.1\" &#125;&#125; 总的来说这个package.json有啥用呢,其实简单来说,当你安装完包以后会生成node_modules文件夹,当你删除这个文件夹以后,可以直接在命令行运行npm install 他就会根据package.json中配置的依赖,自动安装了,不会出现找不到安装的包 npm npm网站,这个就相当于dockerhub官方的私服,maven的资源仓库,也就是有自己的第三方包也可以发布到上面 常用命令12npm --version &#x2F;&#x2F;查看版本npm install --global npm &#x2F;&#x2F;升级npm版本 npm init //初始化package.json npm init -y //跳过向导,快速生成 npm install 包名 //只下载 npm i 包名 //简写 npm install --save 包名 //下载并且保存依赖到package.json npm install -S 包名 npm uninstall --save 包名 //删除依赖删除包 npm un -S 包名 //简写 npm help //查看帮助 当然啦,npm你运行一下会发现,下载超级慢的,因为要翻墙,所以出现了cnpm,大家可以用cnpm命令也一样的,当然最近新出了一些其他的比如说yarn,都类似,看大家使用咯,以后会整理yarn方面的,敬请期待吧 global代表全局下的安装,以后使用在哪个项目中都可以使用到1npm install --global cnpm","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] js代码风格代码规范","slug":"node/js代码风格代码规范","date":"2019-05-23T07:50:57.000Z","updated":"2020-06-10T09:15:19.986Z","comments":true,"path":"2019/05/23/node/js代码风格代码规范/","link":"","permalink":"http://new.zzpblog.cn/2019/05/23/node/js%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/","excerpt":"js代码风格代码规范 常见的规范:JavaScript Standard StyleAirbnb JavaScript Style","text":"js代码风格代码规范 常见的规范:JavaScript Standard StyleAirbnb JavaScript Style 无分号代码风格 当你采用了无分号代码风格的时候,只要注意一下情况,就不会有问题 当一行代码是以 ( [ ` 开头的时候,则在前面不上一个分号以免语法错误","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs-exports","slug":"node/nodejs-exports","date":"2019-05-23T06:50:57.000Z","updated":"2020-06-10T09:15:24.980Z","comments":true,"path":"2019/05/23/node/nodejs-exports/","link":"","permalink":"http://new.zzpblog.cn/2019/05/23/node/nodejs-exports/","excerpt":"nodejs-exports 简单来说exports就是导出 对于希望可以被其他模块访问的成员,我们就需要把这些公开的成员都挂载到exports接口对象中就可以了 导出多个成员(对象中)","text":"nodejs-exports 简单来说exports就是导出 对于希望可以被其他模块访问的成员,我们就需要把这些公开的成员都挂载到exports接口对象中就可以了 导出多个成员(对象中) 1234567exports.a = 123exports.c = function()&#123;&#125;exports.e = () =&gt; console.log('bar')exports.d = &#123; foo: 'bar'&#125; 导出单个成员(函数,字符串) 1module.exports = 'hello' 下面情况会覆盖(函数会覆盖掉hello字符串) 12module.exports = 'hello'module.exports = function()&#123;&#125; module也可以导出多个成员 123456module.exports = &#123; add: function()&#123; &#125;, str: 'hello'&#125; 到底怎么回事呢,我来解析一下,上面两种方式有什么区别呢 你可以认为在每一个模块内部都有一个自己的module对象 123var module = &#123;&#125; 该module对象中,有一个成员叫:exports 12345var module = &#123; exports: &#123; &#125;&#125; 默认在代码最后一句:所以谁require我,谁就能得到这个哦 1return module.exports 也就是说如果你需要对外导出成员,只需要把导出的成员挂载到module.exports中 1module.exports.foo = 'bar' 但是我们发现每次导出接口成员都要通过module.exports.xxx的方式,特别麻烦所以node为了简化操作,专门提供了一个变量 exports = module.exports 1var exports = module.exports 所以呢 1console.log(exports === module.exports) 注意!!!当一个模块要导出单个成员的时候,直接给exprots是不管用的!! 12//不管用exprots = 'hello' 原因是: 12//exports只是module.exports的一个引用而已,如果不清楚的话,那就看看js对象引用相关的内容吧var exports = module.exports 注意:给exports赋值会断开 exports与module.exports之间的引用","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs-require","slug":"node/nodejs-require","date":"2019-05-23T06:50:57.000Z","updated":"2020-06-10T09:15:38.380Z","comments":true,"path":"2019/05/23/node/nodejs-require/","link":"","permalink":"http://new.zzpblog.cn/2019/05/23/node/nodejs-require/","excerpt":"nodejs-require 简单来说require就是加载 语法1234var 自定义变量名称 = require('模块')//模块:核心模块//第三方模块//自定义模块","text":"nodejs-require 简单来说require就是加载 语法1234var 自定义变量名称 = require('模块')//模块:核心模块//第三方模块//自定义模块 执行被加载模块中的代码 当然它会优先在缓存加载(多个文件重复引用require模块的时候) 得到加载模块中的exports导出的接口对象 require可以省略后缀名.js require相对路径中./ 不能省略,否则会报错 在node中,没有全局作用于,只有模块作用于 外部访问不到内部 内部也访问不到外部 关于require(‘模块/路径/第三方包’) 路径形式的模块./(当前目录),../(上一级目录),/xxx,/,绝对路径C:/ 核心模块: 本质也是文件,只不过该核心模块的文件已经加载到二进制文件中了,可以在源码中找到哦 第三方包: 凡是第三方的模块都必须通过npm或者cnpm/yarn来安装,可以通过require(&#39;包名&#39;)方式来加载 先找到node_modules/xxx模块 node_modules/xxx/package.json文件 node_modules/xxx/package.json 文件中的main属性 main属性记录了xxx入口模块 如果没有package.json也没有main指定入口也没有,则node会自动找该目录下的index.js,如果上面说的都没有,则会进入上一级目录中的node_modules目录查找,如果上一级还没有,则继续往上上级找,如果还没找到则会报错can node find module xxx 注意!!咱们一个项目中有且只有一个node_modules文件夹哦,别多想了,人家就一个想了解更多的node的底层 看这里@by &lt;&lt;深入浅出nodejs&gt;&gt;","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] 关于nodejs中的http请求(2)","slug":"node/nodejs-http(2)","date":"2019-05-23T05:50:57.000Z","updated":"2020-06-10T09:15:31.625Z","comments":true,"path":"2019/05/23/node/nodejs-http(2)/","link":"","permalink":"http://new.zzpblog.cn/2019/05/23/node/nodejs-http(2)/","excerpt":"关于nodejs中的http请求(2) 在服务端默认发送的数据,其实是utf8编码的内容,但是浏览器并不知道你是utf8的内容,浏览器在不知道服务器响应内容的编码情况下,它会默认当前操作系统编码去解析,中文操作系统默认是gbk解决方法就是正确的告诉浏览器给你发送的内容是什么编码,那怎么告诉浏览器呢,看下面代码吧..","text":"关于nodejs中的http请求(2) 在服务端默认发送的数据,其实是utf8编码的内容,但是浏览器并不知道你是utf8的内容,浏览器在不知道服务器响应内容的编码情况下,它会默认当前操作系统编码去解析,中文操作系统默认是gbk解决方法就是正确的告诉浏览器给你发送的内容是什么编码,那怎么告诉浏览器呢,看下面代码吧.. 123456789101112131415161718var http = require('http')var server = http.createServer()var hostname = '127.0.0.1'var port = 3000server.on('request', (request,response)=&gt;&#123; console.log(`收到客户端请求,请求路径:$&#123;request.url&#125;`); response.statusCode = 200; response.setHeader('Content-Type', 'text/html;charset=utf-8'); response.write('response输出内容'); response.write('response输出内容22'); response.end('Hello World\\n');&#125;)server.on()server.listen(port,hostname,()=&gt;&#123; console.log(`Server running at http://$&#123;hostname&#125;:$&#123;port&#125;/`);&#125;) 上边的代码是不是很熟悉呢,没错,就是http(1)中的代码.但是不一样的,请看response.setHeader(&#39;Content-Type&#39;, &#39;text/html;charset=utf-8&#39;);,这一段代码就是给响应头增加Content-Type来指定内容类型,在http协议中Content-Type,就是告知对方给你发送的数据类型,当然类型不止是text/html当然我们常说的编码,是针对字符的编码,所以图片什么的,不需要这东西的 普通文本 text/plain html text/html ,这样浏览器会将内容当成html去解析 … 还有很多很多哦,去这里自己查吧 http://tool.oschina.net/commons","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] 关于nodejs中的http请求(1)","slug":"node/nodejs-http(1)","date":"2019-05-22T06:50:57.000Z","updated":"2020-06-10T09:15:28.777Z","comments":true,"path":"2019/05/22/node/nodejs-http(1)/","link":"","permalink":"http://new.zzpblog.cn/2019/05/22/node/nodejs-http(1)/","excerpt":"关于nodejs中的http请求(1) request request应该都有了解,他其实就是请求对象,通过这个请求对象,可以获取客户端请求过来的一些信息,比如请求路径 request有很多属性 url,返回请求路径后缀比如 http://localhost:3000/test,这里返回的就是/test response response当然是响应对象了,通过这个响应对象可以返回信息给客户端 response要使用end来结束响应,不然客户端会一直等待","text":"关于nodejs中的http请求(1) request request应该都有了解,他其实就是请求对象,通过这个请求对象,可以获取客户端请求过来的一些信息,比如请求路径 request有很多属性 url,返回请求路径后缀比如 http://localhost:3000/test,这里返回的就是/test response response当然是响应对象了,通过这个响应对象可以返回信息给客户端 response要使用end来结束响应,不然客户端会一直等待 123456789101112131415161718var http = require('http')var server = http.createServer()var hostname = '127.0.0.1'var port = 3000server.on('request', (request,response)=&gt;&#123; console.log(`收到客户端请求,请求路径:$&#123;request.url&#125;`); response.statusCode = 200; response.setHeader('Content-Type', 'text/plain'); response.write('response输出内容'); response.write('response输出内容22'); response.end('Hello World\\n');&#125;)server.on()server.listen(port,hostname,()=&gt;&#123; console.log(`Server running at http://$&#123;hostname&#125;:$&#123;port&#125;/`);&#125;)","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] 服务端渲染与客户端渲染","slug":"node/服务端渲染与客户端渲染","date":"2019-05-21T07:56:57.000Z","updated":"2020-06-10T09:15:12.374Z","comments":true,"path":"2019/05/21/node/服务端渲染与客户端渲染/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B8%B2%E6%9F%93%E4%B8%8E%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%B8%B2%E6%9F%93/","excerpt":"服务端渲染与客户端渲染 服务端渲染 说白了,就是在服务端使用模板引擎末班引擎最早诞生于服务端,后来才到了前端 服务端和客户端渲染的区别是什么","text":"服务端渲染与客户端渲染 服务端渲染 说白了,就是在服务端使用模板引擎末班引擎最早诞生于服务端,后来才到了前端 服务端和客户端渲染的区别是什么 客户端渲染 浏览器发请求,拿数据,模板引擎渲染,得到页面响应给浏览器页面中的字符串 浏览器收到服务端响应的页面字符串,从上到下一次解析html,解析过程中,如果发现有script标签就会执行脚本,如果发现ajax请求,则再次发起新的请求,最后在做模板引擎渲染 第一次请求拿到页面 第二次请求拿到动态数据 服务端渲染 服务端有页面和数据,服务端都提供 给浏览器响应页面的时候,服务端已经渲染完成整个页面,所以浏览器只管展示就可以了 总结: 其实很清楚,服务端渲染更快,因为服务端所有事情全都做了,一次性给浏览器,浏览器不需要做什么,但是服务端也会造成压力小技巧:有个小技巧可以快速知道是服务端渲染还是客户端渲染,就是打开网页查看源代码,如果源代码中可以搜索到页面的内容,那就是服务端渲染,如果是客户端渲染则是异步的渲染,不刷新页面而且查看源代码搜不到展示出来的内容. 还有个重点哦,异步渲染很难被爬虫抓取到的,所以客户端渲染很难被爬虫抓取到,这也就是大家说的客户端渲染SEO会有影响 所以很多网站等等都是客户端和服务端渲染结合来做的,服务端渲染为了SEO搜索引擎优化,而不需要考虑SEO的为了提高用户体验,所以采用客户端渲染 所以没有绝对哦,一般一个网站是客户端服务端渲染的结合版哦","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs-helloWord","slug":"node/nodejs-helloWord","date":"2019-05-21T06:50:57.000Z","updated":"2020-06-10T09:15:26.802Z","comments":true,"path":"2019/05/21/node/nodejs-helloWord/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/nodejs-helloWord/","excerpt":"nodejs-helloWord现在就是正式开始学习nodejs,好像什么语言学习都要从helloword学起,那node也从这里开始学吧 nodejs写helloword很简单很简单 建一个js文件咯,当然这个名字有讲头了,咱们用nodejs当然文件名不能叫node.js了,哈哈是不是很傻,当然最好文件名也不要使用中文定义会出意想不到的问题啦,其他的名字随便起,小写字母文件名开头,好了建好文件了 我要写helloword啦12var helloword &#x3D; &#39;helloword&#39;;console.log(helloword); 写好了js代码,node怎么执行这个js文件呢,很简单,打开命令行,输入 node (文件名).js,看到了吧,我们期待已久的helloword出现了","text":"nodejs-helloWord现在就是正式开始学习nodejs,好像什么语言学习都要从helloword学起,那node也从这里开始学吧 nodejs写helloword很简单很简单 建一个js文件咯,当然这个名字有讲头了,咱们用nodejs当然文件名不能叫node.js了,哈哈是不是很傻,当然最好文件名也不要使用中文定义会出意想不到的问题啦,其他的名字随便起,小写字母文件名开头,好了建好文件了 我要写helloword啦12var helloword &#x3D; &#39;helloword&#39;;console.log(helloword); 写好了js代码,node怎么执行这个js文件呢,很简单,打开命令行,输入 node (文件名).js,看到了吧,我们期待已久的helloword出现了 当然上面是最简单的nodejs的例子 http服务关于helloword123456789101112131415var http = require('http')var server = http.createServer()var hostname = '127.0.0.1'var port = 3000server.on('request', (request,res)=&gt;&#123; console.log('收到客户端请求'); res.statusCode = 200; res.setHeader('Content-Type', 'text/plain'); res.end('Hello World\\n');&#125;)server.listen(port,hostname,()=&gt;&#123; console.log(`Server running at http://$&#123;hostname&#125;:$&#123;port&#125;/`);&#125;)","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] 使用webstom开发nodejs","slug":"node/webstom开发nodejs","date":"2019-05-21T05:50:57.000Z","updated":"2020-06-10T09:15:50.345Z","comments":true,"path":"2019/05/21/node/webstom开发nodejs/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/webstom%E5%BC%80%E5%8F%91nodejs/","excerpt":"使用webstom开发nodejs nodejs自动提示 https://www.cnblogs.com/tgxh/p/6293084.html","text":"使用webstom开发nodejs nodejs自动提示 https://www.cnblogs.com/tgxh/p/6293084.html","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs安装","slug":"node/nodejs安装","date":"2019-05-21T05:50:57.000Z","updated":"2020-06-10T09:15:41.308Z","comments":true,"path":"2019/05/21/node/nodejs安装/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/nodejs%E5%AE%89%E8%A3%85/","excerpt":"nodejs安装 Windows windows安装很简单啦,去官网下载,(LTS版本是长期支持版本,稳定版)就可以啦(Currect版本体验版,最新特性版),然后写一部下一步咯https://nodejs.org/en/ 一般安装完成以后,他会自动将node和npm都安装进去,以及环境变量 安装完成node --version 输出一下版本号咯 linux 官网也有啦,进去下载解压安装就好了","text":"nodejs安装 Windows windows安装很简单啦,去官网下载,(LTS版本是长期支持版本,稳定版)就可以啦(Currect版本体验版,最新特性版),然后写一部下一步咯https://nodejs.org/en/ 一般安装完成以后,他会自动将node和npm都安装进去,以及环境变量 安装完成node --version 输出一下版本号咯 linux 官网也有啦,进去下载解压安装就好了 NVM 我最喜欢的就是这个工具了,多版本管理工具,可以下载多个版本的node,可以动态的切换,超级好用 windows下安装 https://www.jianshu.com/p/d0e0935b150a Ubuntu下安装 https://www.cnblogs.com/duaimili/p/10084809.html","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs到底干嘛","slug":"node/nodejs到底干嘛","date":"2019-05-21T04:50:57.000Z","updated":"2020-06-10T09:15:44.014Z","comments":true,"path":"2019/05/21/node/nodejs到底干嘛/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/nodejs%E5%88%B0%E5%BA%95%E5%B9%B2%E5%98%9B/","excerpt":"nodejs到底干嘛 Web服务器做后台,java/php能做的,他都能做 命令行工具","text":"nodejs到底干嘛 Web服务器做后台,java/php能做的,他都能做 命令行工具 对于前端开发工程师来说,主要是使用第三方的工具 WebPack gulp npm 需要预备的知识 HTML CSS JavaScript 阮一峰的教程哦 http://javascript.ruanyifeng.com/ 简单的命令行操作","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] nodejs到底是什么","slug":"node/nodejs到底是什么","date":"2019-05-21T03:50:57.000Z","updated":"2020-06-10T09:15:46.450Z","comments":true,"path":"2019/05/21/node/nodejs到底是什么/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/nodejs%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/","excerpt":"nodejs到底是什么 当然首先就是nodejs的官网 https://nodejs.org/en/ Node.js® is a JavaScript runtime built on Chrome’s V8 JavaScript engine. nodejs不是一门语言 nodejs不是库,不是框架 nodejs是一个JavaScript运行时环境 简单来说就是nodejs可以解析和执行JavaScript代码(以前只有浏览器可以解析JavaScript代码,现在可以完全脱离浏览器来运行JavaScript)","text":"nodejs到底是什么 当然首先就是nodejs的官网 https://nodejs.org/en/ Node.js® is a JavaScript runtime built on Chrome’s V8 JavaScript engine. nodejs不是一门语言 nodejs不是库,不是框架 nodejs是一个JavaScript运行时环境 简单来说就是nodejs可以解析和执行JavaScript代码(以前只有浏览器可以解析JavaScript代码,现在可以完全脱离浏览器来运行JavaScript) 浏览器中的JavaScript ECMAScript 基本语法 if function … BOM DOM nodejs中的JavaScript 没有BOM和DOM(因为服务端是不操作页面的) ECMAScript 在nodejs这个JavaScript执行环境中,对JavaScript提供了一些服务端的API 文件读写 网络服务构建 网络通信 http服务器 … 构建在Chrome的V8引擎之上 什么是引擎,其实就是解析执行js用,引擎越好,那性能就越好 具体有哪些浏览器对应哪些引擎呢,自行百度咯 https://baike.baidu.com/item/javascript%E5%BC%95%E6%93%8E/5356108?fr=aladdin其实他的目标就是做后端应用 nodejs特性 nodejs event-driver 事件驱动 异步(非阻塞IO模型) 轻量和高效 当然nodejs使用就不得不提npm npm是最大的开源库生态系统 npm是什么呢,其实就是将绝大多数第三方js相关的包放到npm上边,目的其实是为了开发人员更方便的下载和使用,也可以将自己写好的JavaScript工具类其他包发布到npm供其他人使用 比如之前要用jquery,需要下载jquery的js文件,然后引用,现在直接使用npm install jquery就可以了,简单直接","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"[Node] 为什么要使用nodejs","slug":"node/为什么使用nodejs","date":"2019-05-21T02:50:57.000Z","updated":"2020-06-10T09:15:15.481Z","comments":true,"path":"2019/05/21/node/为什么使用nodejs/","link":"","permalink":"http://new.zzpblog.cn/2019/05/21/node/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8nodejs/","excerpt":"为什么要使用nodejs","text":"为什么要使用nodejs 自己的理解 其实根本原因是为了全栈工程师这个名号,什么是全栈工程师呢?很简单就是 front-end+back-end 就是前端加后端,当然如果加上移动端那更厉害咯 前端有什么呢,其实很简单,就是html+css+JavaScript,简单吧,当然js也有很多框架,什么vue,react,等等,css也提供很多框架咯,比如sass/less等等,html都出到HTML5咯,增加了很多新特性,也可以去了解,不过个人认为最难也是很难学深入的就是JavaScript了,所以本人一直在努力中.. 当然这里的nodejs用途就是用来做back-end的,也就是后端应用,其实它的最大特点就是可以使用JavaScript编写后端服务,当然后端应用还有好多种,比如java/.net/PHP/Python/go,但是他们要单独学java语言/.net语言等等,需要重新学习一门语言. 感觉前端加上nodejs就可以做全栈了,前端这是都要包揽了吗,哈哈,其实感觉nodejs算是轻量化的后端服务,毕竟没有java处理大数据以及其他复杂的能力,就目前使用nodejs都用来开发一些小型的网站或应用系统,或者做中间层,比如vue+nodejs+java这种结构 总结以上 JavaScript –everywhere,凡是能用JavaScript实现的,最终都可以用JavaScript来实现,好厉害哟木有. 好啦好啦,不啰嗦,后面继续学习nodejs咯,以上是个人理解,有歧义找我咯","categories":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"}],"tags":[{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"}]},{"title":"mapstruct插件","slug":"mapstruct/mapstruct","date":"2019-05-06T08:20:57.000Z","updated":"2020-06-10T09:15:08.152Z","comments":true,"path":"2019/05/06/mapstruct/mapstruct/","link":"","permalink":"http://new.zzpblog.cn/2019/05/06/mapstruct/mapstruct/","excerpt":"关于mapstruct插件的使用参考链接官网文档","text":"关于mapstruct插件的使用参考链接官网文档 经常使用1234567891011121314151617181920212223242526@Mapper interface PostHotSquareResourcesMapper&#123; PostHotSquareResourcesMapper INSTANCE= Mappers.getMapper(PostHotSquareResourcesMapper.class); @Mappings(&#123; @Mapping(target = \"likeCount\", expression = \"java(post.getLikeCountValue())\"), @Mapping(target = \"shareCount\", expression = \"java(post.getShareCountValue())\"), @Mapping(target = \"label\",source = \"label\", qualifiedByName = \"formatLabelDef\"), @Mapping(target = \"author\", expression = \"java(new PostHotSquareResource.Author(post.getAuthor().getId(),post.getAuthor().getOperatorId()))\"), @Mapping(target = \"category\", expression = \"java(new PostHotSquareResource.Category(post.getCategory().getId(),post.getCategory().getGroup()))\"), &#125;) PostHotSquareResource from(Post post); List&lt;PostHotSquareResource&gt; toPost(Iterable&lt;Post&gt; posts); default Label formatLabelDef(com.dapeng.cloud.service.domain.Label label)&#123; if(label!=null)&#123; return new Label(label.getName(),label.getOrder(),label.getCreatedDate()); &#125;else&#123; return null; &#125; &#125; &#125; public List&lt;PostHotSquareResource&gt; toPostResources(Iterable&lt;Post&gt; posts)&#123; return PostHotSquareResourcesMapper.INSTANCE.toPost(posts); &#125;","categories":[{"name":"mapstruct","slug":"mapstruct","permalink":"http://new.zzpblog.cn/categories/mapstruct/"}],"tags":[{"name":"mapstruct插件","slug":"mapstruct插件","permalink":"http://new.zzpblog.cn/tags/mapstruct%E6%8F%92%E4%BB%B6/"}]},{"title":"解决ubuntu安装软件has install-snap change in progress错误","slug":"Ubuntu/Ubuntu软件安装问题","date":"2019-04-28T06:48:57.000Z","updated":"2020-06-10T08:45:01.031Z","comments":true,"path":"2019/04/28/Ubuntu/Ubuntu软件安装问题/","link":"","permalink":"http://new.zzpblog.cn/2019/04/28/Ubuntu/Ubuntu%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/","excerpt":"解决ubuntu安装软件has install-snap change in progress错误","text":"解决ubuntu安装软件has install-snap change in progress错误 今天在ubuntu软件商店安装idea报错： cannot install “intellij-idea-community”: snap “intellij-idea-community” has “install-snap” change in progress 其实就是软件之前安装了一次，只是没安装完。 解决方案 先snap changes 可以看到ID=5是我之前安装失败的。 现在我们终止它 sudo snap abort 5","categories":[{"name":"服务器","slug":"服务器","permalink":"http://new.zzpblog.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://new.zzpblog.cn/tags/Ubuntu/"}]},{"title":"Idea注释配置","slug":"Idea/Idea注释配置","date":"2019-04-26T04:22:57.000Z","updated":"2020-06-10T09:15:05.195Z","comments":true,"path":"2019/04/26/Idea/Idea注释配置/","link":"","permalink":"http://new.zzpblog.cn/2019/04/26/Idea/Idea%E6%B3%A8%E9%87%8A%E9%85%8D%E7%BD%AE/","excerpt":"Idea 模板注释配置在使用IDEA开发的过程中，我们可以通过设置代码注释模版，实现注释信息的自动补齐，提高编码效率。我使用的是Mac电脑，就以Mac环境来进行说明吧。 在Mac上配置IDEA的代码注释模版，主要包括两个部分：一个是File Head文件头注释，用于描述类文件的信息；一个是方法头注释，用于描述类方法的信息。具体配置过程如下。","text":"Idea 模板注释配置在使用IDEA开发的过程中，我们可以通过设置代码注释模版，实现注释信息的自动补齐，提高编码效率。我使用的是Mac电脑，就以Mac环境来进行说明吧。 在Mac上配置IDEA的代码注释模版，主要包括两个部分：一个是File Head文件头注释，用于描述类文件的信息；一个是方法头注释，用于描述类方法的信息。具体配置过程如下。 一、配置类文件头注释模版点击IDEA编译器左上角的“IntelliJ IDEA”按钮，选择“Preferences…”，在弹出窗口中，选择“Editor–&gt;File and Code Templates”，在窗口的右边“Schema”下拉栏选择“Default”，然后点击“Includes”标签，在右边模版栏中填写注释模版。最后点击右下角OK按钮生效。参考内容如下： 1234567&#x2F;** * 项目名称：$&#123;PROJECT_NAME&#125; * 类 名 称：$&#123;NAME&#125; * 类 描 述：TODO * 创建时间：$&#123;DATE&#125; $&#123;TIME&#125; * 创 建 人：$&#123;USER&#125; *&#x2F; 其中${…}里填写的是自动填充内容的标签。窗口右下角有IDEA当前支持的标签列表。 二、配置方法头注释模版点击IDEA编译器左上角的“IntelliJ IDEA”按钮，选择“Preferences…”，在弹出窗口中，选择“Editor–&gt;Live Templates”，进入方法头注释模版编辑界面，如下图。 添加方法头的注释，需要有以下步骤：（1）首先通过点击图中第二步中的“+”号，创建注释模版分组，比如我们命名为：MethodGroup；（2）在第四步中的“Abbreviation”输入框中添加填充注释时需要输入的指令关键字，此处我们使用“add”作为关键字，并在第五步中添加指令说明。经过这个步骤后，指令关键字会出现在上一步创建的注释分组MethodGroup中，效果如图中的第三步；（3）编辑注释内容模版，参考如下（注意：不需要以 /* 开头，因为需要我们在添加注释时会手动输入）： 12345678* * @name: $enclosing_method$ * @description: TODO $param$ * @return: $return$ * @date: $date$ $time$ * @auther: $user$ * *&#x2F; （4）点击第七步按钮，在弹窗中指定注释代码里参数的取值方式。 需要注意的是，如果param参数默认系统的methodParam()，那么在注释语句中，将以 “@param: [pa1, pa2…]”形式展现。我们使用groovyScript脚本来设置param的注释语句格式，让每个参数占一行。脚本内容为： 1groovyScript(&quot;def result&#x3D;&#39;&#39;; def params&#x3D;\\&quot;$&#123;_1&#125;\\&quot;.replaceAll(&#39;[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]&#39;, &#39;&#39;).split(&#39;,&#39;).toList(); for(i &#x3D; 0; i &lt; params.size(); i++) &#123;if(params[i] &#x3D;&#x3D; &#39;&#39;) return result;if(i&#x3D;&#x3D;0) result +&#x3D; &#39;\\\\n&#39;; result+&#x3D;&#39; * @param &#39; + params[i] + ((i &lt; params.size() - 1) ? &#39;\\\\n&#39; : &#39;&#39;)&#125;; return result&quot;, methodParameters()) （5）接下来指定填充注释语句的提示字符，通过窗口中的“Expand with”来指定。”Space”表示空格，”Tab”表示 Tab键。（6）最后是指定注释的使用范围，通过点击窗口下面的“…Change”来完成。","categories":[{"name":"Idea","slug":"Idea","permalink":"http://new.zzpblog.cn/categories/Idea/"}],"tags":[{"name":"Idea","slug":"Idea","permalink":"http://new.zzpblog.cn/tags/Idea/"}]},{"title":"[Spring boot - Swagger2] Swagger2的坑","slug":"Spring boot/Swagger","date":"2019-01-28T02:50:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2019/01/28/Spring boot/Swagger/","link":"","permalink":"http://new.zzpblog.cn/2019/01/28/Spring%20boot/Swagger/","excerpt":"Swagger2的坑","text":"Swagger2的坑 在使用Swagger2的时候出现404访问不到swagger-ui.html的问题 解决：其实这个问题是资源访问不到的问题，其实默认的话是可以访问到的，只是有些其他配置导致的swagger-ui.html访问不到了， 原因123456789101112131415161718192021222324@Configurationpublic class MvcConfig extends WebMvcConfigurationSupport &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/home\").setViewName(\"home\"); registry.addViewController(\"/\").setViewName(\"home\"); registry.addViewController(\"/hello\").setViewName(\"hello\"); registry.addViewController(\"/login\").setViewName(\"login\"); &#125;// @Override// public void addResourceHandlers(ResourceHandlerRegistry registry) &#123;// registry.addResourceHandler(\"/**\")// .addResourceLocations(\"classpath:/static/\");//// registry.addResourceHandler(\"swagger-ui.html\")// .addResourceLocations(\"classpath:/META-INF/resources/\");//// registry.addResourceHandler(\"/webjars/**\")// .addResourceLocations(\"classpath:/META-INF/resources/webjars/\");// &#125;&#125; 主要是这里我继承了WebMvcConfigurationSupport，导致资源访问不到的改成这样就可以了 123456789101112@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/home\").setViewName(\"home\"); registry.addViewController(\"/\").setViewName(\"home\"); registry.addViewController(\"/hello\").setViewName(\"hello\"); registry.addViewController(\"/login\").setViewName(\"login\"); &#125;&#125; 还有一个地方就是使用EnableWebMvc这个注解，去掉就可以了","categories":[{"name":"Swagger2","slug":"Swagger2","permalink":"http://new.zzpblog.cn/categories/Swagger2/"}],"tags":[{"name":"Spring boot","slug":"Spring-boot","permalink":"http://new.zzpblog.cn/tags/Spring-boot/"}]},{"title":"Ubuntu安装Mac主题","slug":"Ubuntu/Ubuntu安装Mac主题","date":"2018-11-05T09:11:57.000Z","updated":"2020-06-10T08:44:58.702Z","comments":true,"path":"2018/11/05/Ubuntu/Ubuntu安装Mac主题/","link":"","permalink":"http://new.zzpblog.cn/2018/11/05/Ubuntu/Ubuntu%E5%AE%89%E8%A3%85Mac%E4%B8%BB%E9%A2%98/","excerpt":"","text":"安装完的效果： 参考： https://linuxhint.com/gnome-tweak-tool-ubuntu-17-10/ ———————————————————————————————————————————————————— 下面正式开始———————————————————————————————————————————————————— 要安装主题，首先要先安装相应的工具：TweakTool 12sudo apt-get updatesudo apt-get install gnome-tweak-tool 下图就是安装完后，打开的Tweaks 修改窗口的按钮位置 Before: After: 现在按钮位置就修改到左边了 显示或隐藏桌面上的图标 修改鼠标图标 去掉Shell上无法修改的叹号 执行下面的命令 1sudo apt-get install gnome-shell-extensions 安装完成后打开Tweaks选择 “Extensions”选项 “User themes” 按钮设置成on 去“Appearances”选项，就能发现Shell那里没有叹号了 ———————————————————————————————————————————————————— 到现在我们已经把工具安装配置完成了，下面正式安装主题———————————————————————————————————————————————————— 1.安装GTK主题去这个链接：https://www.opendesktop.org/s/Gnome/p/1171688/ 网页上有好几个标签：Prodect、FIles、Changelogs等等 找到Files标签，去下载文件。点击文件名就可以下载。 可以看到这里一共有6个压缩文件，分别包装各种主题。通过文件名能发现每一个文件都有一个“2”，这个2的意思是该压缩包下有两个主题。 随便选中一个比如Gnome-OSC-HS–2themes.tar.xz（第一个文件），下载下来。 通过xz和tar命令解压 12xz -d Gnome-OSC-HS--2-themes.tar.xztar xvf Gnome-OSC-HS--2-themes.tar.xz 解压后得到的文件夹中有两个文件夹 这两个文件夹分别是两个主题，把这两个文件夹移动到/usr/share/themes下就可以了。 然后打开前面安装的工具Tweaks（中文下叫“优化”）,在“应用程序”英文是“Applications”这个选项下就可以选择刚刚安装的主题了。这几个截图是我安装主题后的截图。 刚刚是两个文件夹，就是两个主题，这两个主题从名字上看只有transparent前面是否有个not，顾名思义就是有没有透明效果。 到现在已经修改了外观样式，最大化最小化的样式已经很苹果了。 2.修改图标去下面的链接下载 https://www.opendesktop.org/s/Gnome/p/1102582/ 解压后把文件都放到/usr/share/icons目录下，如下图（这是已经应用过主题的截图）所示： 然后去Tweaks中应用一下 3.修改桌面Shell去这个链接：https://www.opendesktop.org/s/Gnome/p/1013741/ 下载下面红框里的 应用下 效果： -——————- 2018-05-09更新 关于plymouth theme，开机动画。 -——————- 如上图所示，/etc/alternatives/default.plymouth文件指定了一个logo文件夹，指定了一个执行脚本。开机的时候就用这个文件指定的logo和脚本执行。 那么思路就是，把logo文件夹和脚本指定成别的就可以修改开机动画。 开机动画主题没找到好看的，试一下这个吧： 下载下压缩包，解压后： 把解压的文件mv到 /usr/share/plymouth/themes/目录下 然后去修改下/etc/alternatives/default.plymouth（先备份源文件）成如下 实际图示就类似下图，不过中间的logo是会转动的（手机录制的不好看就不贴gif了） -——————- 2018-05-10更新 GDM（GNOME Display Manager，GDM）主题，也就是登录界面的主题 -——————- 选了一个主题https://www.opendesktop.org/s/Gnome/p/1207015/，如下 解压压缩包 该文件夹下有三个文件 先说明下修改登录界面样式的原理： 重要步骤是在css文件，这个/usr/share/gnome-shell/theme/ubuntu.css就配置了登录界面的样式。 在/usr/share/gnome-shell/theme/ubuntu.css文件（上面我下载的包中，非系统自带的这个css文件）中有这样一行代码： 是的，Ubuntu18.04的登录界面是用css文件渲染的，做网页前端的应该最熟悉不过了。 如果你只想替换登录界面的背景，把系统自带的这个css文件中指定图像文件的位置修改成你自己的图片的绝对目录就行了。 当然，如果你想让你的登录界面炫酷一些，修改css文件，渲染成你想要的效果即可。 或者你想省事，那就和我一样去网上下载别人写好的css文件。 在我下载的中，还有个脚本文件，内容如下： 有注释，这个脚本的作用是把你现在正在用的壁纸模糊处理，然后放到 ~/Pictures/gdm_look.jpg，执行过脚本后，你的 ~/Pictures目录下就会多一个gdm_look.jpg文件，这个文件就是你当前用的壁纸的模糊处理过后的图片。 然后 ~/Pictures/gdm_look.jpg又被复制到/usr/share/backgrounds/目录下，再看下面这个图 这个包中提供的css文件指定的登录页面壁纸，也就是脚本处理完后cp到/usr/share/backgrounds/的gdm_look.jpg。 至此，原理说明白了，操作如下： 备份/usr/share/gnome-shell/theme/ubuntu.css 1sudo cp /usr/share/gnome-shell/theme/ubuntu.css /usr/share/gnome-shell/theme/ubuntu.css.backup 用下图中的ubuntu.css替换掉系统自带的/usr/share/gnome-shell/theme/ubuntu.css 把SetAsWallpaper脚本文件复制到~/.local/share/nautilus/scripts/目录下，然后修改下权限（如果需要） 1sudo chmod +x SetAsWallpaper 然后重启nautilus（下面的命令是关闭） 1nautilus -q 点击桌面右下角“所有应用”，查找“nautilus ” 执行如下命令，修改下 /usr/share/backgrounds 的权限 1sudo chmod 777 /usr/share/backgrounds/ 最后一步，去~/.local/share/nautilus/scripts/ 目录下执行下SetAsWallpaper脚本。 重启系统就好了。（执行脚本后，你的桌面壁纸可能会没了，重新设置下就好了） 最后放一张效果图： -——————- 2018-05-12更新 TopBar -——————- 我使用的gnome-shell主题是)它的TopBar是这样的字体略粗，且很宽太占空间。 修改后的样子这样明显好看一些。 下面正式开始修改，由于我是用的Sierra-compact-light主题，所以要去这个主题下面的配置文件（其实是一个css文件）修改，就是下面的目录 1/usr/share/themes/Sierra-compact-light/gnome-shell/gnome-shell.css 如果你是想修改Ubuntu默认的TopBar就不是上面这个目录了而应该是Ubuntu默认Shell的目录，可能是下面几个文件中修改，因为我没试过，所以不确定具体是哪个文件。 回到/usr/share/themes/Sierra-compact-light/gnome-shell/gnome-shell.css文件，也就是我的主题文件，ctrl+f找#panel 修改TopBar高度 加粗字体改成正常字体 保存重启就好了。 -——————- 2018-05-19更新 Dash to Dock -——————- 打开Ubuntu Software，直接搜索 dash to dock，安装上。 打开Tweaks -&gt; Extensions，注意，这里不要打开Dash to Dock扩展，修改样式直接点击齿轮按钮就好，我尝试打开，但是锁屏后再进入桌面会有bug。 我的设置如下 效果： 比起docky这个的好处是直接修改的系统的dock，而docky是直接添加了一dock且系统自带的dock也不能移除，但docky有macOS的放大效果这个没有。","categories":[{"name":"服务器","slug":"服务器","permalink":"http://new.zzpblog.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://new.zzpblog.cn/tags/Ubuntu/"}]},{"title":"Ubuntu安装idea","slug":"Ubuntu/Ubuntu安装idea","date":"2018-10-18T09:11:57.000Z","updated":"2020-06-10T08:44:55.699Z","comments":true,"path":"2018/10/18/Ubuntu/Ubuntu安装idea/","link":"","permalink":"http://new.zzpblog.cn/2018/10/18/Ubuntu/Ubuntu%E5%AE%89%E8%A3%85idea/","excerpt":"","text":"个人分类： Ubuntu 1、下载地址：https://www.jetbrains.com/idea/download/#section=linux 2、解压 找到下载的tar包1$ sudo tar -zxvf Idea-UI-2018.2.5.tar.gz 进入bin/1$ cd bin 找到idea.sh并运行1$ .&#x2F;idea.sh 2、破解 修改环境变量1$ sudo gedit &#x2F;etc&#x2F;hosts 增加 0.0.0.0 account.jetbrains.com 注册码地址 http://idea.lanyus.com/","categories":[{"name":"服务器","slug":"服务器","permalink":"http://new.zzpblog.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://new.zzpblog.cn/tags/Ubuntu/"}]},{"title":"Springboot热加载","slug":"Spring boot/Springboot热加载","date":"2018-10-05T10:28:57.000Z","updated":"2020-06-10T08:45:04.741Z","comments":true,"path":"2018/10/05/Spring boot/Springboot热加载/","link":"","permalink":"http://new.zzpblog.cn/2018/10/05/Spring%20boot/Springboot%E7%83%AD%E5%8A%A0%E8%BD%BD/","excerpt":"Spring boot 热加载","text":"Spring boot 热加载 1 pom.xml文件 注：热部署功能spring-boot-1.3开始有的 1234567&lt;!--添加依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;&#x2F;artifactId&gt; &lt;!-- optional&#x3D;true,依赖不会传递，该项目依赖devtools；之后依赖myboot项目的项目如果想要使用devtools，需要重新引入 --&gt; &lt;optional&gt;true&lt;&#x2F;optional&gt;&lt;&#x2F;dependency&gt; 注：project 中添加 spring-boot-maven-plugin,主要在eclipse中使用，idea中不需要添加此配置。 1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;&#x2F;fork&gt; &lt;&#x2F;configuration&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt;&lt;&#x2F;build&gt; 2 更改idea配置 1） “File” -&gt; “Settings” -&gt; “Build,Execution,Deplyment” -&gt; “Compiler”，选中打勾 “Build project automatically” 。 2） 组合键：“Shift+Ctrl+Alt+/” ，选择 “Registry” ，选中打勾 “compiler.automake.allow.when.app.running” 。 3 Chrome禁用缓存 F12或者“Ctrl+Shift+I”，打开开发者工具，“Network” 选项卡下 选中打勾 “Disable Cache(while DevTools is open)”","categories":[{"name":"Springboot","slug":"Springboot","permalink":"http://new.zzpblog.cn/categories/Springboot/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://new.zzpblog.cn/tags/Springboot/"}]},{"title":"Ubuntu系统Xshell root连接时linux时提示ssh服务器拒绝了密码","slug":"Ubuntu/Ubuntu xShell无法连接","date":"2018-09-29T15:28:57.000Z","updated":"2020-06-10T08:44:49.561Z","comments":true,"path":"2018/09/29/Ubuntu/Ubuntu xShell无法连接/","link":"","permalink":"http://new.zzpblog.cn/2018/09/29/Ubuntu/Ubuntu%20xShell%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/","excerpt":"Ubuntu系统Xshell root连接时linux时提示ssh服务器拒绝了密码","text":"Ubuntu系统Xshell root连接时linux时提示ssh服务器拒绝了密码 安装openssh-server 1$ sudo apt-get install openssh-server 用Xshell root连接时linux时提示ssh服务器拒绝了密码，应该sshd设置了不允许root用户用密码远程登录修改 /etc/ssh/sshd_config文件，注意，安装了openssh才会有这个文件，如果文件不存在请检查是否安装了openssh。 1vim &#x2F;etc&#x2F;ssh&#x2F;sshd_config 找到 1234# Authentication:LoginGraceTime 120PermitRootLogin prohibit-passwordStrictModes yes 修改成 1234# Authentication:LoginGraceTime 120PermitRootLogin yesStrictModes yes 输入命令 1&#x2F;etc&#x2F;init.d&#x2F;ssh restart","categories":[{"name":"服务器","slug":"服务器","permalink":"http://new.zzpblog.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://new.zzpblog.cn/tags/Ubuntu/"}]},{"title":"Docker容器通过宿主机安装JDK和MAVEN","slug":"docker/Docker部署JDK和MAVEN","date":"2018-09-29T01:55:57.000Z","updated":"2020-06-10T08:13:26.460Z","comments":true,"path":"2018/09/29/docker/Docker部署JDK和MAVEN/","link":"","permalink":"http://new.zzpblog.cn/2018/09/29/docker/Docker%E9%83%A8%E7%BD%B2JDK%E5%92%8CMAVEN/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Docker容器通过宿主机安装JDK和MAVEN","text":"&lt;Excerpt in index | 首页摘要&gt;Docker容器通过宿主机安装JDK和MAVEN &lt;The rest of contents | 余下全文&gt; Docker容器通过宿主机安装JDK和MAVEN1，下载jdk和mavenJDK http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html MAVEN https://maven.apache.org/download.cgi 2，解压12tar zxvf jdk-8u161-linux-x64.tar.gztar zxvf apache-maven-3.5.3.tar.gz 3移动到指定目录下12mv .&#x2F;jdk-8u161 &#x2F;usr&#x2F;localmv .&#x2F;apache-maven-3.5.3&#x2F;usr&#x2F;local 4, Dockerfile123456789FROM centosENV JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdkENV CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jarENV MAVEN_HOME &#x2F;usr&#x2F;local&#x2F;mavenENV PATH $PATH:$JAVA_HOME&#x2F;bin:$MAVEN_HOME&#x2F;binCMD [&quot;java&quot;, &quot;-version&quot;]CMD [&quot;mvn&quot;, &quot;-v&quot;] 5，构建镜像1docker build -t java_maven . 生成docker image。 6，启动容器1docker run -v &#x2F;usr&#x2F;local&#x2F;jdk1.8.0_161:&#x2F;usr&#x2F;local&#x2F;jdk -v &#x2F;usr&#x2F;local&#x2F;apache-maven-3.5.3:&#x2F;usr&#x2F;local&#x2F;maven --name jdk_maven java_maven image.png 运行容器后，显示上图，表示成功。 链接：https://www.jianshu.com/p/cb73ac39820b 來源：简书","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"docker命令总结","slug":"docker/Docker常用指令操作","date":"2018-09-28T09:28:57.000Z","updated":"2020-06-10T08:13:26.458Z","comments":true,"path":"2018/09/28/docker/Docker常用指令操作/","link":"","permalink":"http://new.zzpblog.cn/2018/09/28/docker/Docker%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E6%93%8D%E4%BD%9C/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;docker命令总结","text":"&lt;Excerpt in index | 首页摘要&gt;docker命令总结 &lt;The rest of contents | 余下全文&gt; docker命令总结查看镜像12$ docker iamges $ docker image ls 获取镜像1$ docker pull [镜像名称] 删除镜像123$ docker rmi [镜像名称&#x2F;id]$ docker image rm [镜像名称&#x2F;id]$ docker image prune 清除none的镜像 运行容器12345$ docker run -p 8080:8080 tomcat$ docker run -p 8080:8080 --name tomcat2 tomcat 运行一个镜像为tomcat名称为tomcat2的容器$ docker run -it --rm tomcat bash 交互方式进入退出时候删除$ docker run -it tomcat bash 交互方式进入但退出时候不删除$ docker run -p 8080:8080 -d tomcat -d的意思是守护太运行，也就是后台运行 查看容器12$ docker ps -a 查看所有容器$ docker ps 查看正在运行的容器 重启容器1$ docker restart 容器id 进入容器1$ docker exec -it 容器id bash 停止容器1$ docker stop 容器名称&#x2F;id 删除容器12$ docker rm 容器id$ docker rm -f 容器id 强制删除容器 删除镜像12$ docker rmi 镜像id&#x2F;镜像名称$ docker image rm 镜像id 监听查看日志1$ docker logs -f 容器名 构建Dockerfile1$ docker build -t 镜像名称 . (.代表dockerfile路径) Dockerfile命令1234567FROM 镜像 （必须）WORKDIR 路径 (工作路径)COPY 上下文路径 目标镜像路径RUN shell脚本 (运行shell脚本)EXPOSE 8080 暴露端口CMD service nginx start CMD启动命令CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 前台运行1docker-compose up 后台运行1docker-compose up -d 启动1docker-compose start 停止1docker-compose stop 停止并移除容器1docker-compose down","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"docker-compose 模板文件","slug":"docker/Docker-compose模板文件","date":"2018-09-28T03:55:57.000Z","updated":"2020-06-10T08:13:26.454Z","comments":true,"path":"2018/09/28/docker/Docker-compose模板文件/","link":"","permalink":"http://new.zzpblog.cn/2018/09/28/docker/Docker-compose%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;docker-compose 模板文件","text":"&lt;Excerpt in index | 首页摘要&gt;docker-compose 模板文件 &lt;The rest of contents | 余下全文&gt; docker-compose 模板文件模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 123456789version: &quot;3&quot;services: webapp: image: examples&#x2F;web ports: - &quot;80:80&quot; volumes: - &quot;&#x2F;data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。 下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 12345version: &#39;3&#39;services: webapp: build: .&#x2F;dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 123456789version: &#39;3&#39;services: webapp: build: context: .&#x2F;dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 12345build: context: . cache_from: - alpine:latest - corp&#x2F;web_app:3.14 cap_add, cap_drop指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： 12cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： 12cap_drop: - NET_ADMIN command覆盖容器启动后默认执行的命令。 1command: echo &quot;hello world&quot; configs仅用于 Swarm mode cgroup_parent指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 1cgroup_parent: cgroups_1 container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy仅用于 Swarm mode devices指定设备映射关系。 12devices: - &quot;&#x2F;dev&#x2F;ttyUSB1:&#x2F;dev&#x2F;ttyUSB0&quot; depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 1234567891011121314version: &#39;3&#39;services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns自定义 DNS 服务器。可以是一个值，也可以是一个列表。 12345dns: 8.8.8.8dns: - 8.8.8.8 - 114.114.114.114 dns_search配置 DNS 搜索域。可以是一个值，也可以是一个列表。 12345dns_search: example.comdns_search: - domain1.example.com - domain2.example.com tmpfs挂载一个 tmpfs 文件系统到容器。 1234tmpfs: &#x2F;runtmpfs: - &#x2F;run - &#x2F;tmp env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - .&#x2F;common.env - .&#x2F;apps&#x2F;web.env - &#x2F;opt&#x2F;secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# common.env: Set development environmentPROG_ENV&#x3D;development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV&#x3D;development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 123expose: - &quot;3000&quot; - &quot;8000&quot; external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 1234external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 123extra_hosts: - &quot;googledns:8.8.8.8&quot; - &quot;dockerhub:52.1.157.61&quot; 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 128.8.8.8 googledns52.1.157.61 dockerhub healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http:&#x2F;&#x2F;localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123image: ubuntuimage: orchardup&#x2F;postgresqlimage: a4bc65fd labels为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 1234labels: com.startupteam.description: &quot;webapp for a startup team&quot; com.startupteam.department: &quot;devops department&quot; com.startupteam.release: &quot;rc3 for v1.0&quot; links 注意：不推荐使用该指令。 logging配置日志选项。 1234logging: driver: syslog options: syslog-address: &quot;tcp:&#x2F;&#x2F;192.168.0.42:123&quot; 目前支持三种日志驱动类型。 123driver: &quot;json-file&quot;driver: &quot;syslog&quot;driver: &quot;none&quot; options 配置日志驱动的相关参数。 123options: max-size: &quot;200k&quot; max-file: &quot;10&quot; network_mode设置网络模式。使用和 docker run 的 --network 参数一样的值。 12345network_mode: &quot;bridge&quot;network_mode: &quot;host&quot;network_mode: &quot;none&quot;network_mode: &quot;service:[service name]&quot;network_mode: &quot;container:[container name&#x2F;id]&quot; networks配置容器连接的网络。 1234567891011version: &quot;3&quot;services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: pid跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 1pid: &quot;host&quot; ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets存储敏感数据，例如 mysql 服务密码。 12345678910111213141516version: &quot;3.1&quot;services:mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: &#x2F;run&#x2F;secrets&#x2F;db_root_password secrets: - db_root_password - my_other_secretsecrets: my_secret: file: .&#x2F;my_secret.txt my_other_secret: external: true security_opt指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 123security_opt: - label:user:USER - label:role:ROLE stop_signal设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 1stop_signal: SIGUSR1 sysctls配置容器内核参数。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn&#x3D;1024 - net.ipv4.tcp_syncookies&#x3D;0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - &#x2F;var&#x2F;lib&#x2F;mysql - cache&#x2F;:&#x2F;tmp&#x2F;cache - ~&#x2F;configs:&#x2F;etc&#x2F;configs&#x2F;:ro 其它指令此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 1entrypoint: &#x2F;code&#x2F;entrypoint.sh 指定容器中运行应用的用户名。 1user: nginx 指定容器中工作目录。 1working_dir: &#x2F;code 指定容器中搜索域名、主机名、mac 地址等。 123domainname: your_website.comhostname: testmac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 1privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 1restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 1read_only: true 打开标准输入，可以接受外部输入。 1stdin_open: true 模拟一个伪终端。 1tty: true 读取变量Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。 12345version: &quot;3&quot;services:db: image: &quot;mongo:$&#123;MONGO_VERSION&#125;&quot; 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 12# 支持 # 号注释MONGO_VERSION&#x3D;3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"docker-compose 命令","slug":"docker/Docker-compose命令","date":"2018-09-28T02:55:57.000Z","updated":"2020-06-10T08:13:26.453Z","comments":true,"path":"2018/09/28/docker/Docker-compose命令/","link":"","permalink":"http://new.zzpblog.cn/2018/09/28/docker/Docker-compose%E5%91%BD%E4%BB%A4/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;docker-compose 命令","text":"&lt;Excerpt in index | 首页摘要&gt;docker-compose 命令 &lt;The rest of contents | 余下全文&gt; docker-compose 命令命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 1docker-compose [-f&#x3D;&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 命令使用说明build格式为 docker-compose build [options] [SERVICE...]。 构建（重新构建）项目中的服务容器。 服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 选项包括： --force-rm 删除构建过程中的临时容器。 --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。 --pull 始终尝试通过 pull 来获取更新版本的镜像。 config验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 down此命令将会停止 up 命令所启动的容器，并移除网络 exec进入指定的容器。 help获得一个命令的帮助。 images列出 Compose 文件中包含的镜像。 kill格式为 docker-compose kill [options] [SERVICE...]。 通过发送 SIGKILL 信号来强制停止服务容器。 支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。 1$ docker-compose kill -s SIGINT logs格式为 docker-compose logs [options] [SERVICE...]。 查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。 该命令在调试问题的时候十分有用。 pause格式为 docker-compose pause [SERVICE...]。 暂停一个服务容器。 port格式为 docker-compose port [options] SERVICE PRIVATE_PORT。 打印某个容器端口所映射的公共端口。 选项： --protocol=proto 指定端口协议，tcp（默认值）或者 udp。 --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： -q 只打印容器的 ID 信息。 pull格式为 docker-compose pull [options] [SERVICE...]。 拉取服务依赖的镜像。 选项： --ignore-pull-failures 忽略拉取镜像过程中的错误。 push推送服务依赖的镜像到 Docker 镜像仓库。 restart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 run格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。 在指定服务上执行一个命令。 例如： 1$ docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。 默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。 该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。 两个不同点： 给定命令将会覆盖原有的自动运行命令； 不会自动创建端口，以避免冲突。 如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如 1$ docker-compose run --no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 选项： -d 后台运行容器。 --name NAME 为容器指定一个名字。 --entrypoint CMD 覆盖默认的容器启动指令。 -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。 -u, --user=&quot;&quot; 指定运行容器的用户名或者 uid。 --no-deps 不自动启动关联的服务容器。 --rm 运行命令后自动删除容器，d 模式下将忽略。 -p, --publish=[] 映射容器端口到本地主机。 --service-ports 配置服务端口并映射到本地主机。 -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。 scale格式为 docker-compose scale [options] [SERVICE=NUM...]。 设置指定服务运行的容器个数。 通过 service=num 的参数来设置数量。例如： 1$ docker-compose scale web&#x3D;3 db&#x3D;2 将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。 一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start格式为 docker-compose start [SERVICE...]。 启动已经存在的服务容器。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d &lt;SERVICE_NAME&gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项： -d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 version格式为 docker-compose version。 打印版本信息。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Idea发布项目到git 使用","slug":"Idea/Idea发布项目到Git","date":"2018-09-28T01:55:57.000Z","updated":"2020-06-10T09:15:02.963Z","comments":true,"path":"2018/09/28/Idea/Idea发布项目到Git/","link":"","permalink":"http://new.zzpblog.cn/2018/09/28/Idea/Idea%E5%8F%91%E5%B8%83%E9%A1%B9%E7%9B%AE%E5%88%B0Git/","excerpt":"Idea发布项目到Git1、新建项目","text":"Idea发布项目到Git1、新建项目 2、打开idea要发布的项目 VCS–Import into Version Control–Create git Respository 选择要发布的项目根目录 右键项目目录–git–Add 项目内容加到本地git 右键项目目录–git–commit Directory 提交项目 push 填写远程仓库的地址 这时候push会出现 先右键项目–git–pull 会出现 点击右下角，选择远程分支master–Rebase Current onto Selected 进行rebase把远程master更新下来 再次Push 完成 方法二配置本地仓库 ​ （1）VCS –&gt; Import into Version Control –&gt; Create Git Repository ​ （2）选择本地仓库位置（个人比较喜欢放在项目根目录下） ​ （3）创建完成后会在该位置生成一个.git文件 3：提交代码到本地仓库 ​ （1）首先要add（将目录下所有新增和修改存至缓存区，但不包括删除）。 ​ 更改或新增的文件颜色会变为红色，意为可add。 ​ add过后的文件颜色会变为绿色 ​ （2）其次要commit （将缓存区中的内容保存至本地仓库），文件为绿色意为可commit 4：建立本地仓库与远程仓库的连接 ​ 如果没有远程仓库，需要创建一个远成仓库。可以自己搭建一个，也可以使用码云、coding等。 ​ 这里使用的是coding。 ​ （1）打开Remotes （2）在弹出的小窗口里点击加号，URL里填写在coding创建的项目所提供的https SSH链接。点击ok。 ​ （3）正常情况下到这里已经成功建立连接了。 ​ 在这里可能会出现这个错误：Remote URL test failed: unable to access ‘https://git.coding.net/taobu/back.git/&#39;: The requested URL returned error: 403 ​ 这个问题有可能是我们在coding或码云或github上注册账号所使用的邮箱与我们在本地配置git时使用的邮箱不一致。 ​ 解决方案是使用相同的邮箱即可 5：上传到远程仓库 ​ （1）push到远程仓库 ​ （2）登录我们的远程仓库，在我们创建的项目中可以看得到已经有一个分支已成功推送","categories":[{"name":"Idea","slug":"Idea","permalink":"http://new.zzpblog.cn/categories/Idea/"}],"tags":[{"name":"Idea","slug":"Idea","permalink":"http://new.zzpblog.cn/tags/Idea/"}]},{"title":"docker-compose 使用","slug":"docker/Docker-compose使用","date":"2018-09-28T01:55:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2018/09/28/docker/Docker-compose使用/","link":"","permalink":"http://new.zzpblog.cn/2018/09/28/docker/Docker-compose%E4%BD%BF%E7%94%A8/","excerpt":"docker-compose 使用","text":"docker-compose 使用 1、新建docker-compose.yml12$ cd &#x2F;usr&#x2F;local&#x2F;docker&#x2F;tomcat &#x2F;&#x2F;已tomcat为例，tomcat目录为应用目录，没有可以创建$ vi docker-compose.yml 2、docker-compose.yml书写编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件。 12345678version: &#39;3&#39;services: tomcat: restart: always image: tomcat container_name: tomcat ports: - 8080:8080 version: &#39;3&#39; docker-compose的版本 services: 代表服务 tomcat: 服务的名字，这个名字可以随便起，前面为两个空格，不能按tab image:要使用的镜像,前面四个空格 container_name:容器名字，前面四个空格 ports：启动的端口 运行 compose 项目1$ docker-compose up 删除容器1$ docker-compose down 更换docker-compose路径1$ docker-compose -f &#x2F;usr&#x2F;local&#x2F;。。 实例编写tomcat+mysql的docker-compose 123456789101112131415161718192021222324252627282930version: &#39;3&#39;services: web: restart: always image: tomcat container_name: web ports: - 8080:8080 volumes: - &#x2F;usr&#x2F;local&#x2F;docker&#x2F;dapeng&#x2F;ROOT:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps&#x2F;ROOT mysql: restart: always image: mysql:5.7.22 container_name: mysql ports: - 3306:3306 environment: TZ: Asia&#x2F;Shanghai MYSQL_ROOT_PASSWORD: 123456 command: --character-set-server&#x3D;utf8mb4 --collation-server&#x3D;utf8mb4_general_ci --explicit_defaults_for_timestamp&#x3D;true --lower_case_table_names&#x3D;1 --max_allowed_packet&#x3D;128M --sql-mode&#x3D;&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO&quot; volumes: - mysql-data:&#x2F;var&#x2F;lib&#x2F;mysqlvolumes: mysql-data: 其中：environment为环境变量设置 command:为初始化命令 volumes：数据卷，这里的mysql-data:/var/lib/mysql mysql-data在下面 volumes: mysql-data: 声明一个统一的mysql-data数据卷，数据一般放在/var目录下：默认目录放在/var/lib/docker/volumes下 启动 1$ docker-compose up","categories":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker-compose安装","slug":"docker/Docker-compose安装","date":"2018-09-28T01:28:57.000Z","updated":"2020-06-10T08:45:19.028Z","comments":true,"path":"2018/09/28/docker/Docker-compose安装/","link":"","permalink":"http://new.zzpblog.cn/2018/09/28/docker/Docker-compose%E5%AE%89%E8%A3%85/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;什么是Docker-compose、Docker-compose安装","text":"&lt;Excerpt in index | 首页摘要&gt;什么是Docker-compose、Docker-compose安装 &lt;The rest of contents | 余下全文&gt; Docker-compose安装什么是Docker-composeDocker Compose` 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 之前启动必须是要docker run 后面加一堆参数部署很麻烦，Docker-compose就是用来解决这个问题的。其实就是为了简化原生docker使用。 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Docker Compose 安装与卸载Compose 支持 Linux、macOS、Windows 10 三大平台。 Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。 前两种方式是传统方式，适合本地环境下安装使用；最后一种方式则不破坏系统环境，更适合云计算场景。 Docker for Mac 、Docker for Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 123$ docker-compose --versiondocker-compose version 1.17.1, build 6d101fb Linux 系统请使用以下介绍的方法安装。 二进制包在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。 例如，在 Linux 64 位系统上直接下载对应的二进制包。 12$ sudo curl -L https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;1.22.0&#x2F;docker-compose-&#96;uname -s&#96;-&#96;uname -m&#96; &gt; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose$ sudo chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose PIP 安装注： x86_64 架构的 Linux 建议按照上边的方法下载二进制包进行安装，如果您计算机的架构是 ARM (例如，树莓派)，再使用 pip 安装。 这种方式是将 Compose 当作一个 Python 应用来从 pip 源中安装。 执行安装命令： 1$ sudo pip install -U docker-compose 可以看到类似如下输出，说明安装成功。 1234Collecting docker-compose Downloading docker-compose-1.17.1.tar.gz (149kB): 149kB downloaded...Successfully installed docker-compose cached-property requests texttable websocket-client docker-py dockerpty six enum34 backports.ssl-match-hostname ipaddress bash 补全命令1$ curl -L https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;docker&#x2F;compose&#x2F;1.8.0&#x2F;contrib&#x2F;completion&#x2F;bash&#x2F;docker-compose &gt; &#x2F;etc&#x2F;bash_completion.d&#x2F;docker-compose 容器中执行Compose 既然是一个 Python 应用，自然也可以直接用容器来执行它。 12$ curl -L https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;1.8.0&#x2F;run.sh &gt; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose$ chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose 实际上，查看下载的 run.sh 脚本内容，如下 1234567891011121314151617181920212223242526272829303132333435363738394041set -eVERSION&#x3D;&quot;1.8.0&quot;IMAGE&#x3D;&quot;docker&#x2F;compose:$VERSION&quot;# Setup options for connecting to docker hostif [ -z &quot;$DOCKER_HOST&quot; ]; then DOCKER_HOST&#x3D;&quot;&#x2F;var&#x2F;run&#x2F;docker.sock&quot;fiif [ -S &quot;$DOCKER_HOST&quot; ]; then DOCKER_ADDR&#x3D;&quot;-v $DOCKER_HOST:$DOCKER_HOST -e DOCKER_HOST&quot;else DOCKER_ADDR&#x3D;&quot;-e DOCKER_HOST -e DOCKER_TLS_VERIFY -e DOCKER_CERT_PATH&quot;fi# Setup volume mounts for compose config and contextif [ &quot;$(pwd)&quot; !&#x3D; &#39;&#x2F;&#39; ]; then VOLUMES&#x3D;&quot;-v $(pwd):$(pwd)&quot;fiif [ -n &quot;$COMPOSE_FILE&quot; ]; then compose_dir&#x3D;$(dirname $COMPOSE_FILE)fi# TODO: also check --file argumentif [ -n &quot;$compose_dir&quot; ]; then VOLUMES&#x3D;&quot;$VOLUMES -v $compose_dir:$compose_dir&quot;fiif [ -n &quot;$HOME&quot; ]; then VOLUMES&#x3D;&quot;$VOLUMES -v $HOME:$HOME -v $HOME:&#x2F;root&quot; # mount $HOME in &#x2F;root to share docker.configfi# Only allocate tty if we detect oneif [ -t 1 ]; then DOCKER_RUN_OPTIONS&#x3D;&quot;-t&quot;fiif [ -t 0 ]; then DOCKER_RUN_OPTIONS&#x3D;&quot;$DOCKER_RUN_OPTIONS -i&quot;fiexec docker run --rm $DOCKER_RUN_OPTIONS $DOCKER_ADDR $COMPOSE_OPTIONS $VOLUMES -w &quot;$(pwd)&quot; $IMAGE &quot;$@&quot; 可以看到，它其实是下载了 docker/compose 镜像并运行。 卸载如果是二进制包方式安装的，删除二进制文件即可。 1$ sudo rm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose 如果是通过 pip 安装的，则执行如下命令即可删除。 1$ sudo pip uninstall docker-compose","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker安装mysql","slug":"docker/Docker镜像安装mysql","date":"2018-09-27T15:28:57.000Z","updated":"2020-06-10T08:13:26.462Z","comments":true,"path":"2018/09/27/docker/Docker镜像安装mysql/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E9%95%9C%E5%83%8F%E5%AE%89%E8%A3%85mysql/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Docker安装mysql","text":"&lt;Excerpt in index | 首页摘要&gt;Docker安装mysql &lt;The rest of contents | 余下全文&gt; Docker安装mysql1、拉取官方镜像1$ docker pull mysql:5.7.22 2、运行mysql123456docker run -p 3306:3306 --name mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;conf:&#x2F;etc&#x2F;mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;logs:&#x2F;var&#x2F;log&#x2F;mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql \\-e MYSQL_ROOT_PASSWORD&#x3D;123456 \\-d mysql:5.7.22 注意，如果挂载宿主机目录不存在则会自动创建该文件夹 命令参数： -p 3306:3306：将容器的3306端口映射到主机的3306端口-v /usr/local/docker/mysql/conf:/etc/mysql：将主机当前目录下的 conf 挂载到容器的 /etc/mysql-v /usr/local/docker/mysql/logs:/var/log/mysql：将主机当前目录下的 logs 目录挂载到容器的 /var/log/mysql-v /usr/local/docker/mysql/data:/var/lib/mysql：将主机当前目录下的 data 目录挂载到容器的 /var/lib/mysql-e MYSQL_ROOT_PASSWORD=123456：初始化root用户的密码其中镜像mysql的存放目录如何获得：通过 1234$ docker run -it --rm mysql:5.7.22 bash 进入msql$ ls -al$ whereis mysqlmysql: &#x2F;usr&#x2F;bin&#x2F;mysql &#x2F;usr&#x2F;lib&#x2F;mysql &#x2F;etc&#x2F;mysql &#x2F;usr&#x2F;share&#x2F;mysql 3、修改max_allowed_packet 先暂时不适用conf这个数据卷12345docker run -p 3306:3306 --name mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;logs:&#x2F;var&#x2F;log&#x2F;mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql \\-e MYSQL_ROOT_PASSWORD&#x3D;123456 \\-d mysql:5.7.22 进入运行的mysql1$ docker exec -it mysql bash 找到mysql中的max_allowed_packet12$ cd &#x2F;etc&#x2F;mysql&#x2F;$ echo &quot;max_allowed_packet&#x3D; 128M&quot; &gt;&gt; mysql.conf.d 将mysql容器里的配置文件夹拷贝到宿主机的数据卷 先进入宿主机12345678$ cd &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;conf$ docker cp mysql:&#x2F;etc&#x2F;mysql .相当于在宿主机运行命令 拷贝容器mysql中&#x2F;etc&#x2F;mysql 文件夹 到 . 也就是本目录然后将mysql中的东西全部移动到conf下$ cd mysql$ mv *.* ..$ rm -fr mysql$ docker rm -f mysql容器id 重新启动一个新的容器123456docker run -p 3306:3306 --name mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;conf:&#x2F;etc&#x2F;mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;logs:&#x2F;var&#x2F;log&#x2F;mysql \\-v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;mysql&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql \\-e MYSQL_ROOT_PASSWORD&#x3D;123456 \\-d mysql:5.7.22","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker数据卷","slug":"docker/Docker数据卷","date":"2018-09-27T13:28:57.000Z","updated":"2020-06-10T08:13:26.459Z","comments":true,"path":"2018/09/27/docker/Docker数据卷/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E6%95%B0%E6%8D%AE%E5%8D%B7/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Docker数据卷","text":"&lt;Excerpt in index | 首页摘要&gt;Docker数据卷 &lt;The rest of contents | 余下全文&gt; Docker数据卷由于Docker容器—对象，容器一旦销毁则，容器内的数据则一并会被删除数据无法持久化 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享数据和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 数据卷。 选择 -v 还是 -–mount 参数Docker 新用户应该选择 --mount 参数，经验丰富的 Docker 使用者对 -v 或者 --volume 已经很熟悉了，但是推荐使用 --mount 参数。 创建一个数据卷1$ docker volume create my-vol 查看所有的 数据卷 123$ docker volume lslocal my-vol 在主机里使用以下命令可以查看指定 数据卷 的信息 1234567891011$ docker volume inspect my-vol[ &#123; &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;my-vol&#x2F;_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;] 启动一个挂载数据卷的容器在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run 中可以挂载多个 数据卷。 下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /webapp 目录。 123456$ docker run -d -P \\ --name web \\ # -v my-vol:&#x2F;wepapp \\ --mount source&#x3D;my-vol,target&#x3D;&#x2F;webapp \\ training&#x2F;webapp \\ python app.py 查看数据卷的具体信息在主机里使用以下命令可以查看 web 容器的信息 1$ docker inspect web 数据卷 信息在 “Mounts” Key 下面 123456789101112&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;my-vol&#x2F;_data&quot;, &quot;Destination&quot;: &quot;&#x2F;app&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125;], 删除数据卷1$ docker volume rm my-vol 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令 1$ docker volume prune 实例： 已tomcat为例 先创建自己的ROOT目录，将tomcat中的ROOT挂在到自己的ROOT目录 1234567$ cd &#x2F;usr&#x2F;local&#x2F;docker&#x2F;tomcat&#x2F;ROOT$ mkdir ROOT$ cd vi index.html 创建一个html$ docker run -p 8080:8080 --name tomcat -d -v &#x2F;usr&#x2F;local&#x2F;docker&#x2F;tomcat&#x2F;ROOT:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps&#x2F;ROOT tomcat -d守护太运行 -v挂在一个数据卷&#x2F;usr&#x2F;local&#x2F;docker&#x2F;tomcat&#x2F;ROOT 为宿主机目录 &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps&#x2F;ROOT 为镜像内tomcat中ROOT的目录","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker镜像(二)","slug":"docker/Docker镜像(二)","date":"2018-09-27T10:28:57.000Z","updated":"2020-06-10T08:13:26.460Z","comments":true,"path":"2018/09/27/docker/Docker镜像(二)/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E9%95%9C%E5%83%8F(%E4%BA%8C)/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Dockerfile镜像操作","text":"&lt;Excerpt in index | 首页摘要&gt;Dockerfile镜像操作 &lt;The rest of contents | 余下全文&gt; Dockerfile镜像操作1、WORKDIR 指定工作目录格式为 WORKDIR &lt;工作目录路径&gt;。 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误： 12RUN cd &#x2F;appRUN echo &quot;hello&quot; &gt; world.txt 如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。 2、COPY 复制文件格式： COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。 COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。比如： 1COPY package.json &#x2F;usr&#x2F;src&#x2F;app&#x2F; &lt;源路径&gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： 12COPY hom* &#x2F;mydir&#x2F;COPY hom?.txt &#x2F;mydir&#x2F; &lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 3、ADD高级复制ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如 &lt;源路径&gt; 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt; 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去。 在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu 中： 123FROM scratchADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz &#x2F;... 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 ADD 命令了。 在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。 另外需要注意的是，ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。 因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。 4、CMD容器启动命令CMD 指令的格式和 RUN 相似，也是两种格式： shell 格式：CMD &lt;命令&gt; exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...] 参数列表格式：CMD [&quot;参数1&quot;, &quot;参数2&quot;...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 &quot;，而不要使用单引号。 如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如： 1CMD echo $HOME 在实际执行中，会将其变更为： 1CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。 提到 CMD 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。 Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart/systemd 去启动后台服务，容器内没有后台服务的概念。 一些初学者将 CMD 写为： 1CMD service nginx start 然后发现容器执行后就立即退出了。甚至在容器内去使用 systemctl 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 而使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。而刚才说了 CMD service nginx start 会被理解为 CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 也就结束了，sh 作为主进程退出了，自然就会令容器退出。 正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如： 1CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 5、EXPOSE 暴露端口格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]。 EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 此外，在早期 Docker 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 Docker 引擎参数 --icc=false，当指定该参数后，容器间将默认无法互访，除非互相间使用了 --links 参数的容器才可以互通，并且只有镜像中 EXPOSE 所声明的端口才可以被访问。这个 --icc=false 的用法，在引入了 docker network 后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 6、ENTRYPOINT 入口点ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： 12345FROM ubuntu:16.04RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http:&#x2F;&#x2F;ip.cn&quot; ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： 12$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ 12$ docker run myip -idocker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://ip.cn 后面。而 -i 根本不是命令，所以自然找不到。 那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： 1$ docker run myip curl -s http:&#x2F;&#x2F;ip.cn -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： 12345FROM ubuntu:16.04RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http:&#x2F;&#x2F;ip.cn&quot; ] 这次我们再来尝试直接使用 docker run myip -i： 123456789101112131415161718$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通$ docker run myip -iHTTP&#x2F;1.1 200 OKServer: nginx&#x2F;1.8.0Date: Tue, 22 Nov 2016 05:12:40 GMTContent-Type: text&#x2F;html; charset&#x3D;UTF-8Vary: Accept-EncodingX-Powered-By: PHP&#x2F;5.6.24-1~dotdeb+7.1X-Cache: MISS from cache-2X-Cache-Lookup: MISS from cache-2:80X-Cache: MISS from proxy-2_6Transfer-Encoding: chunkedVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006Connection: keep-alive当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 场景二：应用运行前的准备工作启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。 比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。 此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。 这些准备工作是和容器 CMD 无关的，无论 CMD 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 &lt;CMD&gt;）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的： 12345678FROM alpine:3.4...RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis...ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]EXPOSE 6379CMD [ &quot;redis-server&quot; ] 可以看到其中为了 redis 服务创建了 redis 用户，并在最后指定了 ENTRYPOINT 为 docker-entrypoint.sh 脚本。 123456789#!&#x2F;bin&#x2F;sh...# allow the container to be started with &#96;--user&#96;if [ &quot;$1&quot; &#x3D; &#39;redis-server&#39; -a &quot;$(id -u)&quot; &#x3D; &#39;0&#39; ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot;fiexec &quot;$@&quot; 该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server 的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。比如： 12$ docker run -it redis iduid&#x3D;0(root) gid&#x3D;0(root) groups&#x3D;0(root) 7、ENV设置环境变量格式有两种： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 12ENV VERSION&#x3D;1.0 DEBUG&#x3D;on \\ NAME&#x3D;&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 node 镜像 Dockerfile 中，就有类似这样的代码： 123456789ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https:&#x2F;&#x2F;nodejs.org&#x2F;dist&#x2F;v$NODE_VERSION&#x2F;node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https:&#x2F;&#x2F;nodejs.org&#x2F;dist&#x2F;v$NODE_VERSION&#x2F;SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\\$&quot; SHASUMS256.txt | sha256sum -c - \\ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C &#x2F;usr&#x2F;local --strip-components&#x3D;1 \\ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \\ &amp;&amp; ln -s &#x2F;usr&#x2F;local&#x2F;bin&#x2F;node &#x2F;usr&#x2F;local&#x2F;bin&#x2F;nodejs 在这里先定义了环境变量 NODE_VERSION，其后的 RUN 这层里，多次使用 $NODE_VERSION 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 7.2.0 即可，Dockerfile 构建维护变得更轻松了。 下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD。 可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker镜像(一)","slug":"docker/Docker镜像（一）","date":"2018-09-27T09:28:57.000Z","updated":"2020-06-10T08:13:26.462Z","comments":true,"path":"2018/09/27/docker/Docker镜像（一）/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E9%95%9C%E5%83%8F%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Dockerfile定制镜像","text":"&lt;Excerpt in index | 首页摘要&gt;Dockerfile定制镜像 &lt;The rest of contents | 余下全文&gt; Dockerfile定制镜像镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 nginx 镜像为例，这次我们使用 Dockerfile 来定制。 首先建立一个Docker目录 123$ cd &#x2F;usr&#x2F;local$ mkdir docker$ cd docker 在一个空白目录中，建立一个文本文件，并命名为 Dockerfile： 123$ mkdir mynginx$ cd mynginx$ vi Dockerfile 其内容为： 12FROM nginxRUN echo &#39;&lt;h1&gt;Hello, Docker!&lt;&#x2F;h1&gt;&#39; &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html 这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN。 FROM 指定基础镜像所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 在 Docker Store 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。 如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 12FROM scratch... 如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。 RUN 执行命令RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种： shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。 1RUN echo &#39;&lt;h1&gt;Hello, Docker!&lt;&#x2F;h1&gt;&#39; &gt; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html exec 格式：RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]，这更像是函数调用中的格式。 docker exec -it 容器id bash 12既然 &#96;RUN&#96; 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样： FROM debian:jessie RUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz “http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis –strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install 123456789之前说过，Dockerfile 中每一个指令都会建立一层，&#96;RUN&#96; 也不例外。每一个 &#96;RUN&#96; 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，&#96;commit&#96; 这一层的修改，构成新的镜像。而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。这是很多初学 Docker 的人常犯的一个错误。*Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层。*上面的 &#96;Dockerfile&#96; 正确的写法应该是这样： FROM debian:jessie RUN buildDeps=’gcc libc6-dev make’ &amp;&amp; apt-get update &amp;&amp; apt-get install -y $buildDeps &amp;&amp; wget -O redis.tar.gz “http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; &amp;&amp; mkdir -p /usr/src/redis &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis –strip-components=1 &amp;&amp; make -C /usr/src/redis &amp;&amp; make -C /usr/src/redis install &amp;&amp; rm -rf /var/lib/apt/lists/* &amp;&amp; rm redis.tar.gz &amp;&amp; rm -r /usr/src/redis &amp;&amp; apt-get purge -y –auto-remove $buildDeps 123456789101112首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 &#96;RUN&#96; 对一一对应不同的命令，而是仅仅使用一个 &#96;RUN&#96; 指令，并使用 &#96;&amp;&amp;&#96; 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 &#96;\\&#96; 的命令换行方式，以及行首 &#96;#&#96; 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 &#96;apt&#96; 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。### WORKDIR 工作目录类似于cd ，而且通过交互式方式进入时候会直接进入到nginx目录下 WORKDIR /usr/share/nginx/ 切换到nginx目录下 12345678### 构建镜像好了，让我们再回到之前定制的 nginx 镜像的 Dockerfile 来。现在我们明白了这个 Dockerfile 的内容，那么让我们来构建这个镜像吧。在 &#96;Dockerfile&#96; 文件所在目录执行： $ docker build -t nginx:v3 .Sending build context to Docker daemon 2.048 kBStep 1 : FROM nginx —&gt; e43d811ce2f4Step 2 : RUN echo ‘Hello, Docker!‘ &gt; /usr/share/nginx/html/index.html —&gt; Running in 9cdc27646c7b —&gt; 44aa4490ce2cRemoving intermediate container 9cdc27646c7bSuccessfully built 44aa4490ce2c 1234从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 &#96;Step 2&#96; 中，如同我们之前所说的那样，&#96;RUN&#96; 指令启动了一个容器 &#96;9cdc27646c7b&#96;，执行了所要求的命令，并最后提交了这一层 &#96;44aa4490ce2c&#96;，随后删除了所用到的这个容器 &#96;9cdc27646c7b&#96;。这里我们使用了 &#96;docker build&#96; 命令进行镜像构建。其格式为： docker build [选项] &lt;上下文路径/URL/-&gt; 1234567891011121314在这里我们指定了最终镜像的名称 &#96;-t nginx:v3&#96;，构建成功后，我们可以像之前运行 &#96;nginx:v2&#96; 那样来运行这个镜像，其结果会和 &#96;nginx:v2&#96; 一样。### 镜像构建上下文（Context） 如果注意，会看到 &#96;docker build&#96; 命令最后有一个 &#96;.&#96;。&#96;.&#96; 表示当前目录，而 &#96;Dockerfile&#96; 就在当前目录，因此不少初学者以为这个路径是在指定 &#96;Dockerfile&#96; 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定**上下文路径**。那么什么是上下文呢？首先我们要理解 &#96;docker build&#96; 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 [Docker Remote API](https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;api&#x2F;docker_remote_api&#x2F;)，而如 &#96;docker&#96; 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 &#96;docker&#96; 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C&#x2F;S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。当我们进行镜像构建的时候，并非所有定制都会通过 &#96;RUN&#96; 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 &#96;COPY&#96; 指令、&#96;ADD&#96; 指令等。而 &#96;docker build&#96; 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端&#x2F;服务端的架构中，如何才能让服务端获得本地文件呢？这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，&#96;docker build&#96; 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。如果在 &#96;Dockerfile&#96; 中这么写： COPY ./package.json /app/ 123456789101112.&#x2F;package.json 这个路径指的是Docker server上下文的路径&#x2F;app&#x2F; 代表宿主机docker镜像里面文件夹的位置这并不是要复制执行 &#96;docker build&#96; 命令所在的目录下的 &#96;package.json&#96;，也不是复制 &#96;Dockerfile&#96; 所在目录下的 &#96;package.json&#96;，而是复制 **上下文（context）**目录下的 &#96;package.json&#96;。因此，&#96;COPY&#96; 这类指令中的源文件的路径都是*相对路径(Docker Server下带过来的)*。这也是初学者经常会问的为什么 &#96;COPY ..&#x2F;package.json &#x2F;app&#96; 或者 &#96;COPY &#x2F;opt&#x2F;xxxx &#x2F;app&#96; 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。现在就可以理解刚才的命令 &#96;docker build -t nginx:v3 .&#96; 中的这个 &#96;.&#96;，实际上是在指定上下文的目录，&#96;docker build&#96; 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。如果观察 &#96;docker build&#96; 输出，我们其实已经看到了这个发送上下文的过程： $ docker build -t nginx:v3 .Sending build context to Docker daemon 2.048 kB… 123456789101112131415161718理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 &#96;COPY &#x2F;opt&#x2F;xxxx &#x2F;app&#96; 不工作后，于是干脆将 &#96;Dockerfile&#96; 放到了硬盘根目录去构建，结果发现 &#96;docker build&#96; 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 &#96;docker build&#96; 打包整个硬盘，这显然是使用错误。一般来说，应该会将 &#96;Dockerfile&#96; 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 &#96;.gitignore&#96; 一样的语法写一个 &#96;.dockerignore&#96;，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。那么为什么会有人误以为 &#96;.&#96; 是指定 &#96;Dockerfile&#96; 所在目录呢？这是因为在默认情况下，如果不额外指定 &#96;Dockerfile&#96; 的话，会将上下文目录下的名为 &#96;Dockerfile&#96;的文件作为 Dockerfile。这只是默认行为，实际上 &#96;Dockerfile&#96; 的文件名并不要求必须为 &#96;Dockerfile&#96;，而且并不要求必须位于上下文目录中，比如可以用 &#96;-f ..&#x2F;Dockerfile.php&#96; 参数指定某个文件作为 &#96;Dockerfile&#96;。当然，一般大家习惯性的会使用默认的文件名 &#96;Dockerfile&#96;，以及会将其置于镜像构建上下文目录中。![1538029922544](http:&#x2F;&#x2F;www.zzpblog.cn&#x2F;img&#x2F;1538029922544.png)![1538029716957](http:&#x2F;&#x2F;www.zzpblog.cn&#x2F;img&#x2F;1538029716957.png)![1538030531675](http:&#x2F;&#x2F;www.zzpblog.cn&#x2F;img&#x2F;1538030531675.png)实例操作： $ ls -al总用量 4drwxr-xr-x. 2 root root 43 9月 27 15:05 .drwxr-xr-x. 3 root root 20 9月 27 12:02 ..-rw-r–r–. 1 root root 184 9月 27 15:05 Dockerfile-rw-r–r–. 1 root root 0 9月 27 15:01 index2.html 12Dockerfile FROM tomcatCOPY index2.html /usr/local/tomcat/webapps/ROOTindex2.html相当于Docker Server下的路径 /usr/local/tomcat/webapps/ROOT相当于构建的镜像下的路径 1234构建 docker build -t mytomcat .Sending build context to Docker daemon 7.168kBStep 1/4 : FROM tomcat —&gt; 41a54fe1f79dStep 2/4 : COPY index2.html /usr/local/tomcat/webapps/ROOT —&gt; Using cache —&gt; 9cd9b0da59c4Step 3/4 : WORKDIR /usr/local/tomcat/webapps/ROOT/ —&gt; Using cache —&gt; 5f678b9212c9Step 4/4 : RUN echo “hello Docker” &gt; /usr/local/tomcat/webapps/ROOT/index.html —&gt; Running in 64deebaa2c4aRemoving intermediate container 64deebaa2c4a —&gt; 99f30d526966Successfully built 99f30d526966Successfully tagged myshop:latest 12进入构建的镜像 docker run -it –rm myshop bashroot@886e2d6031b0:/usr/local/tomcat/webapps/ROOT#ls -altotal 192drwxr-xr-x. 1 root root 24 Sep 27 07:09 .drwxr-xr-x. 1 root root 18 Sep 4 22:29 ..-rw-r–r–. 1 root root 7142 Sep 4 22:30 RELEASE-NOTES.txtdrwxr-xr-x. 2 root root 21 Sep 12 20:48 WEB-INF-rw-r–r–. 1 root root 27235 Sep 4 22:30 asf-logo-wide.svg-rw-r–r–. 1 root root 713 Sep 4 22:29 bg-button.png-rw-r–r–. 1 root root 1918 Sep 4 22:29 bg-middle.png-rw-r–r–. 1 root root 1392 Sep 4 22:29 bg-nav-item.png-rw-r–r–. 1 root root 1401 Sep 4 22:29 bg-nav.png-rw-r–r–. 1 root root 3103 Sep 4 22:29 bg-upper.png-rw-r–r–. 1 root root 21630 Sep 4 22:29 favicon.ico-rw-r–r–. 1 root root 13 Sep 27 07:09 index.html-rw-r–r–. 1 root root 12290 Sep 4 22:30 index.jsp-rw-r–r–. 1 root root 0 Sep 27 07:01 index2.html 此文件已经拷贝-rw-r–r–. 1 root root 2376 Sep 4 22:29 tomcat-power.gif-rw-r–r–. 1 root root 5581 Sep 4 22:30 tomcat.css-rw-r–r–. 1 root root 2066 Sep 4 22:29 tomcat.gif-rw-r–r–. 1 root root 5103 Sep 4 22:29 tomcat.png-rw-r–r–. 1 root root 67795 Sep 4 22:30 tomcat.svg 1234567891011121314WORKDIR &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps&#x2F;ROOT&#x2F;RUN rm -fr *RUN echo &quot;hello Docker&quot; &gt; &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps&#x2F;ROOT&#x2F;index.html### 其它 &#96;docker build&#96; 的用法#### 直接用 Git repo 进行构建或许你已经注意到了，&#96;docker build&#96; 还支持从 URL 构建，比如可以直接从 Git repo 中构建： $ docker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14docker build https://github.com/twang2218/gitlab-ce-zh.git\\#:8.14Sending build context to Docker daemon 2.048 kBStep 1 : FROM gitlab/gitlab-ce:8.14.0-ce.08.14.0-ce.0: Pulling from gitlab/gitlab-ceaed15891ba52: Already exists773ae8583d14: Already exists… 1234这行命令指定了构建所需的 Git repo，并且指定默认的 &#96;master&#96; 分支，构建目录为 &#96;&#x2F;8.14&#x2F;&#96;，然后 Docker 就会自己去 &#96;git clone&#96; 这个项目、切换到指定分支、并进入到指定目录后开始构建。#### 用给定的 tar 压缩包构建 $ docker build http://server/context.tar.gz 1234如果所给出的 URL 不是个 Git repo，而是个 &#96;tar&#96; 压缩包，那么 Docker 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。#### 从标准输入中读取 Dockerfile 进行构建 docker build - &lt; Dockerfile 12或 cat Dockerfile | docker build - 1234如果标准输入传入的是文本文件，则将其视为 &#96;Dockerfile&#96;，并开始构建。这种形式由于直接从标准输入中读取 Dockerfile 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件 &#96;COPY&#96; 进镜像之类的事情。#### 从标准输入中读取上下文压缩包进行构建 $ docker build - &lt; context.tar.gz ``` 如果发现标准输入的文件格式是 gzip、bzip2 以及 xz 的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker镜像使用","slug":"docker/Docker镜像使用","date":"2018-09-27T06:28:57.000Z","updated":"2020-06-10T08:13:26.461Z","comments":true,"path":"2018/09/27/docker/Docker镜像使用/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E9%95%9C%E5%83%8F%E4%BD%BF%E7%94%A8/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Docker镜像使用、获取、列表、删除","text":"&lt;Excerpt in index | 首页摘要&gt;Docker镜像使用、获取、列表、删除 &lt;The rest of contents | 余下全文&gt; Docker镜像的使用1、获取镜像之前提到过，Docker Hub 上有大量的高质量的镜像可以用，这里我们就说一下怎么获取这些镜像。 从 Docker 镜像仓库获取镜像的命令是 docker pull。其命令格式为： 1docker pull [选项] [Docker Registry 地址[:端口号]&#x2F;]仓库名[:标签] 具体的选项可以通过 docker pull --help 命令看到，这里我们说一下镜像名称的格式。 Docker 镜像仓库地址：地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。 仓库名：如之前所说，这里的仓库名是两段式名称，即 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 比如： 123456789$ docker pull ubuntu:16.0416.04: Pulling from library&#x2F;ubuntubf5d46315322: Pull complete9f13e0ac480c: Pull completee8988b5b3097: Pull complete40af181810e7: Pull completee6f7c7e5c03e: Pull completeDigest: sha256:147913621d9cdea08853f6ba9116c2e27a3ceffecf3b492983ae97c3d643fbbeStatus: Downloaded newer image for ubuntu:16.04 上面的命令中没有给出 Docker 镜像仓库地址，因此将会从 Docker Hub 获取镜像。而镜像名称是 ubuntu:16.04，因此将会获取官方镜像 library/ubuntu 仓库中标签为 16.04 的镜像。 从下载过程中可以看到我们之前提及的分层存储的概念，镜像是由多层存储所构成。下载也是一层层的去下载，并非单一文件。下载过程中给出了每一层的 ID 的前 12 位。并且下载结束后，给出该镜像完整的 sha256 的摘要，以确保下载一致性。 在使用上面命令的时候，你可能会发现，你所看到的层 ID 以及 sha256 的摘要和这里的不一样。这是因为官方镜像是一直在维护的，有任何新的 bug，或者版本更新，都会进行修复再以原来的标签发布，这样可以确保任何使用这个标签的用户可以获得更安全、更稳定的镜像。 如果从 Docker Hub 下载镜像非常缓慢，可以参照 镜像加速器 配置加速器。 运行有了镜像后，我们就能够以这个镜像为基础启动并运行一个容器。以上面的 ubuntu:16.04 为例，如果我们打算启动里面的 bash 并且进行交互式操作的话，可以执行下面的命令。 1234567891011121314$ docker run -it --rm \\ ubuntu:16.04 \\ bashroot@e7009c6ce357:&#x2F;# cat &#x2F;etc&#x2F;os-releaseNAME&#x3D;&quot;Ubuntu&quot;VERSION&#x3D;&quot;16.04.4 LTS, Trusty Tahr&quot;ID&#x3D;ubuntuID_LIKE&#x3D;debianPRETTY_NAME&#x3D;&quot;Ubuntu 16.04.4 LTS&quot;VERSION_ID&#x3D;&quot;16.04&quot;HOME_URL&#x3D;&quot;http:&#x2F;&#x2F;www.ubuntu.com&#x2F;&quot;SUPPORT_URL&#x3D;&quot;http:&#x2F;&#x2F;help.ubuntu.com&#x2F;&quot;BUG_REPORT_URL&#x3D;&quot;http:&#x2F;&#x2F;bugs.launchpad.net&#x2F;ubuntu&#x2F;&quot; docker run 就是运行容器的命令，我们这里简要的说明一下上面用到的参数。 -it：已交互的方式运行容器，这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 ubuntu:16.04：这是指用 ubuntu:16.04 镜像为基础来启动容器。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 进入容器后，我们可以在 Shell 下操作，执行任何所需的命令。这里，我们执行了 cat /etc/os-release，这是 Linux 常用的查看当前系统版本的命令，从返回的结果可以看到容器内是 Ubuntu 16.04.4 LTS 系统。 最后我们通过 exit 退出了这个容器。 已交互的方式运行容器123$ docker run -p 8080:8080 tomcat$ docker run -P tomcat P代表随机端口$ docker exec -it 容器id bash&#96; 2、列出镜像要想列出已经下载下来的镜像，可以使用 docker image ls或者使用 docker images 列出所有镜像 命令。 123456789$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEredis latest 5f515359c7f8 5 days ago 183 MBnginx latest 05a60462f8ba 5 days ago 181 MBmongo 3.2 fe9198c04d62 5 days ago 342 MB&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MBubuntu 16.04 f753707788c5 4 weeks ago 127 MBubuntu latest f753707788c5 4 weeks ago 127 MBubuntu 14.04 1e0c3dd64ccd 4 weeks ago 188 MB 列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 其中仓库名、标签在之前的基础概念章节已经介绍过了。镜像 ID 则是镜像的唯一标识，一个镜像可以对应多个标签。因此，在上面的例子中，我们可以看到 ubuntu:16.04 和 ubuntu:latest 拥有相同的 ID，因为它们对应的是同一个镜像。 镜像体积如果仔细观察，会注意到，这里标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，ubuntu:16.04 镜像大小，在这里是 127 MB，但是在 Docker Hub 显示的却是 50 MB。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而 docker image ls 显示的是镜像下载到本地后，展开的大小，准确说，是展开后的各层所占空间的总和，因为镜像到本地后，查看空间的时候，更关心的是本地磁盘空间占用的大小。 另外一个需要注意的问题是，docker image ls 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。 你可以通过以下命令来便捷的查看镜像、容器、数据卷所占用的空间。 1234567$ docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 24 0 1.992GB 1.992GB (100%)Containers 1 0 62.82MB 62.82MB (100%)Local Volumes 9 0 652.2MB 652.2MB (100%)Build Cache 0B 0B 虚悬镜像上面的镜像列表中，还可以看到一个特殊的镜像，这个镜像既没有仓库名，也没有标签，均为 &lt;none&gt;。： 1&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB 这个镜像原本是有镜像名和标签的，原来为 mongo:3.2，随着官方镜像维护，发布了新版本后，重新 docker pull mongo:3.2 时，mongo:3.2 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 &lt;none&gt;。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 &lt;none&gt; 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像： 123$ docker image ls -f dangling=trueREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB 一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。注意！！！！需要先删除容器，不然镜像无法删除！！ 1$ docker image prune 中间层镜像为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。 1$ docker image ls -a 这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 列出部分镜像不加任何参数的情况下，docker image ls 会列出所有顶级镜像，但是有时候我们只希望列出部分镜像。docker image ls 有好几个参数可以帮助做到这个事情。 根据仓库名列出镜像 12345$ docker image ls ubuntuREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 f753707788c5 4 weeks ago 127 MBubuntu latest f753707788c5 4 weeks ago 127 MBubuntu 14.04 1e0c3dd64ccd 4 weeks ago 188 MB 列出特定的某个镜像，也就是说指定仓库名和标签 123$ docker image ls ubuntu:16.04REPOSITORY TAG IMAGE ID CREATED SIZEubuntu 16.04 f753707788c5 4 weeks ago 127 MB 除此以外，docker image ls 还支持强大的过滤器参数 --filter，或者简写 -f。之前我们已经看到了使用过滤器来列出虚悬镜像的用法，它还有更多的用法。比如，我们希望看到在 mongo:3.2 之后建立的镜像，可以用下面的命令： 1234$ docker image ls -f since=mongo:3.2REPOSITORY TAG IMAGE ID CREATED SIZEredis latest 5f515359c7f8 5 days ago 183 MBnginx latest 05a60462f8ba 5 days ago 181 MB 想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可。 此外，如果镜像构建时，定义了 LABEL，还可以通过 LABEL 来过滤。 12$ docker image ls -f label=com.example.version=0.1... 以特定格式显示默认情况下，docker image ls 会输出一个完整的表格，但是我们并非所有时候都会需要这些内容。比如，刚才删除虚悬镜像的时候，我们需要利用 docker image ls 把所有的虚悬镜像的 ID 列出来，然后才可以交给 docker image rm 命令作为参数来删除指定的这些镜像，这个时候就用到了 -q 参数。 12345678$ docker image ls -q5f515359c7f805a60462f8bafe9198c04d6200285df0df87f753707788c5f753707788c51e0c3dd64ccd --filter 配合 -q 产生出指定范围的 ID 列表，然后送给另一个 docker 命令作为参数，从而针对这组实体成批的进行某种操作的做法在 Docker 命令行使用过程中非常常见，不仅仅是镜像，将来我们会在各个命令中看到这类搭配以完成很强大的功能。因此每次在文档看到过滤器后，可以多注意一下它们的用法。 另外一些时候，我们可能只是对表格的结构不满意，希望自己组织列；或者不希望有标题，这样方便其它程序解析结果等，这就用到了 Go 的模板语法。 比如，下面的命令会直接列出镜像结果，并且只包含镜像ID和仓库名： 12345678$ docker image ls --format \"&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;\"5f515359c7f8: redis05a60462f8ba: nginxfe9198c04d62: mongo00285df0df87: &lt;none&gt;f753707788c5: ubuntuf753707788c5: ubuntu1e0c3dd64ccd: ubuntu 或者打算以表格等距显示，并且有标题行，和默认一样，不过自己定义列： 123456789$ docker image ls --format \"table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;\"IMAGE ID REPOSITORY TAG5f515359c7f8 redis latest05a60462f8ba nginx latestfe9198c04d62 mongo 3.200285df0df87 &lt;none&gt; &lt;none&gt;f753707788c5 ubuntu 16.04f753707788c5 ubuntu latest1e0c3dd64ccd ubuntu 14.04 3、删除本地镜像如果要删除本地的镜像，注意！！！！需要先删除容器，不然镜像无法删除！！可以使用 docker image rm 命令，其格式为： 123$ docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...]或者$ docker rmi [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 用 ID、镜像名、摘要删除镜像其中，&lt;镜像&gt; 可以是 镜像短 ID、镜像长 ID、镜像名 或者 镜像摘要。 比如我们有这么一些镜像： 123456$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 0584b3d2cf6d 3 weeks ago 196.5 MBredis alpine 501ad78535f0 3 weeks ago 21.03 MBdocker latest cf693ec9b5c7 3 weeks ago 105.1 MBnginx latest e43d811ce2f4 5 weeks ago 181.5 MB 我们可以用镜像的完整 ID，也称为 长 ID，来删除镜像。使用脚本的时候可能会用长 ID，但是人工输入就太累了，所以更多的时候是用 短 ID 来删除镜像。docker image ls 默认列出的就已经是短 ID 了，一般取前3个字符以上，只要足够区分于别的镜像就可以了。 比如这里，如果我们要删除 redis:alpine 镜像，可以执行： 123456789$ docker image rm 501Untagged: redis:alpineUntagged: redis@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86dDeleted: sha256:501ad78535f015d88872e13fa87a828425117e3d28075d0c117932b05bf189b7Deleted: sha256:96167737e29ca8e9d74982ef2a0dda76ed7b430da55e321c071f0dbff8c2899bDeleted: sha256:32770d1dcf835f192cafd6b9263b7b597a1778a403a109e2cc2ee866f74adf23Deleted: sha256:127227698ad74a5846ff5153475e03439d96d4b1c7f2a449c7a826ef74a2d2faDeleted: sha256:1333ecc582459bac54e1437335c0816bc17634e131ea0cc48daa27d32c75eab3Deleted: sha256:4fc455b921edf9c4aea207c51ab39b10b06540c8b4825ba57b3feed1668fa7c7 我们也可以用镜像名，也就是 &lt;仓库名&gt;:&lt;标签&gt;，来删除镜像。 12345$ docker image rm centosUntagged: centos:latestUntagged: centos@sha256:b2f9d1c0ff5f87a4743104d099a3d561002ac500db1b9bfa02a783a46e0d366cDeleted: sha256:0584b3d2cf6d235ee310cf14b54667d889887b838d3f3d3033acd70fc3c48b8aDeleted: sha256:97ca462ad9eeae25941546209454496e1d66749d53dfa2ee32bf1faabd239d38 当然，更精确的是使用 镜像摘要 删除镜像。 123456$ docker image ls --digestsREPOSITORY TAG DIGEST IMAGE ID CREATED SIZEnode slim sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 6e0c4c8e3913 3 weeks ago 214 MB$ docker image rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228Untagged: node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 Untagged 和 Deleted如果观察上面这几个命令的运行输出信息的话，你会注意到删除行为分为两类，一类是 Untagged，另一类是 Deleted。我们之前介绍过，镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。 因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的 Untagged 的信息。因为一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么 Delete 行为就不会发生。所以并非所有的 docker image rm 都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变动非常容易，因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。直到没有任何层依赖当前层时，才会真实的删除当前层。这就是为什么，有时候会奇怪，为什么明明没有别的标签指向这个镜像，但是它还是存在的原因，也是为什么有时候会发现所删除的层数和自己 docker pull 看到的层数不一样的源。 除了镜像依赖以外，还需要注意的是容器对镜像的依赖。如果有用这个镜像启动的容器存在（即使容器没有运行），那么同样不可以删除这个镜像。之前讲过，容器是以镜像为基础，再加一层容器存储层，组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖的，那么删除必然会导致故障。如果这些容器是不需要的，应该先将它们删除，然后再来删除镜像。 用 docker image ls 命令来配合像其它可以承接多个实体的命令一样，可以使用 docker image ls -q 来配合使用 docker image rm，这样可以成批的删除希望删除的镜像。我们在“镜像列表”章节介绍过很多过滤镜像列表的方式都可以拿过来使用。 比如，我们需要删除所有仓库名为 redis 的镜像： 1$ docker image rm $(docker image ls -q redis) 或者删除所有在 mongo:3.2 之前的镜像： 1$ docker image rm $(docker image ls -q -f before&#x3D;mongo:3.2) 充分利用你的想象力和 Linux 命令行的强大，你可以完成很多非常赞的功能。 CentOS/RHEL 的用户需要注意的事项在 Ubuntu/Debian 上有 UnionFS 可以使用，如 aufs 或者 overlay2，而 CentOS 和 RHEL 的内核中没有相关驱动。因此对于这类系统，一般使用 devicemapper 驱动利用 LVM 的一些机制来模拟分层存储。这样的做法除了性能比较差外，稳定性一般也不好，而且配置相对复杂。Docker 安装在 CentOS/RHEL 上后，会默认选择 devicemapper，但是为了简化配置，其 devicemapper 是跑在一个稀疏文件模拟的块设备上，也被称为 loop-lvm。这样的选择是因为不需要额外配置就可以运行 Docker，这是自动配置唯一能做到的事情。但是 loop-lvm 的做法非常不好，其稳定性、性能更差，无论是日志还是 docker info 中都会看到警告信息。官方文档有明确的文章讲解了如何配置块设备给 devicemapper 驱动做存储层的做法，这类做法也被称为配置 direct-lvm。 除了前面说到的问题外，devicemapper + loop-lvm 还有一个缺陷，因为它是稀疏文件，所以它会不断增长。用户在使用过程中会注意到 /var/lib/docker/devicemapper/devicemapper/data 不断增长，而且无法控制。很多人会希望删除镜像或者可以解决这个问题，结果发现效果并不明显。原因就是这个稀疏文件的空间释放后基本不进行垃圾回收的问题。因此往往会出现即使删除了文件内容，空间却无法回收，随着使用这个稀疏文件一直在不断增长。 所以对于 CentOS/RHEL 的用户来说，在没有办法使用 UnionFS 的情况下，一定要配置 direct-lvm 给 devicemapper，无论是为了性能、稳定性还是空间利用率。 或许有人注意到了 CentOS 7 中存在被 backports 回来的 overlay 驱动，不过 CentOS 里的这个驱动达不到生产环境使用的稳定程度，所以不推荐使用。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker安装","slug":"docker/Docker安装","date":"2018-09-27T05:28:57.000Z","updated":"2020-06-10T08:13:26.457Z","comments":true,"path":"2018/09/27/docker/Docker安装/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E5%AE%89%E8%A3%85/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Docker分为两个版本：Docker-ce 社区版（免费）、Docker-EE 企业版（收费）","text":"&lt;Excerpt in index | 首页摘要&gt;Docker分为两个版本：Docker-ce 社区版（免费）、Docker-EE 企业版（收费） &lt;The rest of contents | 余下全文&gt; 一、安装dockerDocker分为两个版本：Docker-ce 社区版（免费）、Docker-EE 企业版（收费） 1、Ubuntu 安装 Docker 警告：切勿在没有配置 Docker APT 源的情况下直接使用 apt 命令安装 Docker. 准备工作系统要求Docker CE 支持以下版本的 Ubuntu 操作系统： Artful 17.10 (Docker CE 17.11 Edge +) Xenial 16.04 (LTS) Trusty 14.04 (LTS) Docker CE 可以安装在 64 位的 x86 平台或 ARM 平台上。Ubuntu 发行版中，LTS（Long-Term-Support）长期支持版本，会获得 5 年的升级维护支持，这样的版本会更稳定，因此在生产环境中推荐使用 LTS 版本,当前最新的 LTS 版本为 Ubuntu 16.04。 卸载旧版本旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： 123$ sudo apt-get remove docker \\ docker-engine \\ docker.io Ubuntu 14.04 可选内核模块从 Ubuntu 14.04 开始，一部分内核模块移到了可选内核模块包 (linux-image-extra-*) ，以减少内核软件包的体积。正常安装的系统应该会包含可选内核模块包，而一些裁剪后的系统可能会将其精简掉。AUFS 内核驱动属于可选内核模块的一部分，作为推荐的 Docker 存储层驱动，一般建议安装可选内核模块包以使用 AUFS。 如果系统没有安装可选内核模块的话，可以执行下面的命令来安装可选内核模块包： 12345$ sudo apt-get update$ sudo apt-get install \\ linux-image-extra-$(uname -r) \\ linux-image-extra-virtual Ubuntu 16.04 +Ubuntu 16.04 + 上的 Docker CE 默认使用 overlay2 存储层驱动,无需手动配置。 使用 APT 安装由于 apt 源使用 HTTPS 以确保软件下载过程中不被篡改。因此，我们首先需要添加使用 HTTPS 传输的软件包以及 CA 证书。 1234567$ sudo apt-get update$ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 为了确认所下载软件包的合法性，需要添加软件源的 GPG 密钥。 12345$ curl -fsSL https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -# 官方源# $ curl -fsSL https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add - 然后，我们需要向 source.list 中添加 Docker 软件源 1234567891011$ sudo add-apt-repository \\ &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;ubuntu \\ $(lsb_release -cs) \\ stable&quot;# 官方源# $ sudo add-apt-repository \\# &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;ubuntu \\# $(lsb_release -cs) \\# stable&quot; 以上命令会添加稳定版本的 Docker CE APT 镜像源，如果需要最新或者测试版本的 Docker CE 请将 stable 改为 edge 或者 test。从 Docker 17.06 开始，edge test 版本的 APT 镜像源也会包含稳定版本的 Docker。 安装 Docker CE更新 apt 软件包缓存，并安装 docker-ce： 123$ sudo apt-get update$ sudo apt-get install docker-ce 使用脚本自动安装在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Ubuntu 系统上可以使用这套脚本安装： 123$ curl -fsSL get.docker.com -o get-docker.sh# 可能会出现 404 错误，请移步下面的特别说明$ sudo sh get-docker.sh --mirror Aliyun 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker CE 的 Edge 版本安装在系统中。 特别说明2018 年 7 月 21 日，貌似阿里云这边在做调整，故导致 Docker 的 Aliyun 安装脚本不可用，是永久性还是临时性的尚不清除，如果你已经按照之前的操作安装 Docker，请按以下步骤进行修复并重新安装 如果已经使用了 Aliyun 脚本安装并成功的 请先卸载 Docker，命令为：apt-get autoremove docker-ce 删除 /etc/apt/sources.list.d 目录下的 docker.list 文件 使用 AzureChinaCloud 镜像脚本重新安装，命令为：sudo sh get-docker.sh --mirror AzureChinaCloud 启动 Docker CE12$ sudo systemctl enable docker$ sudo systemctl start docker Ubuntu 14.04 请使用以下命令启动： 1$ sudo service docker start 建立 docker 用户组默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： 1$ sudo groupadd docker 将当前用户加入 docker 组： 1$ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确12345678910111213141516171819202122232425262728$ docker run hello-worldUnable to find image &#39;hello-world:latest&#39; locallylatest: Pulling from library&#x2F;hello-worldca4f61b1923c: Pull completeDigest: sha256:be0cd392e45be79ffeffa6b05338b98ebb16c87b255f48e297ec7f98e123905cStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https:&#x2F;&#x2F;cloud.docker.com&#x2F;For more examples and ideas, visit: https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;userguide&#x2F; 若能正常输出以上信息，则说明安装成功。 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，强烈建议安装 Docker 之后配置 国内镜像加速。 参考文档 Docker 官方 Ubuntu 安装文档 2、CentOS 安装 Docker 警告：切勿在没有配置 Docker YUM 源的情况下直接使用 yum 命令安装 Docker. 准备工作系统要求Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10。 CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。 卸载旧版本旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： 12345678910$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 使用 yum 安装执行以下命令安装依赖包： 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 执行下面的命令添加 yum 软件源： 123456789$ sudo yum-config-manager \\ --add-repo \\ https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo# 官方源# $ sudo yum-config-manager \\# --add-repo \\# https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo 如果需要最新版本的 Docker CE 请使用以下命令： 1$ sudo yum-config-manager --enable docker-ce-edge 如果需要测试版本的 Docker CE 请使用以下命令： 1$ sudo yum-config-manager --enable docker-ce-test 安装 Docker CE更新 yum 软件源缓存，并安装 docker-ce。 12$ sudo yum makecache fast$ sudo yum install docker-ce 使用脚本自动安装在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装： 12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker CE 的 Edge 版本安装在系统中。 启动 Docker CE12$ sudo systemctl enable docker$ sudo systemctl start docker 建立 docker 用户组默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： 1$ sudo groupadd docker 将当前用户加入 docker 组： 1$ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确12345678910111213141516171819202122232425262728$ docker run hello-worldUnable to find image &#39;hello-world:latest&#39; locallylatest: Pulling from library&#x2F;hello-worldca4f61b1923c: Pull completeDigest: sha256:be0cd392e45be79ffeffa6b05338b98ebb16c87b255f48e297ec7f98e123905cStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https:&#x2F;&#x2F;cloud.docker.com&#x2F;For more examples and ideas, visit: https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;userguide&#x2F; 若能正常输出以上信息，则说明安装成功。 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，强烈建议安装 Docker 之后配置 国内镜像加速。 添加内核参数默认配置下，如果在 CentOS 使用 Docker CE 看到下面的这些警告信息： 12WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled 请添加内核配置参数以启用这些功能。 1234$ sudo tee -a &#x2F;etc&#x2F;sysctl.conf &lt;&lt;-EOFnet.bridge.bridge-nf-call-ip6tables &#x3D; 1net.bridge.bridge-nf-call-iptables &#x3D; 1EOF 然后重新加载 sysctl.conf 即可 1$ sudo sysctl -p 参考文档 Docker 官方 CentOS 安装文档。 3、Docker 镜像加速器国内从 Docker Hub 拉取镜像有时会遇到困难，此时可以配置镜像加速器。Docker 官方和国内很多云服务商都提供了国内加速器服务，例如： Docker 官方提供的中国 registry mirror 阿里云加速器 DaoCloud 加速器 我们以 Docker 官方加速器为例进行介绍。 Ubuntu 14.04、Debian 7 Wheezy对于使用 upstart 的系统而言，编辑 /etc/default/docker 文件，在其中的 DOCKER_OPTS 中配置加速器地址： 1DOCKER_OPTS&#x3D;&quot;--registry-mirror&#x3D;https:&#x2F;&#x2F;registry.docker-cn.com&quot; 重新启动服务。 1$ sudo service docker restart Ubuntu 16.04+、Debian 8+、CentOS 7对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 12345&#123; &quot;registry-mirrors&quot;: [ &quot;https:&#x2F;&#x2F;registry.docker-cn.com&quot; ]&#125; 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 注意：如果您之前查看旧教程，修改了 docker.service 文件内容，请去掉您添加的内容（--registry-mirror=https://registry.docker-cn.com），这里不再赘述。 Windows 10对于使用 Windows 10 的系统，在系统右下角托盘 Docker 图标内右键菜单选择 Settings，打开配置窗口后左侧导航菜单选择 Daemon。在 Registry mirrors一栏中填写加速器地址 https://registry.docker-cn.com，之后点击 Apply 保存后 Docker 就会重启并应用配置的镜像地址了。 macOS对于使用 macOS 的用户，在任务栏点击 Docker for mac 应用图标 -&gt; Perferences… -&gt; Daemon -&gt; Registry mirrors。在列表中填写加速器地址 https://registry.docker-cn.com。修改完成之后，点击 Apply &amp; Restart 按钮，Docker 就会重启并应用配置的镜像地址了。 检查加速器是否生效配置加速器之后，如果拉取镜像仍然十分缓慢，请手动检查加速器配置是否生效，在命令行执行 docker info，如果从结果中看到了如下内容，说明配置成功。 12Registry Mirrors: https:&#x2F;&#x2F;registry.docker-cn.com&#x2F;","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker仓库","slug":"docker/Docker仓库","date":"2018-09-27T03:28:57.000Z","updated":"2020-06-10T08:13:26.455Z","comments":true,"path":"2018/09/27/docker/Docker仓库/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E4%BB%93%E5%BA%93/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;公有 Docker Registry 私有 Docker Registry","text":"&lt;Excerpt in index | 首页摘要&gt;公有 Docker Registry 私有 Docker Registry &lt;The rest of contents | 余下全文&gt; 镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。 仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。 公有 Docker RegistryDocker Registry 公开服务是开放给用户使用、允许用户管理镜像的 Registry 服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。 最常使用的 Registry 公开服务是官方的 Docker Hub，这也是默认的 Registry，并拥有大量的高质量的官方镜像。除此以外，还有 CoreOS 的 Quay.io，CoreOS 相关的镜像存储在这里；Google 的 Google Container Registry，Kubernetes 的镜像使用的就是这个服务。 由于某些原因，在国内访问这些服务可能会比较慢。国内的一些云服务商提供了针对 Docker Hub 的镜像服务（Registry Mirror），这些镜像服务被称为加速器。常见的有 阿里云加速器、DaoCloud 加速器 等。使用加速器会直接从国内的地址下载 Docker Hub 的镜像，比直接从 Docker Hub 下载速度会提高很多。 国内也有一些云服务商提供类似于 Docker Hub 的公开服务。比如 时速云镜像仓库、网易云镜像服务、DaoCloud 镜像市场、阿里云镜像库 等。 私有 Docker Registry除了使用公开服务外，用户还可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。 开源的 Docker Registry 镜像只提供了 Docker Registry API 的服务端实现，足以支持 docker 命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。在官方的商业化版本 Docker Trusted Registry 中，提供了这些高级功能。 除了官方的 Docker Registry 外，还有第三方软件实现了 Docker Registry API，甚至提供了用户界面以及一些高级功能。比如，VMWare Harbor 和 Sonatype Nexus。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker引擎架构","slug":"docker/Docker引擎架构","date":"2018-09-27T02:28:57.000Z","updated":"2020-06-10T08:13:26.458Z","comments":true,"path":"2018/09/27/docker/Docker引擎架构/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;Docker 引擎是一个包含以下主要组件的客户端服务器应用程序。 一种服务器，它是一种称为守护进程并且长时间运行的程序。REST API用于指定程序可以用来与守护进程通信的接口，并指示它做什么。一个有命令行界面 (CLI) 工具的客户端。","text":"&lt;Excerpt in index | 首页摘要&gt;Docker 引擎是一个包含以下主要组件的客户端服务器应用程序。 一种服务器，它是一种称为守护进程并且长时间运行的程序。REST API用于指定程序可以用来与守护进程通信的接口，并指示它做什么。一个有命令行界面 (CLI) 工具的客户端。 &lt;The rest of contents | 余下全文&gt; Docker引擎Docker 引擎是一个包含以下主要组件的客户端服务器应用程序。 一种服务器，它是一种称为守护进程并且长时间运行的程序。REST API用于指定程序可以用来与守护进程通信的接口，并指示它做什么。一个有命令行界面 (CLI) 工具的客户端。Docker 引擎组件的流程如下图所示： 如图所示，Docker需要学习的由容器、镜像、网络、数据卷，通过Dockercli命令行工具操作 Docker架构Docker 使用客户端-服务器 (C/S) 架构模式，使用远程 API 来管理和创建 Docker 容器。 Docker 容器通过 Docker 镜像来创建。 容器与镜像的关系类似于面向对象编程中的对象与类。 例如：User.class 镜像 User user=new User() 容器，也就是说定制镜像，部署只需要new一个容器就可以直接使用 Docker 面向对象 容器 对象 镜像 类 图例说明：docker build：构建命令–docker守护进程—构建Ubuntu镜像—docker run镜像，启动容器docker pull：拉取走官方找取镜像比如Ubuntu镜像—docker run镜像，启动容器 标题 说明 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板。 容器(Container) 容器是独立运行的一个或一组应用。 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker API (https://docs.docker.com/reference/api/docker_remote_api) 与 Docker 的守护进程通信。 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 仓库(Registry) Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。 Docker Machine Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"为什么用Docker","slug":"docker/为什么要用Docker","date":"2018-09-27T01:28:57.000Z","updated":"2020-06-10T08:45:11.896Z","comments":true,"path":"2018/09/27/docker/为什么要用Docker/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8Docker/","excerpt":"作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。","text":"作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。 而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易（例如 TOMCAT继承JAVA，那么TOMCAT就默认已经装了JAVA），也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Docker初探","slug":"docker/Docker初探","date":"2018-09-27T00:28:57.000Z","updated":"2020-06-10T08:13:26.456Z","comments":true,"path":"2018/09/27/docker/Docker初探/","link":"","permalink":"http://new.zzpblog.cn/2018/09/27/docker/Docker%E5%88%9D%E6%8E%A2/","excerpt":"&lt;Excerpt in index | 首页摘要&gt;关于Docker是什么","text":"&lt;Excerpt in index | 首页摘要&gt;关于Docker是什么 &lt;The rest of contents | 余下全文&gt; Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目已经超过 4 万 6 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 我们现在使用的是1.12版本，从1.11到1.12是一个里程碑 hypervisor：一种运行在物理服务器和操作系统之间的中间层软件，可以允许多个操作系统和应用共享一套基础物理硬件。可以将hypervisor看做是虚拟环境中的“元”操作系统，可以协调访问服务器上的所有物理设备和虚拟机，所以又称为虚拟机监视器（virtual machine monitor）。hypervisor是所有虚拟化技术的核心，非中断的支持多工作负载迁移是hypervisor的基本功能。当服务器启动并执行hypervisor时，会给每一台虚拟机分配适量的内存，cpu，网络和磁盘资源，并且加载所有虚拟机的客户操作系统。 原始结构 传统虚拟化： 传统虚拟化技术是独占资源的，只能利用分配给它的部分资源 比如：一台计算机：CPU i7 4核 内存16GB VMware 2GB内存 则这台计算机还剩余14GB可用 独占资源 VMware 2GB内存 则这台计算机还剩余12GB可用 独占资源 当VMware中有一个应用app，他占用14GB内存，则会出现内存溢出 Docker: Docker可以利用宿主机的全部资源，共享资源","categories":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"Vue组件库","slug":"vue/vue组件库","date":"2018-09-26T04:09:57.000Z","updated":"2020-06-27T05:57:06.213Z","comments":true,"path":"2018/09/26/vue/vue组件库/","link":"","permalink":"http://new.zzpblog.cn/2018/09/26/vue/vue%E7%BB%84%E4%BB%B6%E5%BA%93/","excerpt":"===官方=== https://github.com/vuejs/vue","text":"===官方=== https://github.com/vuejs/vue vue-components组件库 —PC端— https://github.com/ElemeFE/element Vue2.0 PC端UI组件库 https://github.com/iview/iview 一套基于 Vue.js 的高质量 UI 组件库 https://github.com/jackbarham/vuejs-style-guide Vue UI框架 vibecast UI风格 https://github.com/luojilab/radon-ui 一个帮助你快速开发产品的Vue组件库，简洁好用，效率高，让你摆脱各种定制化的烦恼 https://github.com/myronliu347/vue-carbon 基于vue开发的material design ui库 https://github.com/N3-components/N3-components Vue UI组件库 https://github.com/okoala/vue-antd Vue版 ant.design UI组件库 https://github.com/posva/vue-mdl Material Design Lite 组件库 https://github.com/rafaelpimpa/buefy 基于 Bulma 的 Vue.js 轻量级 UI 组件库 https://github.com/AT-UI/at-ui at-ui 一款基于 Vue.js 2.0 的前端 UI 组件库，主要用于快速开发 PC 网站产品 https://github.com/vuetifyjs/vuetify 基于 Material 的 Vue.js 2.0 前端 UI 组件库 https://github.com/myliang/fish-ui 一个 Vue.js 2.0 的 Web UI 工具库 https://github.com/wmfe/xcui 基于Vue2.0 的桌面端组件库 —移动端— https://github.com/airyland/vuxvue 微信UI组件库 https://github.com/mennghao/vue-muiVue UI组件库 https://github.com/wdfe/wdui基于 Vue 2.0 的移动 UI 组件库 https://github.com/youzan/vant有赞开发的基于 Vue.js 2.0 的 UI 组件库 https://github.com/ydcss/vue-ydui一只基于Vue2.x的移动端&amp;微信UI。 https://www.awesomes.cn/repo/didi/cube-ui滴滴团队开发的一套基于 Vue.js 实现的精致移动端组件库 https://github.com/zdliuccit/ml-ui一套为开发者、设计师和产品经理准备的基于 Vue 2 的移动端组件库 vue-form表单 https://github.com/lincenying/vue2-ajax-form Vue2 ajax提交表单组件 https://github.com/monterail/vue-multiselect Vue 模拟select组件 https://github.com/jinzhe/vue-calendar Vue 日期组件 https://github.com/PeakTai/vue-uploader Vue 上传组件 https://github.com/xiaokaike/magic-upload-image 多功能图片上传，支持截图黏贴，拖拽，文件上传 https://github.com/james2doyle/vue-ajax-form-component Vue ajax提交表单组件 https://github.com/wszgxa/vue-v Vue 表单验证组件 vue-handle操作 https://github.com/MeCKodo/vue-tapVue的tap手势插件 https://github.com/kokdemo/vue-href Vue的指令插件，可以让你给任何dom加上一个跳转的事件 vue-image图片 https://github.com/waynecz/vue-img-inputer 基于 Vue2 的图片输入框，用于图片预览、拖拽、回填，主题可选，高度可定制 https://github.com/hilongjw/vue-lazyload Vue 图片懒加载组件 https://github.com/JALBAA/vue-lazyload-img Vue 图片懒加载组件 https://github.com/qusiba/vue-slider Vue 幻灯片组件 https://github.com/coffcer/vue-loading Vue loadding组件 https://github.com/shhdgit/vue-easy-slider Vue.js 的轮播组件 https://github.com/xLogic92/vue-picture-preview 移动端 Vue.js 图片预览插件 vue-notice通知 https://github.com/s4l1h/vue-toastr Vue Toastr 组件 https://www.npmjs.com/package/vue-toaster-plugin Vue Toastr 组件 vue-other其他 https://github.com/miaolz123/vue-markdown Vue markdown解析器组件 https://github.com/wy-ei/vue-filter Vue 过滤器组件 https://github.com/BrockReece/vue-faker Vue 数据伪造器 https://github.com/Twiknight/vue-transition Vue 处理CSS转换组件和动画 https://github.com/shidianxia/vue-localforage Vue 本地存储插件 https://github.com/jaweii/vueg 为 webApp 提供转场特效的开源 Vue 插件 https://github.com/jcc/v-distpicker 一个简单易用的地区选择器 https://github.com/adeptoas/sweet-modal-vue 支持 Vue.js 的漂亮模态框组件 https://fritx.github.io/vue-at At.js 的 Vue.js 组件，自动完成 @ 功能 https://github.com/epicmaxco/epic-spinners 一系列使用方便的 CSS loading 效果集合组件 https://github.com/michalsnik/vue-content-placeholders 在网页内容加载完成之前渲染占位布局的 Vue 组件 https://github.com/tipsy/bubbly-bg 小于 1kB 的漂亮的泡状背景库 https://github.com/chenxuan0000/vue-seamless-scroll Vue.js 无缝滚动组件 ===实例=== https://github.com/jackhutu/jackblog-vue https://github.com/lincenying/mmf-blog-vue2 https://github.com/lincenying/mmf-blog-vue2-ssr ===资料=== https://github.com/vuejs/awesome-vue","categories":[{"name":"vue","slug":"vue","permalink":"http://new.zzpblog.cn/categories/vue/"}],"tags":[{"name":"vue组件库","slug":"vue组件库","permalink":"http://new.zzpblog.cn/tags/vue%E7%BB%84%E4%BB%B6%E5%BA%93/"}]},{"title":"vscode插件集","slug":"vscode/vscode插件","date":"2018-09-26T03:28:57.000Z","updated":"2020-06-10T08:44:44.150Z","comments":true,"path":"2018/09/26/vscode/vscode插件/","link":"","permalink":"http://new.zzpblog.cn/2018/09/26/vscode/vscode%E6%8F%92%E4%BB%B6/","excerpt":"VScode 插件工具集，不求全但求好","text":"VScode 插件工具集，不求全但求好 一、代码快捷键在 VScode 的首页可以设置通用快捷键，因为平常用sublime比较多，所以干脆合并成一套。 二、代码提示1. Path Intellisense自动路径补全 2. Document this js 的注释模板 （注意：新版的 vscode 已经原生支持,在 function 上输入 /** tab ） 三、代码格式1. ESlint代码规范，对不符合要求的代码或者有语法错误的**JS代码**进行提示，可以自定制提示规则 2. HTMLHint**html代码**检测 3. beautify格式化代码的工具 四、代码可视化改善1. colorize可视化颜色哦，做组件涉及很多不同的主题，个人还是蛮稀饭的 2. RegExp Preview and Editor这个就厉害了.可以完美的展示你写的正则,图形化给你看你写正则的形成 3. Better Comments最好用的注释区域高亮,对于TODO这些支持也很好 4. BreadCrumb in StatusBar -————————————————————————— 华丽丽的分割线，以下插件根据框架语言选择，用什么装什么，不用就不要装了，浪费内存 五、React 插件1. ES7 React/Redux/GraphQL/React-Native snippets涵盖的代码片段贼丰富，React 相关代码提示有这个就够了 2. Useful React Snippets当然如果你只用React,那用这个代码提示吧，管够了 3. CSS Blocks支持css模块化的智能提示，跳转，墙裂推荐 4. styled-components-snippetsstyled-components的代码片段 六、Vue 插件1. vetur语法高亮、智能感知、Emmet 等 2. VueHelpersnippet 代码片段 3. Vue VSCode Snippets很全面的vue代码片段 七、Node1. eggjs蛋框的相关帮助插件,代码片段,智能提示等 2. egg-jump-definition蛋框的函数跳转：Cmd+4 `` 八、微信小程序1. mpvue snippetsmpvue的一些代码片段,以及部分原生小程序的代码提示 2. minapp用VS Code写小程序必备的插件,里面有众多实用的特性集成 九、Markdown 插件1. Markdown All in OneMarkdown 的提示插件用这一个足以，集成了语法快捷键、Math、预览等，很实用 2. markdownlint对 markdown 的语法格式规范进行代码提示 十、代码审查1. CodeMetrics 可以计算TS/JS内代码的复杂度(比如函数这些),这些与代码质量和性能是挂钩的 2.Import Cost就是你import一个东西的时候,可以计算改引入模块的大小! 3. Git Lens暂时没有发现比这个看git记录更为详细了 十一、其他下面的插件可有可无，如有相应功能的需求，却也是非常棒的插件 1. fileheader顶部注释模板，可定义作者、时间等信息，并会自动更新最后修改时间 1ctrl+alt+i 2. Paste JSON as CodeJSON 格式转换成其他的语言格式 3. Node.js Modules Intellisense对于node_module的智能提示 4. npm-import-package-version显示导入的 npm 包的版本信息 5. File Tree View提供几个常见编程语言的函数或状态的树集合展示,可以快速点击跳转!! 6. NPM-Scripts在侧边栏可视化执行 npm 命令(项目内的 package.json), 小巧实用 7. :emojisense: 十二、代码片段两种方式定义代码片段 菜单栏-&gt;文件-&gt;首选项-&gt;用户代码片段 ctrl+shift + p =&gt; snippet toRem: 只是一个单纯的描述 prefix: 是触发snippet的简写 body: 是展开的代码片段 $1,$2：表示占位符，用于用户展开代码片段所需要替换的，也可以写成${1:label}键值对的方式 description : 用户你在输出snippet之前，方便自己识别的注释，而不用强行记忆那些简写的 来源：https://juejin.im/post/5b9c7a0b6fb9a05d2778f631 掘金","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://new.zzpblog.cn/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://new.zzpblog.cn/tags/vscode/"}]},{"title":"关于vscode(一)","slug":"vscode/vscode git","date":"2018-09-25T03:28:57.000Z","updated":"2020-06-10T08:44:40.895Z","comments":true,"path":"2018/09/25/vscode/vscode git/","link":"","permalink":"http://new.zzpblog.cn/2018/09/25/vscode/vscode%20git/","excerpt":"主要用于记录关于vscode操作git的一些注意事项以及使用方式","text":"主要用于记录关于vscode操作git的一些注意事项以及使用方式 1、点击第三个进入页面2、点击初始化存储库，弹出框项目所在的根目录选择文件夹 1234563、git remote add origin https:&#x2F;&#x2F;gitee.com&#x2F;zc.com&#x2F;nuxtproject.git 命令行输入这个后面的地址为git的地址，和远程git链接4、git remote -v查看远程git地址5、git pull origin master --allow-unrelated-histories 合并pushmaster分之6、更改代码后可以点击加号暂存，然后消息框内输入提交的信息，然后再快捷键ctrl+enter提交，然后使用命令git push origin master 将代码push 或者使用点击，推送进行pushgit config --global user.email &quot;352761120@qq.com&quot; 7、ctrl+shift+P或者 面板，输入git有提示创建分之， 可以切换分之 如果push这个分之不管用git push –set-upstream origin zzp2如果合并分之，同上调出面板，git有提示合并分之，选择一个要合并的分之就可以了","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://new.zzpblog.cn/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://new.zzpblog.cn/tags/vscode/"}]},{"title":"Linux命令集合","slug":"Ubuntu/linxu(1)","date":"2018-09-25T03:05:45.000Z","updated":"2020-06-10T08:44:47.739Z","comments":true,"path":"2018/09/25/Ubuntu/linxu(1)/","link":"","permalink":"http://new.zzpblog.cn/2018/09/25/Ubuntu/linxu(1)/","excerpt":"Linux命令集合","text":"Linux命令集合 一、Linux基础命令1、ls指令2、pwd命令3、cd命令4、mkdir命令5、touch命令6、cp命令7、mv命令8、rm命令9、vim命令10、输出重定向11、cat命令二、Linux进阶指令1、df指令2、free指令3、head指令4、tail指令5、less指令作用：查看文件，以做少的内容输出，按下辅助功能键 6、wc指令作用：统计文件内容信息（包含行数、单词数、字节数） 语法：#wc -lwc 文件路径 -l:行数 -w:单词数 -c:字节数 7、date作用：操作时间和日期（读取、设置） 小解释：CST：指的是当地时间 用法1：#date +%F或者#date +”%Y-%m-%d” 用法2 #date “+%F %T”或者#date +”%Y-%m-%d %H:%M:%S” 8、cal作用：日历 语法：#cal 等价于#cal -1当前月日历 语法：#cal -3 三天的 语法：# cal -y 2018输出某一年的 9、clear/ctrl+L指令作用：清楚信息 10、管道作用：一般用于过滤 语法：#ls /| grep y 需要通过管道查询出根目录下包含“y”字母的文档名称 grep主要用于过滤 扩展处理：#ls /| wc -l 三、Linux高级指令1、hostname指令作用：操作服务器的主机名 用法1：hostname 输出完整主机名 用法2：hostname -f 输出当前主机名中的fqdn（权限定域名） 2、id指令作用：查看一个用户的一些基本信息，不指定则默认当前用户 ### 3、whoami指令 作用：显示当前的登录名 4、ps -ef指令作用：用于查看当前服务器的进程 -e：表示全部进程 -f：表示全部列 案例：#ps -ef |grep 进程名称 5、top指令作用：查看服务器进程占用的资源 语法：#top 动态资源 退出：q 解释：PR：优先级 VIRT：虚拟内存 RES：常驻内存 SHR：共享内存 ​ 计算一个进程实际使用的内存 = 常驻内存（RES） 注意：在运行top的时候可以按下快捷键排序，从高到底降序 M：表示内存排序 P：按照CPU使用率排序 1：当服务器有多个CPU时可以使用‘1’ 切换是否展示每个cpu的详细信息 6、du -sh指令作用：查看目录的真实大小 -s:只显示汇总的大小 -h：表示以高可读形式显示 案例：#du -sh 后面是路径例如/etc/ 四、常用的命令1、查看系统版本lsb_release -a 2、压缩文件tar压缩命令 tar tar [-cxzjvf] 压缩打包文档的名称 欲打包目录 -c 建立一个归档文件的参数指令压缩 -x 解开一个归档文件的参数指令解压 -z 是否需要用 gzip 压缩 -j 是否需要用 bzip2 压缩 -v 压缩的过程中显示文件 -f 使用档名，在 f 之后要立即接档名 -tf 查看归档文件里面的文件 例子： 压缩文件夹：tar -zcvf test.tar.gz test\\ 解压文件夹：tar -zxvf test.tar.gz gzip 命令 语法 参数 参数说明 gzip gzip [选项] 压缩（解压缩）的文件名 -d 解压缩 -l 对每个压缩文件，显示压缩文件的大小，未压缩文件的大小，压缩比，未压缩文件的名字 -v 对每一个压缩和解压的文件，显示文件名和压缩比 -num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6 说明：压缩文件后缀为 gz bzip2 命令 语法 参数 参数说明 bzip2 bzip2 [-cdz] -d 解压缩 -z 压缩参数 -num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6 说明：压缩文件后缀为 bz2 3、安装包centos：下是使用yum install 软件名 卸载使用yum remove 软件名 Ubuntu：apt-get install 文件名 卸载使用apt-get remove 文件名 centos修改数据源： 超简单将Centos的yum源更换为国内的阿里云源 1、备份mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup、 2、下载新的CentOS-Base.repo 到/etc/yum.repos.d/CentOS 51wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-5.repo CentOS 61wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-6.repo CentOS 7wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3、运行yum makecache生成缓存Ubuntu：编辑数据源1vi &#x2F;etc&#x2F;apt&#x2F;sources.list 删除全部内容并修改为 1234deb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; xenial main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; xenial-security main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; xenial-updates main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; xenial-backports main restricted universe multiverse 更新数据源1apt-get update 4、文件权限r 读 w 写 x 执行 ls –al使用 ls 不带参数只显示文件名称，通过ls –al` 可以显示文件或者目录的权限信息。 ls -l 文件名 显示信息包括：文件类型 (d 目录，- 普通文件，l 链接文件)，文件权限，文件的用户，文件的所属组，文件的大小，文件的创建时间，文件的名称 -rw-r--r-- 1 lusifer lusifer 675 Oct 26 17:20 .profile -：普通文件 rw-：说明用户 lusifer 有读写权限，没有运行权限 r--：表示用户组 lusifer 只有读权限，没有写和运行的权限 r--：其他用户只有读权限，没有写权限和运行的权限 -rw-r–r– 1 lusifer lusifer 675 Oct 26 17:20 .profile 文档类型及权限 连接数 文档所属用户 文档所属组 文档大小 文档最后被修改日期 文档名称 - rw- r– r– 文档类型 文档所有者权限（user） 文档所属用户组权限（group） 其他用户权限（other） 文档类型 d 表示目录 l 表示软连接 – 表示文件 c 表示串行端口字符设备文件 b 表示可供存储的块设备文件 余下的字符 3 个字符为一组。r 只读，w 可写，x 可执行，- 表示无此权限 连接数指有多少个文件指向同一个索引节点。 文档所属用户和所属组就是文档属于哪个用户和用户组。文件所属用户和组是可以更改的 文档大小默认是 bytes chown是 change owner 的意思，主要作用就是改变文件或者目录所有者，所有者包含用户和用户组 chown [-R] 用户名称 文件或者目录 chown [-R] 用户名称 用户组名称 文件或目录 -R：进行递归式的权限更改，将目录下的所有文件、子目录更新为指定用户组权限 chmod简单实用化chmod 直接使用chmod +x shell.sh对这个文件赋予可执行权限 不使用x执行权限 chmod -x shell.sh 执行shell.sh使用路径下的文件 改变访问权限 chmod [who] [+ | - | =] [mode] 文件名 who表示操作对象可以是以下字母的一个或者组合 u：用户 user g：用户组 group o：表示其他用户 a：表示所有用户是系统默认的 操作符号 +：表示添加某个权限 -：表示取消某个权限 =：赋予给定的权限，取消文档以前的所有权限 mode表示可执行的权限，可以是 r、w、x 文件名文件名可以使空格分开的文件列表 示例123456lusifer@UbuntuBase:~$ ls -al test.txt -rw-rw-r-- 1 lusifer lusifer 6 Nov 2 21:47 test.txtlusifer@UbuntuBase:~$ chmod u&#x3D;rwx,g+r,o+r test.txt lusifer@UbuntuBase:~$ ls -al test.txt -rwxrw-r-- 1 lusifer lusifer 6 Nov 2 21:47 test.txtlusifer@UbuntuBase:~$ 5、数字设定法数字设定法中数字表示的含义 0 表示没有任何权限 1 表示有可执行权限 = x 2 表示有可写权限 = w 4 表示有可读权限 = r 也可以用数字来表示权限如 chmod 755 file_name r w x r – x r - x 4 2 1 4 - 1 4 - 1 user group others 若要 rwx 属性则 4+2+1=7 若要 rw- 属性则 4+2=6 若要 r-x 属性则 4+1=5 1234567lusifer@UbuntuBase:~$ chmod 777 test.txt lusifer@UbuntuBase:~$ ls -al test.txt -rwxrwxrwx 1 lusifer lusifer 6 Nov 2 21:47 test.txtlusifer@UbuntuBase:~$ chmod 770 test.txt lusifer@UbuntuBase:~$ ls -al test.txt -rwxrwx--- 1 lusifer lusifer 6 Nov 2 21:47 test.txt 五、JAVA安装Linux 安装 Java此处以 JDK 1.8.0_152 为例 下载地址http://www.oracle.com/technetwork/java/javase/downloads/index.html 解压缩并移动到指定目录解压缩1tar -zxvf jdk-8u152-linux-x64.tar.gz 创建目录1mkdir -p &#x2F;usr&#x2F;local&#x2F;java 移动安装包1mv jdk1.8.0_152&#x2F; &#x2F;usr&#x2F;local&#x2F;java&#x2F; 设置所有者1chown -R root:root &#x2F;usr&#x2F;local&#x2F;java&#x2F; 配置环境变量配置系统环境变量1nano &#x2F;etc&#x2F;environment 添加如下语句1234PATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;games:&#x2F;usr&#x2F;local&#x2F;games&quot;export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.8.0_152export JRE_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.8.0_152&#x2F;jreexport CLASSPATH&#x3D;$CLASSPATH:$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;lib 配置用户环境变量1nano &#x2F;etc&#x2F;profile 添加如下语句1234567891011121314151617181920212223242526272829if [ &quot;$PS1&quot; ]; then if [ &quot;$BASH&quot; ] &amp;&amp; [ &quot;$BASH&quot; !&#x3D; &quot;&#x2F;bin&#x2F;sh&quot; ]; then # The file bash.bashrc already sets the default PS1. # PS1&#x3D;&#39;\\h:\\w\\$ &#39; if [ -f &#x2F;etc&#x2F;bash.bashrc ]; then . &#x2F;etc&#x2F;bash.bashrc fi else if [ &quot;&#96;id -u&#96;&quot; -eq 0 ]; then PS1&#x3D;&#39;# &#39; else PS1&#x3D;&#39;$ &#39; fi fifiexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.8.0_152export JRE_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.8.0_152&#x2F;jreexport CLASSPATH&#x3D;$CLASSPATH:$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;libexport PATH&#x3D;$JAVA_HOME&#x2F;bin:$JAVA_HOME&#x2F;jre&#x2F;bin:$PATH:$HOME&#x2F;binif [ -d &#x2F;etc&#x2F;profile.d ]; then for i in &#x2F;etc&#x2F;profile.d&#x2F;*.sh; do if [ -r $i ]; then . $i fi done unset ifi 使用户环境变量生效1source &#x2F;etc&#x2F;profile 测试是否安装成功1234root@UbuntuBase:&#x2F;usr&#x2F;local&#x2F;java# java -versionjava version &quot;1.8.0_152&quot;Java(TM) SE Runtime Environment (build 1.8.0_152-b16)Java HotSpot(TM) 64-Bit Server VM (build 25.152-b16, mixed mode) 为其他用户更新用户环境变量12su lusifersource &#x2F;etc&#x2F;profile 六、yum更新yum 1yum update 七、文件目录代表的意思etc 放置配置文件var 放置数据文件一般日志usr 一般放置用户的一些数据文件等","categories":[{"name":"服务器","slug":"服务器","permalink":"http://new.zzpblog.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://new.zzpblog.cn/tags/linux/"}]},{"title":"[Docker] 安装Docker","slug":"docker/install-docker","date":"2018-06-23T09:26:24.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2018/06/23/docker/install-docker/","link":"","permalink":"http://new.zzpblog.cn/2018/06/23/docker/install-docker/","excerpt":"","text":"1. CentOS 安装Docker 建议使用centos7 1.1. 安装Docker1.1.1. 卸载旧版本旧版本的Docker命名为docker或docker-engine，如果有安装旧版本，先卸载旧版本 12345678910$ sudo yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 1.1.2. 使用仓库安装1、安装yum-utils、device-mapper-persistent-data、lvm2 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 2、添加软件源 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 1.1.3. 安装Docker安装最新版本的Docker CE。 1$ sudo yum install -y docker-ce 1.1.4. 启动Docker1234# 启动Docker$ sudo systemctl start docker# 运行容器$ sudo docker run hello-world 1.2. 安装指定版本Docker1、列出可安装版本 123$ yum list docker-ce --showduplicates | sort -rdocker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stable 2、安装指定版本 例如：docker-ce-18.03.0.ce 1$ sudo yum install docker-ce-&lt;VERSION STRING&gt; 1.3. 升级Docker依据1.2的方法选择指定版本安装。 1.4. 卸载Docker12345# 卸载Docker$ sudo yum remove docker-ce# 清理镜像、容器、存储卷等$ sudo rm -rf /var/lib/docker 2. Ubuntu 安装Docker2.1. 安装Docker2.1.1. 卸载旧版本旧版本的Docker命名为docker或docker-engine，如果有安装旧版本，先卸载旧版本 1sudo apt-get remove docker docker-engine docker.io 2.1.2. 使用仓库安装1、升级apt 1sudo apt-get update 2、允许apt使用https 12345sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common 3、添加Docker 官方的GPG密钥 1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 4、添加Docker软件源 1234sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 2.1.3. 安装Docker12345# updatesudo apt-get update# install dockersudo apt-get install docker-ce 2.1.4. 启动Docker1234# 设置为开机启动sudo systemctl enable docker# 启动dockersudo systemctl start docker 2.2. 安装指定版本Docker1、列出仓库的可安装版本，apt-cache madison docker-ce。 123# apt-cache madison docker-ce docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages docker-ce | 18.03.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages 2、指定版本安装 例如：docker-ce=18.03.0ce-0ubuntu 1sudo apt-get install docker-ce=&lt;VERSION&gt; 2.3. 升级Docker123# 更新源sudo apt-get update# 依据上述方法，指定版本安装 2.4. 卸载Docker12345# 卸载 docker cesudo apt-get purge docker-ce# 清理镜像、容器、存储卷等sudo rm -rf /var/lib/docker 文章参考： https://docs.docker.com/install/linux/docker-ce/centos/ https://docs.docker.com/install/linux/docker-ce/ubuntu/","categories":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"[Redis] Redis集群模式部署","slug":"redis/redis-cluster","date":"2018-04-17T13:26:24.000Z","updated":"2020-06-10T09:16:22.933Z","comments":true,"path":"2018/04/17/redis/redis-cluster/","link":"","permalink":"http://new.zzpblog.cn/2018/04/17/redis/redis-cluster/","excerpt":"1. Redis部署 以下以Linux系统为例","text":"1. Redis部署 以下以Linux系统为例 1.1 下载和编译1234$ wget http://download.redis.io/releases/redis-4.0.7.tar.gz$ tar xzf redis-4.0.7.tar.gz$ cd redis-4.0.7$ make 编译完成后会在src目录下生成Redis服务端程序redis-server和客户端程序redis-cli。 1.2 启动服务1、前台运行 1src/redis-server 该方式启动默认为前台方式运行，使用默认配置。 2、后台运行 可以修改redis.conf文件的daemonize参数为yes，指定配置文件启动，例如： 12345vi redis.conf# By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes 指定配置文件启动。 1src/redis-server redis.conf 例如： 123456789#指定配置文件后台启动[root@kube-node-1 redis-4.0.7]# src/redis-server redis.conf95778:C 30 Jan 00:44:37.633 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo95778:C 30 Jan 00:44:37.634 # Redis version=4.0.7, bits=64, commit=00000000, modified=0, pid=95778, just started95778:C 30 Jan 00:44:37.634 # Configuration loaded#查看Redis进程[root@kube-node-1 redis-4.0.7]# ps aux|grep redisroot 95779 0.0 0.0 145268 468 ? Ssl 00:44 0:00 src/redis-server 127.0.0.1:6379 更多启动参数如下： 12345678910111213141516[root@kube-node-1 src]# ./redis-server --helpUsage: ./redis-server [/path/to/redis.conf] [options] ./redis-server - (read config from stdin) ./redis-server -v or --version ./redis-server -h or --help ./redis-server --test-memory &lt;megabytes&gt;Examples: ./redis-server (run the server with default conf) ./redis-server /etc/redis/6379.conf ./redis-server --port 7777 ./redis-server --port 7777 --slaveof 127.0.0.1 8888 ./redis-server /etc/myredis.conf --loglevel verboseSentinel mode: ./redis-server /etc/sentinel.conf --sentinel 1.3 客户端测试12345$ src/redis-cliredis&gt; set foo barOKredis&gt; get foo\"bar\" 2. Redis集群部署Redis的集群部署需要在每台集群部署的机器上安装Redis（可参考上述的[Redis安装] ），然后修改配置以集群的方式启动。 2.1 手动部署集群2.1.1 设置配置文件及启动实例修改配置文件redis.conf，集群模式的最小化配置文件如下： 12345678#可选操作，该项设置后台方式运行，daemonize yesport 7000cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yes 更多集群配置参数可参考默认配置文件redis.conf中Cluster模块的说明 最小集群模式需要三个master实例，一般建议起六个实例，即三主三从。因此我们创建6个以端口号命名的目录存放实例的配置文件和其他信息。 123mkdir cluster-testcd cluster-testmkdir 7000 7001 7002 7003 7004 7005 在对应端口号的目录中创建redis.conf的文件，配置文件的内容可参考上述的集群模式配置。每个配置文件中的端口号port参数改为对应目录的端口号。 复制redis-server的二进制文件到cluster-test目录中，通过指定配置文件的方式启动redis服务，例如： 12cd 7000../redis-server ./redis.conf 如果是以前台方式运行，则会在控制台输出以下信息： 1[82462] 26 Nov 11:56:55.329 * No cluster configuration found, I'm 97a3a64667477371c4479320d683e4c8db5858b1 每个实例都会生成一个Node ID，类似97a3a64667477371c4479320d683e4c8db5858b1，用来作为Redis实例在集群中的唯一标识，而不是通过IP和Port，IP和Port可能会改变，该Node ID不会改变。 目录结构可参考： 123456789101112131415161718192021222324252627282930313233cluster-test/├── 7000│ ├── appendonly.aof│ ├── dump.rdb│ ├── nodes.conf│ └── redis.conf├── 7001│ ├── appendonly.aof│ ├── dump.rdb│ ├── nodes.conf│ └── redis.conf├── 7002│ ├── appendonly.aof│ ├── dump.rdb│ ├── nodes.conf│ └── redis.conf├── 7003│ ├── appendonly.aof│ ├── dump.rdb│ ├── nodes.conf│ └── redis.conf├── 7004│ ├── appendonly.aof│ ├── dump.rdb│ ├── nodes.conf│ └── redis.conf├── 7005│ ├── appendonly.aof│ ├── dump.rdb│ ├── nodes.conf│ └── redis.conf├── redis-cli└── redis-server 2.1.2 redis-trib创建集群Redis的实例全部运行之后，还需要redis-trib.rb工具来完成集群的创建，redis-trib.rb二进制文件在Redis包主目录下的src目录中，运行该工具依赖Ruby环境和gem，因此需要提前安装。 1、安装Ruby 1yum -y install ruby rubygems 查看Ruby版本信息。 12[root@kube-node-1 src]# ruby --versionruby 2.0.0p648 (2015-12-16) [x86_64-linux] 由于centos系统默认支持Ruby版本为2.0.0，因此执行gem install redis命令时会报以下错误。 1234[root@kube-node-1 src]# gem install redisFetching: redis-4.0.1.gem (100%)ERROR: Error installing redis: redis requires Ruby version &gt;= 2.2.2. 解决方法是先安装rvm，再升级ruby版本。 2、安装rvm 1curl -L get.rvm.io | bash -s stable 如果遇到以下报错，则执行报错中的gpg2 --recv-keys的命令。 12345678910111213141516171819202122232425[root@kube-node-1 ~]# curl -L get.rvm.io | bash -s stable % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 194 100 194 0 0 335 0 --:--:-- --:--:-- --:--:-- 335100 24090 100 24090 0 0 17421 0 0:00:01 0:00:01 --:--:-- 44446Downloading https://github.com/rvm/rvm/archive/1.29.3.tar.gzDownloading https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.ascgpg: 于 2017年09月11日 星期一 04时59分21秒 CST 创建的签名，使用 RSA，钥匙号 BF04FF17gpg: 无法检查签名：没有公钥Warning, RVM 1.26.0 introduces signed releases and automated check of signatures when GPG software found. Assuming you trust Michal Papis import the mpapis public key (downloading the signatures).GPG signature verification failed for '/usr/local/rvm/archives/rvm-1.29.3.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import -the key can be compared with: https://rvm.io/mpapis.asc https://keybase.io/mpapisNOTE: GPG version 2.1.17 have a bug which cause failures during fetching keys from remote server. Please downgrade or upgrade to newer version (if available) or use the second method described above. 执行报错中的gpg2 --recv-keys的命令。 例如： 12345678[root@kube-node-1 ~]# gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3gpg: 钥匙环‘/root/.gnupg/secring.gpg’已建立gpg: 下载密钥‘D39DC0E3’，从 hkp 服务器 keys.gnupg.netgpg: /root/.gnupg/trustdb.gpg：建立了信任度数据库gpg: 密钥 D39DC0E3：公钥“Michal Papis (RVM signing) &lt;mpapis@gmail.com&gt;”已导入gpg: 没有找到任何绝对信任的密钥gpg: 合计被处理的数量：1gpg: 已导入：1 (RSA: 1) 再次执行命令curl -L get.rvm.io | bash -s stable。例如： 1234567891011121314151617181920212223242526[root@kube-node-1 ~]# curl -L get.rvm.io | bash -s stable % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 194 100 194 0 0 310 0 --:--:-- --:--:-- --:--:-- 309100 24090 100 24090 0 0 18230 0 0:00:01 0:00:01 --:--:-- 103kDownloading https://github.com/rvm/rvm/archive/1.29.3.tar.gzDownloading https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.ascgpg: 于 2017年09月11日 星期一 04时59分21秒 CST 创建的签名，使用 RSA，钥匙号 BF04FF17gpg: 完好的签名，来自于“Michal Papis (RVM signing) &lt;mpapis@gmail.com&gt;”gpg: 亦即“Michal Papis &lt;michal.papis@toptal.com&gt;”gpg: 亦即“[jpeg image of size 5015]”gpg: 警告：这把密钥未经受信任的签名认证！gpg: 没有证据表明这个签名属于它所声称的持有者。主钥指纹： 409B 6B17 96C2 7546 2A17 0311 3804 BB82 D39D C0E3子钥指纹： 62C9 E5F4 DA30 0D94 AC36 166B E206 C29F BF04 FF17GPG verified '/usr/local/rvm/archives/rvm-1.29.3.tgz'Creating group 'rvm'Installing RVM to /usr/local/rvm/Installation of RVM in /usr/local/rvm/ is almost complete: * First you need to add all users that will be using rvm to 'rvm' group, and logout - login again, anyone using rvm will be operating with `umask u=rwx,g=rwx,o=rx`. * To start using RVM you need to run `source /etc/profile.d/rvm.sh` in all your open shell windows, in rare cases you need to reopen all shell windows. 以上表示执行成功， 1source /usr/local/rvm/scripts/rvm 查看rvm库中已知的ruby版本 1rvm list known 例如： 1234567891011121314[root@kube-node-1 ~]# rvm list known# MRI Rubies[ruby-]1.8.6[-p420][ruby-]1.8.7[-head] # security released on head[ruby-]1.9.1[-p431][ruby-]1.9.2[-p330][ruby-]1.9.3[-p551][ruby-]2.0.0[-p648][ruby-]2.1[.10][ruby-]2.2[.7][ruby-]2.3[.4][ruby-]2.4[.1]ruby-head... 3、升级Ruby 12345678#安装rubyrvm install 2.4.0#使用新版本rvm use 2.4.0#移除旧版本rvm remove 2.0.0#查看当前版本ruby --version 例如： 123456789101112131415161718192021222324252627282930313233[root@kube-node-1 ~]# rvm install 2.4.0Searching for binary rubies, this might take some time.Found remote file https://rvm_io.global.ssl.fastly.net/binaries/centos/7/x86_64/ruby-2.4.0.tar.bz2Checking requirements for centos.Installing requirements for centos.Installing required packages: autoconf, automake, bison, bzip2, gcc-c++, libffi-devel, libtool, readline-devel, sqlite-devel, zlib-devel, libyaml-devel, openssl-devel................................Requirements installation successful.ruby-2.4.0 - #configureruby-2.4.0 - #download % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 14.0M 100 14.0M 0 0 852k 0 0:00:16 0:00:16 --:--:-- 980kNo checksum for downloaded archive, recording checksum in user configuration.ruby-2.4.0 - #validate archiveruby-2.4.0 - #extractruby-2.4.0 - #validate binaryruby-2.4.0 - #setupruby-2.4.0 - #gemset created /usr/local/rvm/gems/ruby-2.4.0@globalruby-2.4.0 - #importing gemset /usr/local/rvm/gemsets/global.gems..............................ruby-2.4.0 - #generating global wrappers........ruby-2.4.0 - #gemset created /usr/local/rvm/gems/ruby-2.4.0ruby-2.4.0 - #importing gemsetfile /usr/local/rvm/gemsets/default.gems evaluated to empty gem listruby-2.4.0 - #generating default wrappers........[root@kube-node-1 ~]# rvm use 2.4.0Using /usr/local/rvm/gems/ruby-2.4.0[root@kube-node-1 ~]# rvm remove 2.0.0ruby-2.0.0-p648 - #already goneUsing /usr/local/rvm/gems/ruby-2.4.0[root@kube-node-1 ~]# ruby --versionruby 2.4.0p0 (2016-12-24 revision 57164) [x86_64-linux] 4、安装gem 1gem install redis 例如： 12345678[root@kube-node-1 ~]# gem install redisFetching: redis-4.0.1.gem (100%)Successfully installed redis-4.0.1Parsing documentation for redis-4.0.1Installing ri documentation for redis-4.0.1Done installing documentation for redis after 2 seconds1 gem installed 5、执行redis-trib.rb命令 以上表示安装成功，可以执行redis-trib.rb命令。 1234cd src #执行redis-trib.rb命令./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\&gt; 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 参数create表示创建一个新的集群，--replicas 1表示为每个master创建一个slave。 如果创建成功会显示以下信息 1[OK] All 16384 slots covered 例如： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@kube-node-1 src]# ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\&gt; 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:7000127.0.0.1:7001127.0.0.1:7002Adding replica 127.0.0.1:7004 to 127.0.0.1:7000Adding replica 127.0.0.1:7005 to 127.0.0.1:7001Adding replica 127.0.0.1:7003 to 127.0.0.1:7002&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000 slots:0-5460 (5461 slots) masterM: 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001 slots:5461-10922 (5462 slots) masterM: be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002 slots:10923-16383 (5461 slots) masterS: 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003 replicates 13d0c397604a0b2644244c37b666fce83f29faa8S: dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004 replicates be2718476eba4e56f696e56b75e67df720b7fc24S: 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005 replicates d5a834d075fd93eefab877c6ebb86efff680650fCan I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join....&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)M: d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000 slots:0-5460 (5461 slots) master 1 additional replica(s)M: be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002 slots:10923-16383 (5461 slots) master 1 additional replica(s)M: 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003 slots: (0 slots) slave replicates 13d0c397604a0b2644244c37b666fce83f29faa8S: 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005 slots: (0 slots) slave replicates d5a834d075fd93eefab877c6ebb86efff680650fS: dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004 slots: (0 slots) slave replicates be2718476eba4e56f696e56b75e67df720b7fc24[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 2.1.3 部署结果验证1、客户端访问 使用客户端redis-cli二进制访问某个实例，执行set和get的测试。 12345678910111213$ redis-cli -c -p 7000redis 127.0.0.1:7000&gt; set foo bar-&gt; Redirected to slot [12182] located at 127.0.0.1:7002OKredis 127.0.0.1:7002&gt; set hello world-&gt; Redirected to slot [866] located at 127.0.0.1:7000OKredis 127.0.0.1:7000&gt; get foo-&gt; Redirected to slot [12182] located at 127.0.0.1:7002\"bar\"redis 127.0.0.1:7000&gt; get hello-&gt; Redirected to slot [866] located at 127.0.0.1:7000\"world\" 2、查看集群状态 使用cluster info命令查看集群状态。 1234567891011121314151617127.0.0.1:7000&gt; cluster infocluster_state:ok #集群状态cluster_slots_assigned:16384 #被分配的槽位数cluster_slots_ok:16384 #正确分配的槽位cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6 #当前节点cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:48273cluster_stats_messages_pong_sent:49884cluster_stats_messages_sent:98157cluster_stats_messages_ping_received:49879cluster_stats_messages_pong_received:48273cluster_stats_messages_meet_received:5cluster_stats_messages_received:98157 3、查看节点状态 使用cluster nodes命令查看节点状态。 1234567127.0.0.1:7000&gt; cluster nodesbe2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002@17002 master - 0 1517303607000 3 connected 10923-1638313d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001@17001 master - 0 1517303606000 2 connected 5461-109223d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003@17003 slave 13d0c397604a0b2644244c37b666fce83f29faa8 0 1517303606030 4 connectedd5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000@17000 myself,master - 0 1517303604000 1 connected 0-546099c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005@17005 slave d5a834d075fd93eefab877c6ebb86efff680650f 0 1517303607060 6 connecteddedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004@17004 slave be2718476eba4e56f696e56b75e67df720b7fc24 0 1517303608082 5 connected 参考文章： https://redis.io/download https://redis.io/topics/cluster-tutorial","categories":[{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/tags/Redis/"}]},{"title":"[Redis] Redis哨兵模式部署","slug":"redis/redis-sentinel","date":"2018-04-17T12:26:24.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2018/04/17/redis/redis-sentinel/","link":"","permalink":"http://new.zzpblog.cn/2018/04/17/redis/redis-sentinel/","excerpt":"1. 部署Redis集群redis的安装及配置参考[redis部署]","text":"1. 部署Redis集群redis的安装及配置参考[redis部署] 本文以创建一主二从的集群为例。 1.1 部署与配置先创建sentinel目录，在该目录下创建8000，8001，8002三个以端口号命名的目录。 123mkdir sentinelcd sentinelmkdir 8000 8001 8002 在对应端口号目录中创建redis.conf的文件，配置文件中的端口号port参数改为对应目录的端口号。配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215# 守护进程模式daemonize yes# pid filepidfile /var/run/redis.pid# 监听端口port 8000# TCP接收队列长度，受/proc/sys/net/core/somaxconn和tcp_max_syn_backlog这两个内核参数的影响tcp-backlog 511# 一个客户端空闲多少秒后关闭连接(0代表禁用，永不关闭)timeout 0# 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACKtcp-keepalive 60# 指定服务器调试等级# 可能值：# debug （大量信息，对开发/测试有用）# verbose （很多精简的有用信息，但是不像debug等级那么多）# notice （适量的信息，基本上是你生产环境中需要的）# warning （只有很重要/严重的信息会记录下来）loglevel notice# 指明日志文件名logfile \"./redis8000.log\"# 设置数据库个数databases 16# 会在指定秒数和数据变化次数之后把数据库写到磁盘上# 900秒（15分钟）之后，且至少1次变更# 300秒（5分钟）之后，且至少10次变更# 60秒之后，且至少10000次变更save 900 1save 300 10save 60 10000# 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作# 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难stop-writes-on-bgsave-error yes# 当导出到 .rdb 数据库时是否用LZF压缩字符串对象rdbcompression yes# 版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠。rdbchecksum yes# 持久化数据库的文件名dbfilename dump.rdb# 工作目录dir ./# 当master服务设置了密码保护时，slave服务连接master的密码masterauth 0234kz9*l# 当一个slave失去和master的连接，或者同步正在进行中，slave的行为可以有两种：## 1) 如果 slave-serve-stale-data 设置为 \"yes\" (默认值)，slave会继续响应客户端请求，# 可能是正常数据，或者是过时了的数据，也可能是还没获得值的空数据。# 2) 如果 slave-serve-stale-data 设置为 \"no\"，slave会回复\"正在从master同步# （SYNC with master in progress）\"来处理各种请求，除了 INFO 和 SLAVEOF 命令。slave-serve-stale-data yes# 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve# 的数据在同master同步之后将很容易被删除slave-read-only yes# 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY？# 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave# 上有延迟，Linux内核的默认配置会达到40毫秒# 如果你选择了 \"no\" 数据传输到salve的延迟将会减少但要使用更多的带宽repl-disable-tcp-nodelay no# slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，哨兵将用它来# 选择一个slave提升=升为master。# 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25，# 哨兵将挑选优先级最小数字为10的slave。# 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被# 哨兵挑选提升为masterslave-priority 100# 密码验证# 警告：因为Redis太快了，所以外面的人可以尝试每秒150k的密码来试图破解密码。这意味着你需要# 一个高强度的密码，否则破解太容易了requirepass 0234kz9*l# redis实例最大占用内存，不要用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见：# maxmemmory-policy）删除keymaxmemory 3gb# 最大内存策略：如果达到内存限制了，Redis如何选择删除key。你可以在下面五个行为里选：# volatile-lru -&gt; 根据LRU算法删除带有过期时间的key。# allkeys-lru -&gt; 根据LRU算法删除任何key。# volatile-random -&gt; 根据过期设置来随机删除key, 具备过期时间的key。# allkeys-&gt;random -&gt; 无差别随机删, 任何一个key。# volatile-ttl -&gt; 根据最近过期时间来删除（辅以TTL）, 这是对于有过期时间的key# noeviction -&gt; 谁也不删，直接在写操作时返回错误。maxmemory-policy volatile-lru# 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程# 出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。## AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置）# 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis# 能只丢失1秒的写操作。## AOF和RDB持久化能同时启动并且不会有问题。# 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。appendonly no# aof文件名appendfilename \"appendonly.aof\"# fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。# 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。## Redis支持三种不同的模式：## no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。# always：每次写操作都立刻写入到aof文件。慢，但是最安全。# everysec：每秒写一次。折中方案。appendfsync everysec# 如果AOF的同步策略设置成 \"always\" 或者 \"everysec\"，并且后台的存储进程（后台存储或写入AOF# 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。# 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。## 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止主进程进行fsync()。## 这就意味着如果有子进程在进行保存操作，那么Redis就处于\"不可同步\"的状态。# 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）## 如果你有延时问题把这个设置成\"yes\"，否则就保持\"no\"，这是保存持久数据的最安全的方式。no-appendfsync-on-rewrite yes# 自动重写AOF文件auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# AOF文件可能在尾部是不完整的（这跟system关闭有问题，尤其是mount ext4文件系统时# 没有加上data=ordered选项。只会发生在os死时，redis自己死不会不完整）。# 那redis重启时load进内存的时候就有问题了。# 发生的时候，可以选择redis启动报错，并且通知用户和写日志，或者load尽量多正常的数据。# 如果aof-load-truncated是yes，会自动发布一个log给客户端然后load（默认）。# 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。# 注意，如果在读取的过程中，发现这个aof是损坏的，服务器也是会退出的，# 这个选项仅仅用于当服务器尝试读取更多的数据但又找不到相应的数据时。aof-load-truncated yes# Lua 脚本的最大执行时间，毫秒为单位lua-time-limit 5000# Redis慢查询日志可以记录超过指定时间的查询slowlog-log-slower-than 10000# 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。slowlog-max-len 128# redis延时监控系统在运行时会采样一些操作，以便收集可能导致延时的数据根源。# 通过 LATENCY命令 可以打印一些图样和获取一些报告，方便监控# 这个系统仅仅记录那个执行时间大于或等于预定时间（毫秒）的操作,# 这个预定时间是通过latency-monitor-threshold配置来指定的，# 当设置为0时，这个监控系统处于停止状态latency-monitor-threshold 0# Redis能通知 Pub/Sub 客户端关于键空间发生的事件，默认关闭notify-keyspace-events \"\"# 当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限制时，会用一种节省内存的# 数据结构来编码。可以通过下面的指令来设定限制hash-max-ziplist-entries 512hash-max-ziplist-value 64# 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。# 这种特殊的方式只有在符合下面限制时才可以用list-max-ziplist-entries 512list-max-ziplist-value 64# set有一种特殊编码的情况：当set数据全是十进制64位有符号整型数字构成的字符串时。# 下面这个配置项就是用来设置set使用这种编码来节省内存的最大长度。set-max-intset-entries 512# 与hash和list相似，有序集合也可以用一种特别的编码方式来节省大量空间。# 这种编码只适合长度和元素都小于下面限制的有序集合zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog稀疏结构表示字节的限制。该限制包括# 16个字节的头。当HyperLogLog使用稀疏结构表示# 这些限制，它会被转换成密度表示。# 值大于16000是完全没用的，因为在该点# 密集的表示是更多的内存效率。# 建议值是3000左右，以便具有的内存好处, 减少内存的消耗hll-sparse-max-bytes 3000# 启用哈希刷新，每100个CPU毫秒会拿出1个毫秒来刷新Redis的主哈希表（顶级键值映射表）activerehashing yes# 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# 默认情况下，“hz”的被设定为10。提高该值将在Redis空闲时使用更多的CPU时，但同时当有多个key# 同时到期会使Redis的反应更灵敏，以及超时可以更精确地处理hz 10# 当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步aof-rewrite-incremental-fsync yes 1.2 配置主从关系1、启动实例 三个Redis实例配置相同，分别启动三个Redis实例。建议将redis-server、redis-cli、redis-sentinel的二进制复制到/usr/local/bin的目录下。 12cd 8000redis-server redis.conf 2、配置主从关系 例如，将8000端口实例设为主，8001和8002端口的实例设为从。 则分别登录8001和8002的实例，执行slaveof &lt;MASTER_IP&gt; &lt;MASTER_PORT&gt;命令。 例如： 123[root@kube-node-1 8000]# redis-cli -c -p 8001 -a 0234kz9*l127.0.0.1:8001&gt; slaveof 127.0.0.1 8000OK 3、检查集群状态 登录master和slave实例，执行info replication查看集群状态。 Master 123456789101112131415[root@kube-node-1 8000]# redis-cli -c -p 8000 -a 0234kz9*l127.0.0.1:8000&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=8001,state=online,offset=2853,lag=0slave1:ip=127.0.0.1,port=8002,state=online,offset=2853,lag=0master_replid:4f8331d5f180a4669241ab0dd97e43508abd6d8fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:2853second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:2853 Slave 123456789101112131415161718192021[root@kube-node-1 8000]# redis-cli -c -p 8001 -a 0234kz9*l127.0.0.1:8001&gt; info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:8000master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_repl_offset:2909slave_priority:100slave_read_only:1connected_slaves:0master_replid:4f8331d5f180a4669241ab0dd97e43508abd6d8fmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:2909second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:2909 也可以往master写数据，从slave读取数据来验证。 2. 部署sentinel集群2.1 部署与配置在之前创建的sentinel目录中场景sentinel端口号命名的目录28000，28001，28002。 12cd sentinelmkdir 28000 28001 28002 在对应端口号目录中创建redis.conf的文件，配置文件中的端口号port参数改为对应目录的端口号。配置如下： 12345port 28000sentinel monitor mymaster 127.0.0.1 8000 2sentinel down-after-milliseconds mymaster 60000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1 2.2 启动sentinel实例12#&amp; 表示后台运行的方式redis-sentinel sentinel.conf &amp; 2.3 查看状态使用sentinel masters命令查看监控的master节点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@kube-node-1 28000]# redis-cli -c -p 28000 -a 0234kz9*l127.0.0.1:28000&gt;127.0.0.1:28000&gt; pingPONG127.0.0.1:28000&gt;127.0.0.1:28000&gt; sentinel masters1) 1) \"name\" 2) \"mymaster\" 3) \"ip\" 4) \"127.0.0.1\" 5) \"port\" 6) \"8000\" 7) \"runid\" 8) \"\" 9) \"flags\" 10) \"s_down,master,disconnected\" 11) \"link-pending-commands\" 12) \"0\" 13) \"link-refcount\" 14) \"1\" 15) \"last-ping-sent\" 16) \"187539\" 17) \"last-ok-ping-reply\" 18) \"187539\" 19) \"last-ping-reply\" 20) \"3943\" 21) \"s-down-time\" 22) \"127491\" 23) \"down-after-milliseconds\" 24) \"60000\" 25) \"info-refresh\" 26) \"1517346914642\" 27) \"role-reported\" 28) \"master\" 29) \"role-reported-time\" 30) \"187539\" 31) \"config-epoch\" 32) \"0\" 33) \"num-slaves\" 34) \"0\" 35) \"num-other-sentinels\" 36) \"0\" 37) \"quorum\" 38) \"2\" 39) \"failover-timeout\" 40) \"180000\" 41) \"parallel-syncs\" 42) \"1\" 参考文章： https://redis.io/topics/sentinel","categories":[{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/tags/Redis/"}]},{"title":"[Nginx] Nginx的部署与配置","slug":"nginx/nginx-deploy&config","date":"2017-09-13T02:50:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2017/09/13/nginx/nginx-deploy&config/","link":"","permalink":"http://new.zzpblog.cn/2017/09/13/nginx/nginx-deploy&config/","excerpt":"1. 部署","text":"1. 部署 1.1. 使用安装包的方式rpm -ivh nginx-xxx.rpm 1.2. 使用源代码安装1.2.1. 下载源码包1wget http://nginx.org/download/nginx-1.9.13.tar.gz 1.2.2. 创建临时目录并解压源码包12mkdir $HOME/buildcd $HOME/build &amp;&amp; tar zxvf nginx-`version-number`.tar.gz 1.2.3. 编译并安装12345678910 cd $HOME/build/nginx-`version-number` ./configure \\--prefix=/etc/nginx \\--sbin-path=/usr/sbin/nginx \\--conf-path=/etc/nginx/nginx.conf \\...#`更多配置项见以下说明` make &amp;&amp; make install 1.2.4. 配置项1.2.4.1. 通用配置项 配置选项 说明 –prefix=path nginx安装的根路径，所有其他的路径都要依赖与该选项 –sbin-path=path nginx二进制文件的路径，如果没有指定则会依赖于–prefix –conf-path=path 如果在命令行中没有指定配置文件，则通过该配置项去查找配置文件 –error-log-path=path 指定错误文件的路径 –pid-path=path 指定的文件将会写入nginx master进程的pid，通常在/var/run下 –lock-path=path 共享存储器互斥锁文件的路径 –user=user worker进程运行的用户 –group=group worker进程运行的组 –with-file-aio 启动异步I/O –with-debug 启用调试日志，生产环境不推荐配置 1.2.4.2. 优化配置项 配置选项 说明 –with-cc=path 如果想设置一个不在默认PATH下的C编译器 –with-cpp=path 设置C预处理器的相应路径 –with-cc-opt=options 指定必要的include文件路径 –with-ld-opt=options 包含连接器库的路径和运行路径 –with-cpu-opt=cpu 通过该选项为特定的CPU构建nginx 1.2.4.3. http模块的配置项 配置选项 说明 –without-http-cache 在使用upstream模块时，nginx能够配置本地缓存内容，该选项可以禁用缓存 –with-http_perl_module nginx配置能够扩展使用perl代码。该项启用这个模块，但会降低性能 –with-perl_modules_path=path 对于额外嵌入的perl模块，该选项指定该perl解析器的路径 –with-perl=path 如果在默认的路径中找不到perl则指定perl（5.6版本以上）的路径 –http-log-path=path http访问日志的默认路径 –http-client-body-temp-path=path 从客户端收到请求后，该项用于作为请求体临时存放的目录 –http-proxy-temp-path=path 在使用代理后，通过该项设置存放临时文件路径 –http-fastcgi-temp-path=path 设置FastCGI临时文件的目录 –http-uwsgi-temp-path=path 设置uWSGI临时文件的目录 –http-scgi-temp-path=path 设置SCGI临时文件的目录 1.2.4.4. 其他模块额外配置项默认没有安装这些模块，可以通过–with-module-name_module来启用相应的模块功能。 配置选项 说明 –with-http_ssl_module 如果需要对流量进行加密，可以使用该选项，再URLs中开始部分将会是https(需要OpenSSL库) –with-http_realip_module 如果nginx在七层负载均衡器或者其他设备之后，它们将Http头中的客户端IP地址传递，则需要启用该模块，再多个客户处于一个IP地址的情况下使用 –with-http_addition_module 该模块作为输出过滤器，使能够在请求经过一个location前或后时在该location本身添加内容 –with-http_xslt_module 该模块用于处理XML响应转换，基于一个或多个XSLT格式 –with-http_image_filter_module 该模块被作为图像过滤器使用，在将图像投递到客户之前进行处理（需要libgd库） –with-http_geoip_module 使用该模块，能够设置各种变量以便在配置文件中的区段使用，基于地理位置查找客户端IP地址 –with-http_sub_module 该模块实现替代过滤，在响应中用一个字符串替代另一个字符串 –with-heep_dav_module 启用这个模块将激活使用WebDAV的配置指令。 –with-http_flv_module 如果需要提供Flash流媒体视频文件，那么该模块将会提供伪流媒体 –with-http_mp4_module 这个模块支持H.264/AAC文件伪流媒体 –with-http_gzip_static_module 当被调用的资源没有.gz结尾格式的文件时，如果想支持发送预压缩版本的静态文件，那么使用该模块 –with-http_gunzip_module 对于不支持gzip编码的客户，该模块用于为客户解压缩预压缩内容 –with-http_random_index_module 如果你想提供从一个目录中随机选择文件的索引文件，那么该模块需要激活 –with-http_secure_link_module 该模块提供一种机制，它会将一个哈希值链接到一个URL中，因此只有那些使用正确密码能够计算链接 –with-http_stub_status_module 启用这个模块后会收集Nginx自身的状态信息。输出的状态信息可以使用RRDtool或类似的东西绘制成图 2. 配置配置文件一般为/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf。 2.1. 基本配置格式123`section`&#123; `directive` `parameters`;&#125; 每一个指令行由分号结束，大括号{}表示一个新的上下文。 2.2. Nginx全局配置参数全局配置指令 模块 配置项 说明 main模块 user 配置worker进程的用户和组，如果忽略group，则group等于指定的用户的所属组 worker_processes 指定worker进程的启动数量，可将其设置为可用的CPU内核数，若为auto为自动检测 error_log 所有错误的写入文件，第二个参数指定错误的级别（debug，info，notice，warn，error，crit，alert，emerg） pid 设置主进程IP的文件 events模块 use 用于设置使用什么样的连接方法 worker_connections 用于配置一个工作进程能够接受的并发连接最大数。包括客户连接和向上游服务器的连接。 2.3. 使用include文件include文件可以在任何地方以增强配置文件的可读性，使用include文件要确保被包含文件自身正确的nginx语法，即配置指令和块，然后指定这些文件的路径。 include /etc/nginx/mime.types; 若使用通配符则表示通配的多个文件，若没有给定全路径则依据主配置文件路径进行搜索。 include /etc/nginx/conf.d/*.conf 测试配置文件(包括include的配置文件)语法： nginx -t -c path-to-nginx.conf 2.4. 配置说明2.4.1. main模块123456789101112131415161718192021#main模块类似main函数包含其他子模块，非模块配置项(包括模块内)分号结尾，子模块配置花括号结尾user nobady; #一般按默认设置pid /var/run/nginx.pid; #进程标识符存放路径，一般按默认设置worker_processes auto; #nginx对外提供web服务时的worder进程数，可将其设置为可用的CPU内核数，auto为自动检测worker_rlimit_nofile 100000; # 更改worker进程的最大打开文件数限制error_log logs/error.log info; #错误日志存放路径keepalive_timeout 60; #keepalive_timeout 60;events&#123; #见events模块&#125;http&#123; #见http模块 server&#123; ... location /&#123; &#125; &#125;&#125;mail&#123; #见mail模块&#125; 2.4.2. events模块12345events &#123; worker_connections 2048; #设置可由一个worker进程同时打开的最大连接数 multi_accept on; #告诉nginx收到一个新连接通知后接受尽可能多的连接 use epoll; #设置用于复用客户端线程的轮询方法。Linux 2.6+：使用epoll；*BSD：使用kqueue。&#125; 2.4.3. http模块1234567891011121314151617181920212223242526272829http &#123; #http模块 server &#123; #server模块，http服务上的虚拟主机， server 当做对应一个域名进行的配置 listen 80; #配置监听端口 server_name www.linuxidc.com; #配置访问域名 access_log logs/linuxidc.access.log main; #指定日志文件的存放路径 index index.html; #默认访问页面 root /var/www/androidj.com/htdocs; # root 是指将本地的一个文件夹作为所有 url 请求的根路径 upstream backend &#123; #反向代理的后端机器，实现负载均衡 ip_hash; #指明了我们均衡的方式是按照用户的 ip 地址进行分配 server backend1.example.com; server backend2.example.com; server backend3.example.com; server backend4.example.com; &#125; location / &#123; #location 是在一个域名下对更精细的路径进行配置 proxy_pass http://backend; #反向代理到后端机器 &#125; &#125; server &#123; listen 80; server_name www.Androidj.com; access_log logs/androidj.access.log main; location / &#123; index index.html; root /var/www/androidj.com/htdocs; &#125; &#125;&#125; 2.4.4. mail模块123456789101112131415161718mail &#123; auth_http 127.0.0.1:80/auth.php; pop3_capabilities \"TOP\" \"USER\"; imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; server &#123; listen 110; protocol pop3; proxy on; &#125; server &#123; listen 25; protocol smtp; proxy on; smtp_auth login plain; xclient off; &#125;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://new.zzpblog.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://new.zzpblog.cn/tags/Nginx/"}]},{"title":"[Redis] Redis介绍","slug":"redis/redis-introduction","date":"2017-07-15T02:50:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2017/07/15/redis/redis-introduction/","link":"","permalink":"http://new.zzpblog.cn/2017/07/15/redis/redis-introduction/","excerpt":"一、redis是什么？（what）Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。","text":"一、redis是什么？（what）Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 二、为什么使用redis？（why）（一）redis的特点 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 （二）redis的优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 （三）redis与其他key-value存储有什么不同 Redis有着更为复杂的数据结构并且提供对他们的原子性操作，Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存。 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。 在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 三、如何使用redis？（how）（一）redis的数据类型 数据类型 概念 常用命令 String(字符串) key-value型 SET ，GET Hash(哈希) field-value,适用于存储对象类型（对象名-对象属性值） HMSET，HEGTALL List(列表) string类型的有序列表，按照插入顺序排序 lpush，lrange Set(集合) string类型的无序集合 sadd，smembers zset(sorted set：有序集合) string类型元素的集合,且不允许重复的成员。每个元素关联一个double值来进行排序，double值可以重复但元素不能重复。 zadd，ZRANGEBYSCORE （二）redis常用命令","categories":[{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/tags/Redis/"}]},{"title":"[Docker] Dockerfile使用说明","slug":"docker/dockerfile-usage","date":"2017-07-09T02:50:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2017/07/09/docker/dockerfile-usage/","link":"","permalink":"http://new.zzpblog.cn/2017/07/09/docker/dockerfile-usage/","excerpt":"一、Dockerfile的说明","text":"一、Dockerfile的说明 dockerfile指令忽略大小写，建议大写，#作为注释，每行只支持一条指令，指令可以带多个参数。 dockerfile指令分为构建指令和设置指令。 构建指令：用于构建image，其指定的操作不会在运行image的容器中执行。 设置指令：用于设置image的属性，其指定的操作会在运行image的容器中执行。 二、Dockerfile指令说明1、FROM（指定基础镜像）[构建指令]该命令用来指定基础镜像，在基础镜像的基础上修改数据从而构建新的镜像。基础镜像可以是本地仓库也可以是远程仓库。 指令有两种格式： FROM image 【默认为latest版本】 FROM image:tag 【指定版本】 2、MAINTAINER（镜像创建者信息）[构建指令]将镜像制作者（维护者）的信息写入image中，执行docker inspect时会输出该信息。 格式：MAINTAINER name 3、RUN（安装软件用）[构建指令]RUN可以运行任何被基础镜像支持的命令（即在基础镜像上执行一个进程），可以使用多条RUN指令，指令较长可以使用\\来换行。 指令有两种格式： RUN command (the command is run in a shell - /bin/sh -c) RUN [“executable”, “param1”, “param2” … ] (exec form) 指定使用其他终端实现，使用exec执行。 例子：RUN[“/bin/bash”,”-c”,”echo hello”] 4、CMD（设置container启动时执行的操作）[设置指令]用于容器启动时的指定操作，可以是自定义脚本或命令，只执行一次，多个默认执行最后一个。 指令有三种格式： CMD [“executable”,”param1”,”param2”] (like an exec, this is the preferred form) 运行一个可执行文件并提供参数。 CMD command param1 param2 (as a shell) 直接执行shell命令，默认以/bin/sh -c执行。 CMD [“param1”,”param2”] (as default parameters to ENTRYPOINT) 和ENTRYPOINT配合使用，只作为完整命令的参数部分。 5、ENTRYPOINT（设置container启动时执行的操作）[设置指令]指定容器启动时执行的命令，若多次设置只执行最后一次。 ENTRYPOINT翻译为“进入点”，它的功能可以让容器表现得像一个可执行程序一样。 例子：ENTRYPOINT [“/bin/echo”] ，那么docker build出来的镜像以后的容器功能就像一个/bin/echo程序，docker run -it imageecho “this is a test”，就会输出对应的字符串。这个imageecho镜像对应的容器表现出来的功能就像一个echo程序一样。 指令有两种格式： ENTRYPOINT [“executable”, “param1”, “param2”] (like an exec, the preferred form) 和CMD配合使用，CMD则作为完整命令的参数部分，ENTRYPOINT以JSON格式指定执行的命令部分。CMD可以为ENTRYPOINT提供可变参数，不需要变动的参数可以写在ENTRYPOINT里面。 例子： ENTRYPOINT [“/usr/bin/ls”,”-a”] CMD [“-l”] ENTRYPOINT command param1 param2 (as a shell) 独自使用，即和CMD类似，如果CMD也是个完整命令[CMD command param1 param2 (as a shell) ]，那么会相互覆盖，只执行最后一个CMD或ENTRYPOINT。 例子：ENTRYPOINT ls -l 6、USER（设置container容器启动的登录用户）[设置指令]设置启动容器的用户，默认为root用户。 格式：USER daemon 7、EXPOSE（指定容器需要映射到宿主机的端口）[设置指令]该指令会将容器中的端口映射为宿主机中的端口[确保宿主机的端口号没有被使用]。通过宿主机IP和映射后的端口即可访问容器[避免每次运行容器时IP随机生成不固定的问题]。前提是EXPOSE设置映射端口，运行容器时加上-p参数指定EXPOSE设置的端口。EXPOSE可以设置多个端口号，相应地运行容器配套多次使用-p参数。可以通过docker port +容器需要映射的端口号和容器ID来参考宿主机的映射端口。 格式：EXPOSE port [port…] 8、ENV（用于设置环境变量）[构建指令]在image中设置环境变量[以键值对的形式]，设置之后RUN命令可以使用该环境变量，在容器启动后也可以通过docker inspect查看环境变量或者通过 docker run –env key=value设置或修改环境变量。 格式：ENV key value 例子：ENV JAVA_HOME /path/to/java/dirent 9、ADD（从src复制文件到container的dest路径）[构建指令]复制指定的src到容器中的dest，其中src是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url。dest 是container中的绝对路径。所有拷贝到container中的文件和文件夹权限为0755，uid和gid为0。 如果src是一个目录，那么会将该目录下的所有文件添加到container中，不包括目录； 如果src文件是可识别的压缩格式，则docker会帮忙解压缩（注意压缩格式）； 如果src是文件且dest中不使用斜杠结束，则会将dest视为文件，src的内容会写入dest； 如果src是文件且dest中使用斜杠结束，则会src文件拷贝到dest目录下。 格式：ADD src dest 10、COPY（复制文件）复制本地主机的src为容器中的dest，目标路径不存在时会自动创建。 格式：COPY src dest 11、VOLUME（指定挂载点）[设置指令]创建一个可以从本地主机或其他容器挂载的挂载点，使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用也可以被其他容器使用。 格式：VOLUME [“mountpoint“] 其他容器使用共享数据卷：docker run -t -i -rm -volumes-from container1 image2 bash [container1为第一个容器的ID，image2为第二个容器运行image的名字。] 12、WORKDIR（切换目录）[设置指令]相当于cd命令，可以多次切换目录，为RUN,CMD,ENTRYPOINT配置工作目录。可以使用多个WORKDIR的命令，后续命令如果是相对路径则是在上一级路径的基础上执行[类似cd的功能]。 格式：WORKDIR /path/to/workdir 13、ONBUILD（在子镜像中执行）当所创建的镜像作为其他新创建镜像的基础镜像时执行的操作命令，即在创建本镜像时不运行，当作为别人的基础镜像时再在构建时运行（可认为基础镜像为父镜像，而该命令即在它的子镜像构建时运行，相当于在子镜像构建时多加了一些命令）。 格式：ONBUILD Dockerfile关键字 三、docker build123456789101112131415161718192021222324252627282930313233343536373839Usage: docker build [OPTIONS] PATH | URL | -Build a new image from the source code at PATH-c, --cpu-shares=0 CPU shares (relative weight)--cgroup-parent= Optional parent cgroup for the container--cpu-period=0 Limit the CPU CFS (Completely Fair Scheduler) period--cpu-quota=0 Limit the CPU CFS (Completely Fair Scheduler) quota--cpuset-cpus= CPUs in which to allow execution (0-3, 0,1)--cpuset-mems= MEMs in which to allow execution (0-3, 0,1)--disable-content-trust=true Skip image verification-f, --file= Name of the Dockerfile (Default is 'PATH/Dockerfile')--force-rm=false Always remove intermediate containers--help=false Print usage-m, --memory= Memory limit--memory-swap= Total memory (memory + swap), '-1' to disable swap--no-cache=false Do not use cache when building the image--pull=false Always attempt to pull a newer version of the image-q, --quiet=false Suppress the verbose output generated by the containers--rm=true Remove intermediate containers after a successful build-t, --tag= Repository name (and optionally a tag) for the image--ulimit=[] Ulimit options","categories":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"[Docker] Docker整体架构图","slug":"docker/docker-architecture","date":"2017-07-09T02:50:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2017/07/09/docker/docker-architecture/","link":"","permalink":"http://new.zzpblog.cn/2017/07/09/docker/docker-architecture/","excerpt":"一、Docker的总架构图","text":"一、Docker的总架构图 docker是一个C/S模式的架构，后端是一个松耦合架构，模块各司其职。 用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。 Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求； Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储； 当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境； 当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。 libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。 二、Docker各模块组件分析（一）Docker Client[发起请求] Docker Client是和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker（类似可执行脚本的命令），docker命令后接参数的形式来实现一个完整的请求命令（例如docker images，docker为命令不可变，images为参数可变）。 Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。 Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。[一次完整的请求：发送请求→处理请求→返回结果]，与传统的C/S架构请求流程并无不同。 （二）Docker Daemon[后台守护进程] Docker Daemon的架构图 Docker Server[调度分发请求] Docker Server的架构图 Docker Server相当于C/S架构的服务端。功能为接受并调度分发Docker Client发送的请求。接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。 在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。 创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。 在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。 Engine Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。 在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{“create”: daemon.ContainerCreate,}，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler。 job 一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job。Docker Server的运行过程也是一个job，名为serveapi。 Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等。 （三）Docker Registry[镜像注册中心] Docker Registry是一个存储容器镜像的仓库（注册中心），可理解为云端镜像仓库，按repository来分类，docker pull 按照[repository]:[tag]来精确定义一个image。 在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为”search”，”pull” 与 “push”。 可分为公有仓库（docker hub）和私有仓库。 （四）Graph[docker内部数据库] Graph的架构图 Repository 已下载镜像的保管者（包括下载镜像和dockerfile构建的镜像）。 一个repository表示某类镜像的仓库（例如Ubuntu），同一个repository内的镜像用tag来区分（表示同一类镜像的不同标签或版本）。一个registry包含多个repository，一个repository包含同类型的多个image。 镜像的存储类型有aufs，devicemapper,Btrfs，Vfs等。其中centos系统使用devicemapper的存储类型。 同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs。 GraphDB 已下载容器镜像之间关系的记录者。 GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录 （五）Driver[执行部分]Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。即Graph负责镜像的存储，Driver负责容器的执行。 graphdriver graphdriver架构图 graphdriver主要用于完成容器镜像的管理，包括存储与获取。 存储：docker pull下载的镜像由graphdriver存储到本地的指定目录（Graph中）。 获取：docker run（create）用镜像来创建容器的时候由graphdriver到本地Graph中获取镜像。 networkdriver networkdriver的架构图 networkdriver的用途是完成Docker容器网络环境的配置，其中包括 Docker启动时为Docker环境创建网桥； Docker容器创建时为其创建专属虚拟网卡设备； Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。 execdriver execdriver的架构图 execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。 现在execdriver默认使用native驱动，不依赖于LXC。 （六）libcontainer[函数库] libcontainer的架构图 libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。 Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。 libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。 （七）docker container[服务交付的最终形式] container架构 Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。 Docker按照用户的需求与指令，订制相应的Docker容器： 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统； 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源； 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境； 用户通过指定运行的命令，使得Docker容器执行指定的工作。 附：本文在《docker源码分析》基础上进行整理。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]},{"title":"[Docker] Docker常用命令原理图","slug":"docker/docker-commands-principle","date":"2017-07-09T02:50:57.000Z","updated":"2020-06-10T09:16:24.096Z","comments":true,"path":"2017/07/09/docker/docker-commands-principle/","link":"","permalink":"http://new.zzpblog.cn/2017/07/09/docker/docker-commands-principle/","excerpt":"1. 基本概念","text":"1. 基本概念 1.1. image layer（镜像层）镜像可以看成是由多个镜像层叠加起来的一个文件系统，镜像层也可以简单理解为一个基本的镜像，而每个镜像层之间通过指针的形式进行叠加。 根据上图，镜像层的主要组成部分包括镜像层id，镜像层指针【指向父层】，元数据【layer metadata】包含了docker构建和运行的信息还有父层的层次信息。 只读层和读写层【top layer】的组成部分基本一致。同时读写层可以转换成只读层【docker commit操作实现】 1.2. image（镜像）—【只读层的集合】1、镜像是一堆只读层的统一视角，除了最底层没有指向外，每一层都指向它的父层，统一文件系统（union file system）技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。而每一层都是不可写的，就是只读层。 1.3. container（容器）—【一层读写层+多层只读层】1、容器和镜像的区别在于容器的最上面一层是读写层【top layer】，而这边并没有区分容器是否在运行。运行状态的容器【running container】即一个可读写的文件系统【静态容器】+隔离的进程空间和其中的进程。 隔离的进程空间中的进程可以对该读写层进行增删改，其运行状态容器的进程操作都作用在该读写层上。每个容器只能有一个进程隔离空间。 2. Docker常用命令原理图概览： 3. Docker常用命令说明3.1. 标识说明3.1.1. image—（统一只读文件系统） 3.1.2. 静态容器【未运行的容器】—（统一可读写文件系统） 3.1.3. 动态容器【running container】—（进程空间（包括进程）+统一可读写文件系统） 3.2. 命令说明3.2.1. docker生命周期相关命令:3.2.1.1. docker create {image-id} 即为只读文件系统添加一层可读写层【top layer】，生成可读写文件系统，该命令状态下容器为静态容器，并没有运行。 3.2.1.2. docker start（restart） {container-id}docker stop即为docker start的逆过程 即为可读写文件系统添加一个进程空间【包括进程】，生成动态容器【running container】 3.2.1.3. docker run {image-id} docker run=docker create+docker start 类似流程如下 ： 3.2.1.4. docker stop {container-id} 向运行的容器中发一个SIGTERM的信号，然后停止所有的进程。即为docker start的逆过程。 3.2.1.5. docker kill {container-id} docker kill向容器发送不友好的SIGKILL的信号，相当于快速强制关闭容器，与docker stop的区别在于docker stop是正常关闭，先发SIGTERM信号，清理进程，再发SIGKILL信号退出。 3.2.1.6. docker pause {container-id}docker unpause为逆过程—比较少使用 暂停容器中的所有进程，使用cgroup的freezer顺序暂停容器里的所有进程，docker unpause为逆过程即恢复所有进程。比较少使用。 3.2.1.7. docker commit {container-id} 把容器的可读写层转化成只读层，即从容器状态【可读写文件系统】变为镜像状态【只读文件系统】，可理解为【固化】。 3.2.1.8. docker build docker build=docker run【运行容器】+【进程修改数据】+docker commit【固化数据】，不断循环直至生成所需镜像。 循环一次便会形成新的层（镜像）【原镜像层+已固化的可读写层】 docker build 一般作用在dockerfile文件上。 3.2.2. docker查询类命令查询对象：①image，②container，③image/container中的数据，④系统信息[容器数，镜像数及其他] 3.2.2.1. Image1、docker images docker images 列出当前镜像【以顶层镜像id来表示整个完整镜像】，每个顶层镜像下面隐藏多个镜像层。 2、docker images -a docker images -a列出所有镜像层【排序以每个顶层镜像id为首后接该镜像下的所有镜像层】，依次列出每个镜像的所有镜像层。 3、docker history {image-id} docker history 列出该镜像id下的所有历史镜像。 3.2.2.2. Container1、docker ps 列出所有运行的容器【running container】 2、docker ps -a 列出所有容器，包括静态容器【未运行的容器】和动态容器【running container】 3.2.2.3. Info1、docker inspect {container-id} or {image-id} 提取出容器或镜像最顶层的元数据。 2、docker info显示 Docker 系统信息，包括镜像和容器数。 3.2.3. docker操作类命令：3.2.3.1. docker rm {container-id} docker rm会移除镜像，该命令只能对静态容器【非运行状态】进行操作。 通过docker rm -f {container-id}的-f （force）参数可以强制删除运行状态的容器【running container】。 3.2.3.2. docker rmi {image-id} 3.2.3.3. docker exec {running-container-id} docker exec会在运行状态的容器中执行一个新的进程。 3.2.3.4. docker export {container-id} docker export命令创建一个tar文件，并且移除了元数据和不必要的层，将多个层整合成了一个层，只保存了当前统一视角看到的内容。 参考文章： http://merrigrove.blogspot.com/2015/10/visualizing-docker-containers-and-images.html","categories":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"}]}],"categories":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/categories/webpack/"},{"name":"随笔","slug":"随笔","permalink":"http://new.zzpblog.cn/categories/%E9%9A%8F%E7%AC%94/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://new.zzpblog.cn/categories/Kubernetes/"},{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/categories/Node/"},{"name":"mapstruct","slug":"mapstruct","permalink":"http://new.zzpblog.cn/categories/mapstruct/"},{"name":"服务器","slug":"服务器","permalink":"http://new.zzpblog.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Idea","slug":"Idea","permalink":"http://new.zzpblog.cn/categories/Idea/"},{"name":"Swagger2","slug":"Swagger2","permalink":"http://new.zzpblog.cn/categories/Swagger2/"},{"name":"Springboot","slug":"Springboot","permalink":"http://new.zzpblog.cn/categories/Springboot/"},{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://new.zzpblog.cn/categories/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"},{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/categories/Docker/"},{"name":"vue","slug":"vue","permalink":"http://new.zzpblog.cn/categories/vue/"},{"name":"开发工具","slug":"开发工具","permalink":"http://new.zzpblog.cn/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/categories/Redis/"},{"name":"Nginx","slug":"Nginx","permalink":"http://new.zzpblog.cn/categories/Nginx/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://new.zzpblog.cn/tags/webpack/"},{"name":"随笔","slug":"随笔","permalink":"http://new.zzpblog.cn/tags/%E9%9A%8F%E7%AC%94/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://new.zzpblog.cn/tags/Kubernetes/"},{"name":"Node","slug":"Node","permalink":"http://new.zzpblog.cn/tags/Node/"},{"name":"mapstruct插件","slug":"mapstruct插件","permalink":"http://new.zzpblog.cn/tags/mapstruct%E6%8F%92%E4%BB%B6/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://new.zzpblog.cn/tags/Ubuntu/"},{"name":"Idea","slug":"Idea","permalink":"http://new.zzpblog.cn/tags/Idea/"},{"name":"Spring boot","slug":"Spring-boot","permalink":"http://new.zzpblog.cn/tags/Spring-boot/"},{"name":"Springboot","slug":"Springboot","permalink":"http://new.zzpblog.cn/tags/Springboot/"},{"name":"Docker","slug":"Docker","permalink":"http://new.zzpblog.cn/tags/Docker/"},{"name":"vue组件库","slug":"vue组件库","permalink":"http://new.zzpblog.cn/tags/vue%E7%BB%84%E4%BB%B6%E5%BA%93/"},{"name":"vscode","slug":"vscode","permalink":"http://new.zzpblog.cn/tags/vscode/"},{"name":"linux","slug":"linux","permalink":"http://new.zzpblog.cn/tags/linux/"},{"name":"Redis","slug":"Redis","permalink":"http://new.zzpblog.cn/tags/Redis/"},{"name":"Nginx","slug":"Nginx","permalink":"http://new.zzpblog.cn/tags/Nginx/"}]}